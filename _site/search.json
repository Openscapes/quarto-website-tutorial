[
  {
    "objectID": "explore.html",
    "href": "explore.html",
    "title": "Explore and setup",
    "section": "",
    "text": "With this tutorial, we have a working example website that we will explore together. We’ll learn a few rules and look for patterns to get an understanding of what things to do to help you start customizing and making it your own. And you can continue to use this website as a reference after the tutorial, along with Quarto documentation.\nWe’ll start our exploration online looking at the website architecture and GitHub repository. Then we’ll setup a copy for ourselves so that we can modify from a working example, which is a great way to learn something new. We’ll set it up so that any modifications (commits) will automatically be republished via GitHub Actions. Subsequent chapters will describe how to modify your repo using different tools (browser, RStudio, Jupyter)."
  },
  {
    "objectID": "explore.html#exploring-online",
    "href": "explore.html#exploring-online",
    "title": "Explore and setup",
    "section": "Exploring online",
    "text": "Exploring online\n\nThe website itself\nThis website has 5 things you can see on the left sidebar:\n\nWelcome\nExploring and setup\nQuarto workflows\nLearning more\nTransition from Rmd\n\nMost of these are pages, but you’ll see that “Quarto Workflows” has an arrow; it is a folder with additional pages inside.\n\n\nThe website’s repo\nLet’s go to this website’s GitHub repository (also called a “repo”), https://github.com/openscapes/quarto-website-tutorial. You can also click there from any page in this tutorial website by clicking the GitHub octocat icon underneath the Openscapes logo in the left navbar (click it holding command on Mac, or control on a PC to open it in a different tab in your browser).\nHave a look at the filenames. We can recognize the names of the webpages we’ve seen above, and they have red arrows marking them in the image below. You’ll see the “quarto-workflows” folder and the rest in this site are .qmd files, which are plain text Quarto files that can combine Markdown text with code. index.qmd is the home page. If you click inside “quarto-workflows” you’ll see a mix of filetypes!\n\n\n\nquarto-website-tutorial GitHub repository with files for webpages marked with red arrows\n\n\nThe _site folder has html files with names that should be familiar: they match the .md files we were just exploring. This folder is where Quarto stores files to build the website."
  },
  {
    "objectID": "explore.html#quarto.yml-intro",
    "href": "explore.html#quarto.yml-intro",
    "title": "Explore and setup",
    "section": "_quarto.yml intro",
    "text": "_quarto.yml intro\nThere is also a _quarto.yml file, which is the website’s configuration file. It is essentially metadata for the website that includes the order that the pages/chapters will be in. This is where you update the organization of your website: which page comes before another. If we compare side-by-side, you’ll see that the pages that appear on our website are listed there.\n\n\n\n_quarto.yml and website side-by-side\n\n\nWe’ll learn more about how to interact with _quarto.yml in Quarto Workflows."
  },
  {
    "objectID": "explore.html#fork-to-your-account",
    "href": "explore.html#fork-to-your-account",
    "title": "Explore and setup",
    "section": "Fork to your account",
    "text": "Fork to your account\nLet’s start with an existing Quarto site and copy it into your space to edit. You’ll need a free GitHub account that you create at github.com (follow this advice about choosing your username).\nFirst, choose an existing website to copy. The simplest option is to start with this site: quarto-website-tutorial.\nOther options of potential interest:\n\n2021-Cloud-Hackathon\n2022-SWOT-Ocean-Cloud-Workshop\nOpenscapes Approach-Guide\n\nNext, follow these steps to fork and setup your repo with GitHub Actions from Gavin Fay, using the repo you chose. These instructions will take ~5 minutes.\nNow you’ve got a copy of your repo of choice in your own GitHub account, and you’re set to start making your own edits. Your GitHub repo is set up with a GitHub Action that will use Quarto to rebuild and republish your site anytime you make a commit: committing will trigger the GitHub Action to rebuild and republish the book.\nNote that the GitHub Action for this book does not include R or Python so those will need to be added if your website relies on code. See https://github.com/r-lib/actions for more details and examples.\n\nDownload instead of fork\nForking might not always be the way to go - you can’t fork into the same GitHub user account or organization so if for example you want to make a copy of 2021-Cloud-Hackathon repo within the same NASA-Openscapes GitHub Organization, you’ll need to download instead of fork. In this case, follow these steps to download and copy into a new repository, and set up the GitHub Action separately.\n\nDownload github repo files\nNavigate to https://github.com/openscapes/quarto-website-tutorial (or any other quarto site repo of choice). Click the green “Code” button and select “Download ZIP”. When it downloads on your computer, unzip the files.\n\n\nCreate a new GitHub repo\nNavigate to your GitHub account or organization, and create a new repository, naming it what you’d like. You’ll need a free GitHub account that you create at github.com (follow this advice about choosing your username). When you’re logged in, github.com will show a green button that says “New” which you’ll also see as you navigate to your username’s repository page.\n\n\nAdd original site files\nTo use the GitHub file uploader, click the button next to the green “Code” button that says “Add file”. Add file > Upload files. Then, on your computer, select all the files in unzipped folder (command-A or control-A), and drag them to the GitHub uploader page. Scroll down to write a commit message, which effectively saves your files when you’re working in the browser.\nNote: if you’re comfortable cloning the new repository and copying files into it locally before committing and pushing back to GitHub, that can be preferable to the uploader, which does have limitations with complex repos (although the uploader works fine with this tutorial repo)."
  },
  {
    "objectID": "explore.html#setup-github-action",
    "href": "explore.html#setup-github-action",
    "title": "Explore and setup",
    "section": "Set up GitHub publishing",
    "text": "Set up GitHub publishing\nIf you’ve used the GitHub uploader, you’ll need to set up GitHub publishing separately. We’ll do this in a few steps: we’ll set up a GitHub Action within your repo, and create a gh-pages branch.\nFirst, the GitHub Action. Go back to your main view of your GitHub repository by clicking on the name of your repository in blue at the top-left (the url in your browser window should say https://github.com/username/repo-name).\nNext to the green code button, click Add file > Create new file. Name it exactly this: .github/workflows/quarto-publish.yml . In detail: start by typing the . with github and when you type the / it will give you a new text box to type workflows (plural!), then another /, and finally, quarto-publish.yml.\nNow you’ll have an empty new file. Paste the following in this empty file - you can click on the top-right of this box to copy all the code inside this code box:\non:\n  push:\n    branches: main\n\nname: Render and Publish\n\njobs:\n  build-deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v2 \n        \n      - name: Set up Quarto\n        uses: quarto-dev/quarto-actions/setup@v2\n        with:\n          # To install LaTeX to build PDF book \n          tinytex: true \n          # uncomment below and fill to pin a version\n          # version: 0.9.600\n      \n      # add software dependencies here\n\n      - name: Publish to GitHub Pages (and render)\n        uses: quarto-dev/quarto-actions/publish@v2\n        with:\n          target: gh-pages\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # this secret is always available for github actions\nCommit this to save your new quarto-publish.yml file. This is your GitHub Action.\nNext, we’ll create a new gh-pages branch. Go back to the main view of your GitHub repository. On the far left from the green “Code” button, click the button that says “main”. In the pull-down menu, type gh-pages - all lowercase, with a hyphen. Click the bold text that says “Create branch: gh-pages from main”.\nNow click on the Settings tab in the top right of your repository. On the left sidebar, click Pages. At the top of Pages under “Source”, select gh-pages root, and press Save. You’ll then see a green highlighted text saying that your site is published at a “github.io” url."
  },
  {
    "objectID": "explore.html#confirm",
    "href": "explore.html#confirm",
    "title": "Explore and setup",
    "section": "Confirm your website is published",
    "text": "Confirm your website is published\nTo confirm that your website is published, go back to your main repository page. You’ll now see an orange dot showing that the GitHub Action is beginning to publish the page.\n\n\n\nOur repo with orange dot indicating in-progress GitHub Action build\n\n\nIf you do not see this orange dot, you might need to make a small commit to trigger the GitHub Actions build. If this is the case, click the pencil on the top-right of the README.md file as circled in the image below, add some small edit (like a space after a period), and scroll down to click commit. Now you should see the orange dot.\n\n\n\n\n\nWhen your orange do becomes a green check, you can go inspect your published site at “https://username.github.io/your-repo). For example: https://openscapes.github.io/quarto-website-tutorial.\n\n\n\nOur repo with green check indicating successful GitHub Action build"
  },
  {
    "objectID": "explore.html#renaming-your-repo",
    "href": "explore.html#renaming-your-repo",
    "title": "Explore and setup",
    "section": "Renaming your repo",
    "text": "Renaming your repo\nIf you’d like to rename your repo, go to Settings and the option to rename is on the top of the main settings page."
  },
  {
    "objectID": "explore.html#onward",
    "href": "explore.html#onward",
    "title": "Explore and setup",
    "section": "Onward!",
    "text": "Onward!\nNow you are ready to start editing and publishing! The next chapter describes how starting off from the browser, using Markdown."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistics Production Guidance",
    "section": "",
    "text": "This website is a guide aimed at anyone producing official statistics in the Department for Education (DfE). It covers wider best practice and pulls together pieces of guidance that were previously standalone documents. If viewed in its entirety, it provides a walk-through guide from processing to publication, as well as being a single reference point that is easy to navigate if you just need to check on a specific part of the process, link off to other resources, or access specific guidance.\nThere is already a wealth of resources out there, and therefore this site unashamedly aims to pool the relevant resources for statistics production into one place. There are some things that this site does not yet have, it will develop and change over time. We hope it can prove a useful resource for everyone from the most experienced of producers, right through to those who are working on their very first publication. If you have any feedback, suggested additions, or wish to challenge any of the guidance, please contact us using the envelope button in the top right corner."
  },
  {
    "objectID": "index.html#learning-and-development",
    "href": "index.html#learning-and-development",
    "title": "Statistics Production Guidance",
    "section": "Learning and development",
    "text": "Learning and development\nGeneral resources A collection of useful learning resources, and information on the recommended tools to get you started\nSQL Guidance and tips for accessing data via databases with SQL\nR Guidance and tips for using the programming language R\nGit Guidance and tips for version control with Git"
  },
  {
    "objectID": "index.html#creating-statistics",
    "href": "index.html#creating-statistics",
    "title": "Statistics Production Guidance",
    "section": "Creating statistics",
    "text": "Creating statistics\nProcesses and RAP Guidance for how to process data, including the principles of Reproducible Analytical Pipelines (RAP)\nRAP information for managers Guidance for those managing analysts and FAQs on RAP\nOpen data standards Guidance on how to structure data files\nWriting and visualising Things to consider when writing statistical commentary"
  },
  {
    "objectID": "index.html#publishing-statistics",
    "href": "index.html#publishing-statistics",
    "title": "Statistics Production Guidance",
    "section": "Publishing statistics",
    "text": "Publishing statistics\nHow to publish Guidance for how to publish different types of statistics\nUsing EES Guidance for how to use the features in the Explore Education Statistics platform\nEES good practice examples Examples of good practice in EES across all of our publications\nDashboards Guidance for publishing official statistics dashboards\nCreating embedded visualisations Guidance for creating and embedding R-Shiny charts in EES publications"
  },
  {
    "objectID": "index.html#understanding-users",
    "href": "index.html#understanding-users",
    "title": "Statistics Production Guidance",
    "section": "Understanding users",
    "text": "Understanding users\nUser engagement Guidance on understanding and engaging with the users of published statistics\nEES analytics Guidance on understanding how users are interacting with your statistics published via EES"
  },
  {
    "objectID": "index.html#our-resources",
    "href": "index.html#our-resources",
    "title": "Statistics Production Guidance",
    "section": "Our resources",
    "text": "Our resources\nWe also have a number of other applications for statistics production teams to use to help them in their processes, they can be accessed at the links below when using a DfE device.\n\nDfE QA app\nThis application allows you to screen your data files against the underlying data standards for Official and National statistical publications. If your file passes the checks it also gives you some basic options for exploring the data in the file.\n\nhttps://rsconnect/rsc/dfe-published-data-qa/\nCode hosted at https://github.com/dfe-analytical-services/dfe-published-data-qa\n\n\n\nExplore Education Statistics Analytics\nThis application provides access to the Google Analytics data for the Explore Education Statistics platform.\n\nhttps://rsconnect/rsc/ees-analytics/\nCode is not yet publicly available, contact us if you are interested in seeing it or contributing.\n\n\n\nPublication self-assessment tool\nA self assessment tool allowing teams to compare different aspects of their production processes against best practice.\n\nhttps://rsconnect/rsc/publication-self-assessment/\nCode mirrored at https://github.com/dfe-analytical-services/publication-self-assessment-copy\n\n\n\nTemplate QA code\n\nTemplate QA code https://github.com/dfe-analytical-services/automated-data-qa\n\n\n\ndfeR package\n\nhttps://github.com/dfe-analytical-services/dfeR\n\n\n\nThis guidance website\nThe code for this guidance website is mirrored at https://github.com/dfe-analytical-services/stats-production-guidance-copy"
  },
  {
    "objectID": "learning-more.html",
    "href": "learning-more.html",
    "title": "Learning more",
    "section": "",
    "text": "An excellent overview: Reproducible authoring with Quarto - Mine Çetinkaya-Rundel, Feb 2022 - slides, youtube\nA Quarto tip a day in June 2022, from Mine Çetinkaya-Rundel.\n\n\n\nOpenscapes Champions Lessons Series\nOpenscapes Approach Guide\n\nNASA Earthdata Cloud Cookbook\n\nSee many more examples at the quarto gallery!\n\n\n\nAre you making onboarding documentation? Check out The Fay Lab Manual (now in Quarto!) for inspiration on structure - you could also start there and make it your own."
  },
  {
    "objectID": "quarto-workflows/browser.html",
    "href": "quarto-workflows/browser.html",
    "title": "From the Browser",
    "section": "",
    "text": "A workflow from the browser if good for getting started (since you do not need to install additional software) and for making small contributions, but is definitely limited. Once you feel comfortable here, you can move to a different setup.\nHere’s an example of editing content on an existing page."
  },
  {
    "objectID": "quarto-workflows/browser.html#edit-content-on-an-existing-page",
    "href": "quarto-workflows/browser.html#edit-content-on-an-existing-page",
    "title": "From the Browser",
    "section": "Edit content on an existing page",
    "text": "Edit content on an existing page\nLet’s change the date on the home page of this website.\nIn your repository, navigate to index.md. Then, click the pencil icon in the top right to edit directly.\n\n\n\n\n\nWe are now in the “Edit file” tab of the editor, where we can make modifications. Let’s change the date to today’s date. Click the “Preview” tab to see your changes. You can even check the “Show diff” box on the right side to see the changes you’ve made.\n\n\n\n\n\nWhile you’re here, see if there are additional changes to the text you’d like to make. Maybe changing the title or author at the top, or for the main text on the home page of the website.\nOur index.md file is written in Markdown, which enables you to make simple text formatting. As you go back and forth from “Edit file” to “Preview”, notice the patterns of how the Markdown text looks when it is as source (“Edit file”) and when it is formatted (“Preview”). For example, in Markdown, you can make text as a header with # symbols, bold or italic with * symbols, and hyperlinks with [](). Notice that spacing is important: for example, there are carriage returns (when you hit the “return” key) before any bullet points. You can learn the short list of Markdown rules here: https://quarto.org/docs/authoring/markdown-basics."
  },
  {
    "objectID": "quarto-workflows/browser.html#commit-and-publish",
    "href": "quarto-workflows/browser.html#commit-and-publish",
    "title": "From the Browser",
    "section": "Commit and publish",
    "text": "Commit and publish\nCommit your changes by scrolling to the bottom of the page and writing a commit message - a note to yourself and others about what changes you made. Write your commit message and then click the green “Commit changes” button.\n\n\n\n\n\nNow, click back to the main page of your GitHub repository. You should see the orange dot confirming your website is published. You’ll have to wait for the GitHub Action to tell quarto to build your site for you to see the update, but it will be there!"
  },
  {
    "objectID": "quarto-workflows/browser.html#limitations",
    "href": "quarto-workflows/browser.html#limitations",
    "title": "From the Browser",
    "section": "Limitations",
    "text": "Limitations\nWhile awesome that we can edit using GitHub directly from the browser, there are obvious limitations. One is that to see your edits show up in your book, you have to publish using the GitHub Action. This is slow. Another limitation is that we can only work on one file at a time and commit them each separately, which also is slow. Using additional software can make things much better, as we explore in subsequent chapters."
  },
  {
    "objectID": "quarto-workflows/index.html",
    "href": "quarto-workflows/index.html",
    "title": "Quarto workflows",
    "section": "",
    "text": "How do you work in Quarto? You can use whichever tool you’re comfortable with (RStudio, Jupyter, GitHub, VS Code, etc). Developing your quarto site will have the same basic workflow, no matter which tool you use. It is very iterative, and each is explored more below.\n\nAuthoring: write text, code, images, etc in a file. Supported files include .md, .Rmd, .qmd, .ipynb…\nUpdate _quarto.yml as needed (for example, if you’ve created a new file you’d like included in your site)\nRender individual files and/or the whole website\nRepeat, repeat, repeat\nCommit and push your website to GitHub, your updates will publish automatically!\nRepeat all of the above to make the website as you’d like!\n\nNote: if editing from your internet browser we won’t render in Step 3. That step will not be separate, but combined with Step 5, which will only require a commit, not a push."
  },
  {
    "objectID": "quarto-workflows/index.html#authoring",
    "href": "quarto-workflows/index.html#authoring",
    "title": "Quarto workflows",
    "section": "Authoring",
    "text": "Authoring\nAs an author, you have a lot of options of how your text will be formatted, arranged, and interlinked. You will be writing in Markdown, which is a lightweight text formatting language. The Quarto documentation about authoring introduces markdown-basics that will get you started. Also see Mine Çetinkaya-Rundel’s A Quarto tip a day.\nEach page of our site has a similar first few lines - this YAML, like we saw in our _quarto.yml and it is indicated by two sets of 3 dashes --- :\n---\ntitle: My title\n---\nYou’re able to add more features to individual pages by including it in the YAML, which for the most part here only includes a title. See Quarto excecution options for more information of what you can include in the YAML."
  },
  {
    "objectID": "quarto-workflows/index.html#update-_quarto.yml",
    "href": "quarto-workflows/index.html#update-_quarto.yml",
    "title": "Quarto workflows",
    "section": "Update _quarto.yml",
    "text": "Update _quarto.yml\nLet’s have a closer look at the _quarto.yml file.\nThis type of file (.yml or .yaml) is written in YAML (“Yet Another Markup Language”). You’ll be able to shift the arrangement of webpages by reordering/adding/deleting them in the _quarto.yml file following the patterns you see in this example.\n\n\n\n_quarto.yml and website side-by-side\n\n\nNotice that there are multiple ways in the _quarto.yml for you to include a file in your website. For example, in the above image, the “First Observations” we see in the left sidebar of the published website (right image) is represented in _quarto.yml (left image) over two lines, with line 36 indicating the file reference and line 37 indicating the text to show up in the left sidebar. However, “From RStudio” is only represented in one line of _quarto.yml, on line 43. This represents two strategies for including a file in your website. By default, the title of a specified file will show up in the website’s sidebar, which is what is happening with the “From RStudio” example. If you would like more control over what is written in the sidebar vs the title of your files, then the approach we took with “First Observations” is what you’ll want to do: you’ll see that only “First Observations” shows up in the sidebar as we specified in _quarto.yml, but the page’s title says “First Observations & Setup” (which in our preference was too long for the sidebar).\n\n\n\n\n\n\nNote\n\n\n\nAs you modify _quarto.yml, the most important thing to know is that spacing matters. Pay attention to whether text is indented by one, two, four, or other spaces, and make sure you follow it; if your site is not looking as expected it is likely a silent error in your YAML. Some text editors like RStudio provide debugging support for YAML and are highly recommended to save you time and heartache."
  },
  {
    "objectID": "quarto-workflows/index.html#install-quarto",
    "href": "quarto-workflows/index.html#install-quarto",
    "title": "Quarto workflows",
    "section": "Install Quarto",
    "text": "Install Quarto\nhttps://quarto.org/docs/get-started/ describes how to install Quarto, which will depend on your operating system. We’ll walk through installation for each tool in the next chapters."
  },
  {
    "objectID": "quarto-workflows/jupyter.html",
    "href": "quarto-workflows/jupyter.html",
    "title": "From Jupyter",
    "section": "",
    "text": "You can interact with Quarto through JupyterLab or JupyterHub. Your Jupyter setup will involve .ipynb notebooks and the command line. Quarto’s JupyterLab tutorials has great instructions on getting started with JupyterLab, including computations and authoring.\nHere we will demonstrate how to work with this Quarto tutorial site in JupyterHub and add a Jupyter Notebook (.ipynb file). This example uses the NASA-Openscapes JupyterHub that already has all python environments as well as Quarto installed."
  },
  {
    "objectID": "quarto-workflows/jupyter.html#setup",
    "href": "quarto-workflows/jupyter.html#setup",
    "title": "From Jupyter",
    "section": "Setup",
    "text": "Setup\n\nJupyterHub\nOur JupyterHub is already setup with python environments as well as Quarto (through nasa-openscapes/corn), so there is no further installation required.\n\n\nClone your repo\nYou’ll start by cloning your repository into JupyterHub. Do this by opening a terminal (File > New > Terminal). In the Terminal, git clone your repository and cd into it:\ngit clone https://github.com/openscapes/quarto-website-tutorial\ncd quarto-website-tutorial\n\n\nInstall Quarto\nNot needed - Quarto is already installed on the NASA-Openscapes JupyterHub! But to install elsewhere you would do so from https://quarto.org/docs/get-started/.\nQuarto is a Command Line Interface (CLI), like git. Once download is complete, follow the installation prompts on your computer like you do for other software. You won’t see an application to click on when it is installed.\nNote for Mac users: If you do not have administrative privileges, please select “Install for me only” during the Destination Selection installation step (you will first click on “Change Install Location” at the Installation Type step).\nYou can check to confirm that Quarto is installed properly from the command line:\nquarto check install\n\n\n\n\n\n\nAdditional checks\n\n\n\n\n\nYou can also run:\n\nquarto check knitr to locate R, verify we have the rmarkdown package, and do a basic render\nquarto check jupyter to locate Python, verify we have Jupyter, and do a basic render\nquarto check to run all of these checks together\n\n\n\n\n\n\n\n\n\n\nHistorical aside: Install Quarto in a docker container\n\n\n\n\n\nIn Summer 2021 some NASA Mentors trying to install quarto locally was not an option, but they were able to install it inside a container using the following Dockerfile:\n#| fold: true\n#| summary: \"Show the Dockerfile\"\n\n##############################\n# This Dockerfile installs quarto and then runs quarto serve against the\n# internal /home/quarto/to_serve.\n#\n# BUILD\n# -----\n# To build this container, run\n#\n#     docker build -t quarto_serve .\n#\n# Add the --no-cache option to force docker to build fresh and get the most\n# recent version of quarto.\n#\n#\n# RUN\n# ---\n# 1. Find the directory you want quarto to serve. Let's call this /PATH/TO/earthdata-cloud-cookbook.\n# 2. Run docker:\n#\n#     docker run --rm -it -p 4848:4848 -v /PATH/TO/earthdata-cloud-cookbook:/home/quarto/to_serve quarto_serve\n#\n# 3. Open your browser and go to http://127.0.0.1:4848/\n#\n##############################\n\nFROM ubuntu:hirsute\n\n######\n# Install some command line tools we'll need\n######\nRUN apt-get update\nRUN apt-get -y install wget\nRUN apt-get -y install gdebi-core\nRUN apt-get -y install git\n\n\n######\n# Install quarto (https://quarto.org/)\n######\n\n# This is a quick and dirty way of getting the newest version number from\n# https://github.com/quarto-dev/quarto-cli/releases/latest. What's happening is\n# we're pulling the version number out of the redirect URL. This will end up\n# with QVER set to something like 0.2.11.\nRUN QVER=`wget --max-redirect 0 https://github.com/quarto-dev/quarto-cli/releases/latest 2>&1 | grep \"Location\" | sed 's/L.*tag\\/v//' | sed 's/ .*//'` \\\n    && wget -O quarto.deb \"https://github.com/quarto-dev/quarto-cli/releases/download/v$QVER/quarto-$QVER-amd64.deb\"\nRUN gdebi -n quarto.deb\n\n# Run this to make sure quarto installed correctly\nRUN quarto check install\n\n\n######\n# Create a non-root user called quarto\n######\nRUN useradd -ms /bin/bash quarto\nUSER quarto\nRUN mkdir /home/quarto/to_serve\nWORKDIR /home/quarto/to_serve\n\n\n######\n# Start quarto serve\n######\n\nCMD quarto serve --no-browse --host 0.0.0.0 --port 4848"
  },
  {
    "objectID": "quarto-workflows/jupyter.html#quarto-preview",
    "href": "quarto-workflows/jupyter.html#quarto-preview",
    "title": "From Jupyter",
    "section": "Quarto preview",
    "text": "Quarto preview\nLet’s start off by previewing our quarto site locally. In Terminal, type quarto preview, which will provide a URL with a preview of our site!\nquarto preview\n# Preparing to preview\n# Watching files for changes\n# Browse at https://openscapes.2i2c.cloud/user/jules32/proxy/4593/\nCopy this URL into another browser window; and arrange them so you can see them both. I make a bit more space in Jupyter by collapsing the left file menu by clicking on the file icon at the top of the left sidebar.\n\n\n\n\n\n\nMake a small change and preview it\nNow we’ll be able to see live changes in the preview as we edit in our .md files. Let’s try it: Change the date in index.md by opening it from the file directory. Change to today’s date, and save. Your preview window will refresh automatically! If it does not, you can also refresh the page manually. The refreshed previewed site will now display your changes!"
  },
  {
    "objectID": "quarto-workflows/jupyter.html#create-a-new-.ipynb-page",
    "href": "quarto-workflows/jupyter.html#create-a-new-.ipynb-page",
    "title": "From Jupyter",
    "section": "Create a new .ipynb page",
    "text": "Create a new .ipynb page\nLet’s add a new page to our site. Instead of an .md file like the others, let’s add a .ipynb file.\nFile > New > Notebook. Accept the default kernel by clicking Select.\n\nFirst chunk: raw yaml\nBy default, this Notebook will give us a first chunk that is code. Let’s change it to raw so that we can write our yaml at the top.\n\n\n\n\n\nIn our Raw code chunk, let’s write the title of this document. We need three dashes --- on separate lines preceding and following the title:, which you can name as you’d like.\n---\ntitle: Python Example\n---\n\n\nSecond chunk: Markdown\nLet’s add a new chunk that is Markdown so we can write some description of what this page will be.\nClick the + symbol at the top of the document, and this will add a new chunk, which by default again is a Code chunk. Change it to a Markdown Chunk following the steps we did above when switching to Raw.\nHere, write a little bit of text in Markdown. Since your title is effectively a level-1 header, avoid using level-1 headers in the rest of your document. Here is some example text I wrote:\n## Introduction\n\nThis example has some Python code that will be a part of our Quarto site.\n\n\nThird chunk: Code\nNow let’s create a new chunk with the default Code setting.\nPaste the following code (or write some of your own to test):\n#| label: fig-polar\n#| fig-cap: \"A line plot on a polar axis\"\nimport numpy as np\nimport matplotlib.pyplot as plt\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\nNow, go ahead and execute this code chunk like you normally would, by clicking the cursor in a code block and clicking the sideways “play” triangle to run the selected cells (and advance to the next cell). This code produces a plot.\nNote that the code runs as it normally would; the code options in the comments are just comments.\n\n\nSave your file\nSave your document - I’ll call mine python-example.ipynb in the main repository."
  },
  {
    "objectID": "quarto-workflows/jupyter.html#update-_quarto.yml",
    "href": "quarto-workflows/jupyter.html#update-_quarto.yml",
    "title": "From Jupyter",
    "section": "Update _quarto.yml",
    "text": "Update _quarto.yml\nNow we’ll add python-example.ipynb to our _quarto.yml file; this is where we register of all files to include in our site. Let’s add it after the section called “Basic Workflows”.\nOpen _quarto.yml by clicking on it from the file directory.\nScroll down to review the current contents in the sidebar: section. It’s there we see all the file arrangement that we see in the previewed site.\nAdd - python-example.ipynb to line 46, making sure that your indentation aligns with the other pages.\n\n\n\n\n\nYou’ll see that our new page shows up in our Preview, and the code is executed since we did that in the Jupyter Notebook itself. By default, Quarto will not execute code chunks since your computations will likely become more complex and you will want to control when they are executed (or “run”).\nSince Quarto is still previewing our website and the python-example.ipynb, the plot also displays in the notebook after the code is run and the file is saved, as shown below.\n\n\n\n\n\nSo, your normal workflow for creating and running code blocks in your Jupyter Notebook is the same one you’ll use as Quarto displays the preview."
  },
  {
    "objectID": "quarto-workflows/jupyter.html#quarto-render",
    "href": "quarto-workflows/jupyter.html#quarto-render",
    "title": "From Jupyter",
    "section": "Quarto render",
    "text": "Quarto render\nSo far we have used Quarto preview to view our website as we develop it. Quarto render will build the html elements of the website that we can see when we preview. Rendering will format the markdown text and code nicely as a website (or however is indicated in the _quarto.yml).\nBy default, Quarto render does not execute code in a Jupyter notebook. It will never run .ipynb files unless you tell it to.\n\nRender whole notebook\nIf you would like it to specifically execute code in a Jupyter notebook, you can do so in Terminal.\nOur Terminal is still busy previewing our website, so let’s open a new Terminal.\nFile > New > Terminal. Then type:\ncd quarto-website-tutorial\nquarto render python-example.ipynb --execute"
  },
  {
    "objectID": "quarto-workflows/jupyter.html#authoring-tips",
    "href": "quarto-workflows/jupyter.html#authoring-tips",
    "title": "From Jupyter",
    "section": "Authoring tips",
    "text": "Authoring tips\nQuarto.org has details about authoring, including specific instructions about authoring in Jupyter: quarto.org/docs/reference/cells/cells-jupyter."
  },
  {
    "objectID": "quarto-workflows/jupyter.html#commit-and-push",
    "href": "quarto-workflows/jupyter.html#commit-and-push",
    "title": "From Jupyter",
    "section": "Commit and push!",
    "text": "Commit and push!\nCommitting and pushing will make the changes you see locally live on your website (using the GitHub Action we set up earlier)."
  },
  {
    "objectID": "quarto-workflows/jupyter.html#troubleshooting",
    "href": "quarto-workflows/jupyter.html#troubleshooting",
    "title": "From Jupyter",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nMy changes don’t show up in preview\nMake sure you’ve saved your file! There might be a slight delay depending on your JupyterHub/Lab setup.\n\n\nQuarto render hangs / does not complete\nCheck the specific notebook, are there any `—` throughout to denote line breaks rather than yaml? They might be causing the issue; consider deleting those.\nAlso check how long the first raw cell is. Are there level-1 headers (#)? Try removing them."
  },
  {
    "objectID": "quarto-workflows/rstudio.html",
    "href": "quarto-workflows/rstudio.html",
    "title": "From RStudio",
    "section": "",
    "text": "The RStudio software (called an IDE, integrated development environment) is an excellent way to edit files and interface with GitHub. Plus, as it is made by the same folks who make Quarto, it has many integrated features for streamlining your workflow with Quarto, including how it previews your edits and provides debugging support for yaml! Quarto's RStudio tutorials has great instructions on getting started with RStudio, including computations and authoring.\nHere is what you’ll need to do to set up and use RStudio with Quarto."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#setup",
    "href": "quarto-workflows/rstudio.html#setup",
    "title": "From RStudio",
    "section": "Setup",
    "text": "Setup\n\nRStudio and GitHub\nFor a workflow with RStudio and GitHub on your local computer, you will need four things:\n\nR\nRStudio\nGit\nGitHub\n\nFollow the UCSB MEDS Installation Guide for detailed instructions on how to create accounts, download, install, and configure on Mac and Windows. This takes about 20 minutes. (For an even more detailed walk-through, see Allison Horst’s ESM 206 Google Doc).\n\n\nClone your repo\nYou’ll start by cloning your repository into RStudio.\nFile > New Project > Version Control > Git > paste your repository name.\nR for Excel Users: Clone your repository using RStudio has detailed instructions and screenshots of these steps.\n\n\nInstall Quarto\nNext, you’ll install Quarto: https://quarto.org/docs/get-started/. After downloading, follow the installation wizard on your computer. When it is complete, you won’t see an application or any new software, but it is now available to RStudio (as well as all other applications on your computer, including the command line).\n\n\nRStudio orientation\nNow let’s take a moment to get oriented. This is an RStudio project, which is indicated in the top-right. The bottom right pane shows all the files in your project; everything we’ve cloned from GitHub. We can open any RStudio project by opening its .Rproj file, or from RStudio File > Open Project ….\n\n\n\nRStudio IDE highlighting the project name and files pane\n\n\n\n\nVisual Editor\nThe RStudio Visual Editor is quite new and has features that improve your writing experience. Working in the Visual Editor feels a bit like working in a Google Doc.\nHere’s an example showing the same file in the original Source Editor with content in markdown format and in the Visual Editor with content that looks more like it will appear in a live site. You can switch freely between these modes.\n\n\n\n\n\n\nRStudio IDE highlighting the Source Editor\n\n\n\n\n\n\n\nRStudio IDE highlighting the Visual Editor\n\n\n\n\n\nAlready have some content formatted in a Google Doc? You can copy-paste it into the Visual Editor and most formatting will be retained.\nThe editing bar provides familiar point and click access to text formatting options like bulleted or numbered lists.\n\n\n\nRStudio IDE highlighting the point and click editing bar\n\n\n\nKeyboard shortcuts\nThe Visual Editor also lets you use many keyboard shortcuts that might be familiar for adding boldface (command-b), italics (command-i), or headers. On a Mac, option-command-2 will make a level 2 header. Try it with option-command-1, or option-command-0 for normal text!\n\n\nInsert an image or figure\nTo insert an image (called a figure in Quarto), click the image icon. This brings up a window in which we can select the image, set its alignment, give it a caption and alt text, hyperlink it, or edit other metadata.\n\n\n\nInsert image or figure using the Visual Editor\n\n\nOnce an image is added, clicking on that image gives us editing options. We can resize it dynamically by clicking in the image and dragging a corner or side to resize. When an image is selected, its dimensions are displayed for editing. Clicking on the gray ellipsis to the right of the dimensions opens the pop-up window to access more metadata edits.\n\n\nInsert a table\nSimilar to adding an image, to insert a table, we click the Table dropdown."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#quarto-render",
    "href": "quarto-workflows/rstudio.html#quarto-render",
    "title": "From RStudio",
    "section": "Quarto render",
    "text": "Quarto render\nIn the Build tab in the top-right pane, click “Render Website”. This will build the .html files and preview your website. It’s equivalent to “knitting” in RMarkdown.\nNote that you can also click “Preview Website”. With “Render Website” in RStudio, Quarto is able to render and preview in one step.\nIf you’d ever like to stop the preview, in the bottom-left, click on the Jobs tab and then the red Stop button.\n\nMake a small change and render it\nClick on index.md. This will open this markdown file in a fourth pane; the editor pane. Make a small change, for example change to today’s date on Line 4. Then, save your file; there is a disc icon at the top of the file.\nThen, render this file: press “Render” which is to the right of the disc icon that saves the file. This will render only this single file, as opposed to rerendering the whole website like when we clicked “Render Website” in the top right pane. Checking Render on Save (between the disc icon and the Render button) is a great strategy for doing this in one step."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#create-a-new-.rmd-page",
    "href": "quarto-workflows/rstudio.html#create-a-new-.rmd-page",
    "title": "From RStudio",
    "section": "Create a new .Rmd page",
    "text": "Create a new .Rmd page\nNew > RMarkdown document > OK\nThe starter RMarkdown document has some R code inside: it displays a summary of the cars dataset that is pre-loaded into R (summary(cars)) and plots the pressure data that is also pre-loaded (plot(pressure)).\nSave this document as r-example.rmd."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#update-_quarto.yml",
    "href": "quarto-workflows/rstudio.html#update-_quarto.yml",
    "title": "From RStudio",
    "section": "Update _quarto.yml",
    "text": "Update _quarto.yml\nNow we’ll add r-example.rmd to our _quarto.yml file; this is where we register all files to include in our site. Let’s add it after the section called “Quarto Workflows”.\nOpen _quarto.yml by clicking on it from the file directory.\nScroll down to review the current contents in the sidebar: section under contents:. It’s there we see all the file arrangement that we see in the previewed site.\nAdd - r-example.rmd in its own line, making sure that your indentation aligns with the other pages.\nFrom the Build tab, clicking Preview Website will recreate your website!"
  },
  {
    "objectID": "quarto-workflows/rstudio.html#authoring-tips",
    "href": "quarto-workflows/rstudio.html#authoring-tips",
    "title": "From RStudio",
    "section": "Authoring tips",
    "text": "Authoring tips\nChecking “Render on Save” is really helpful when iterating quickly on a document.\nIf the document is very code-heavy, consider using freeze that will not run the code each time.\nQuarto.org has details about authoring, including specific instructions about authoring in RStudio."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#commit-and-push",
    "href": "quarto-workflows/rstudio.html#commit-and-push",
    "title": "From RStudio",
    "section": "Commit and push!",
    "text": "Commit and push!\nCommitting and pushing will make the changes you see locally live on your website (using the GitHub Action we set up earlier)."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#troubleshooting",
    "href": "quarto-workflows/rstudio.html#troubleshooting",
    "title": "From RStudio",
    "section": "Troubleshooting",
    "text": "Troubleshooting\nIf you have trouble rendering your website after for example changing the extenstion of a file from .md to .qmd, refreshing your RStudio often helps. Do this by clicking the project name at the upper right of the RStudio window (in this case, quarto-website-tutorial), and underneath the “close project” section, click the same name of your project: quarto-website-tutorial. This will relaunch your whole project afresh."
  },
  {
    "objectID": "transition-from-rmarkdown.html",
    "href": "transition-from-rmarkdown.html",
    "title": "Transition from RMarkdown",
    "section": "",
    "text": "You may already have workflows in RMarkdown and are interested in transitioning to Quarto. There’s no hurry to migrate to Quarto. Keep using Rmarkdown and when you’re ready the migration will be fine.\nHere are some notes as we migrate RMarkdown sites and books.\nTODO: translating R code chunks"
  },
  {
    "objectID": "transition-from-rmarkdown.html#bookdown-to-quarto",
    "href": "transition-from-rmarkdown.html#bookdown-to-quarto",
    "title": "Transition from RMarkdown",
    "section": "Bookdown to Quarto",
    "text": "Bookdown to Quarto\nConverting a Bookdown book to Quarto is slightly more involved than converting a website. A book has chapters whose order must be defined, and likely has citations and cross-refs. Still, conversion is not that hard.\nWe got some practice converting from Bookdown to Quarto by helping Gavin Fay convert his lab’s fantastic onboarding documentation, the Faylab Lab Manual. Here’s the GitHub view before and after.\nOur best first reference material for this was Nick Tierney’s Notes on Changing from Rmarkdown/Bookdown to Quarto. Nick shares some scripts in that post to automate some changes. In our case, the book was small enough that we made all changes manually. Quarto documentation was indispensable.\n\nExperimenting in a low-risk environment\nWe forked a copy of the Faylab Lab manual to the Openscapes organization, and worked in a branch so we could make changes relatively risk-free. We could always fork a new copy of the original if we “broke” something. (Caution: the default when making a pull request from a fork is to push changes to the original upstream repo, not your fork and it does this without warning if you have write-access to that repo.) With local previews it’s easy to test / play with settings to see what they do. We tended to make a change, Preview, then compare the look and functionality of the book to the original. It was helpful to comment out some elements of the configuration file _output.yml after their counterparts had been added to the Quarto configuration file _quarto.yml, or to confirm they were no longer needed, before making the drastic move of deleting them.\n\n\nThe conversion\nHere are the main steps to convert the Faylab Lab manual from Bookdown to Quarto.\nCreate new empty file called _quarto.yml and add book metadata there. The screenshots below\nSet project type as book.\nMove metadata out of index.qmd and into _quarto.yml. Title, author, and publication date were in index.qmd with date set using date: \"Last updated:r Sys.Date()\". Now these are in _quarto.yml with date set using date: last-modified. Note that having R code would require you to adjust code chunk options in the Quarto style (#|). This tripped us up a bit; see GitHub Actions.\nMove chapters listing out of _bookdown.yml and into _quarto.yml.\nAdd page footer to _quarto.yml.\nHere’s what ours looked like when we finished the steps above (_quarto.yml).\n\n\n\n\n\n\n_quarto.yml contents\n\n\n\n\n\n\n\nFaylab Lab Manual\n\n\n\n\n\nChange insertion of images from html style to Quarto style. (Note Quarto calls them “figures”, not “images”.) The following snippet will insert the GitHub octocat logo in a page:\n![](https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png){fig-align=\"left\" width=\"35px\"}\nChange all filename extensions .Rmd -> .qmd (you could Preview after this change and see that the book looks the same). Note that Quarto works with .Rmd files just as well as it does .qmd, so this change is not urgent. In fact, if you have a lot of R code in your .Rmds (unlike the Faylab Lab Manual), there will be additional tinkering needed to make the code chunks happy.\n\n\nCitations\nThe Faylab Lab Manual cited two papers, presenting us with an opportunity to see how easy it is to add references to a Quarto book. Briefly, in the Visual Editor, Insert > Citation > DOI. Pasting the DOI or its full URL, we can insert the citation. This automatically creates a references.bib file and adds the full citations at the bottom of the chapter page (watch demo). In July 2022, we had to manually add a ## References heading, but this may not be necessary in future Quarto updates.\n\n\n\n\n\n\nInsert citation via its DOI using RStudio Visual Editor\n\n\n\n\n\n\n\n\n\n\nPublishing notes\nIf the book’s output is strictly html, there’s no need to specify output-dir in _quarto.yml. The output directory default is _book/, which is what we’d like. If we wanted other types of output like like PDF or EPUB, etc. those single file outputs are also written to the output-dir (Quarto docs).\nIf you currently have a docs/ folder, delete it.\nUpdate .gitignore to ignore _book/. At the same time, we have it ignore caches and a .quarto file:\n/.quarto/\n*_cache/\n_book/\nOnce all is settled, delete _output.yml.\nOnce the Openscapes fork was fully reviewed, we made a pull request from that to the main branch of the book’s repo. Once that was merged, we set up GitHub Actions to render the book. (TODO: instructions for GitHub Actions)\n\n\nGitHub Actions\nThis book was mostly prose and screenshots without any R code. This made the conversion from RMarkdown to Quarto likely more straightforward than if you also needed to adjust code chunk options in the quarto style (#|). Our initial GitHub Action to render the converted Faylab Lab Manual failed because we had a piece of R code - even though the code was commented out! This was resolved when we deleted the line."
  },
  {
    "objectID": "transition-from-rmarkdown.html#distill-to-quarto",
    "href": "transition-from-rmarkdown.html#distill-to-quarto",
    "title": "Transition from RMarkdown",
    "section": "Distill to quarto",
    "text": "Distill to quarto\nWe transitioned our events site from distill to quarto in May 2022 (github view before and after). We followed excellent notes and examples from Nick Tierney and Danielle Navarro.\nAfter we had changed all the files, the Build tab in the RStudio IDE still showed “Build website” rather then “Render Website” and “Preview Website”, and would error when we pushed them (because that button was expecting a distill site, not a quarto site). To fix this, we updated the .Rproj file. Clicking on the .Rproj file in the RStudio IDE will open a dialog box where you can click things you want (you can also open these in a text editor or from the GitHub website to see the actual text). To fix this situation with the Build tab: Project Options > Build Tools > Project Build Tools > None.\nLooking at files /posts/_metadata.yml and _quarto.yml helps see where things are defined. For example, to make event post citations appear, we added citation: true to /posts/_metadata.yml and in _quarto.yml under the website key we set site-url: https://openscapes.github.io/events. We deleted footer.html used with distill because footer is now defined in quarto.yml.\n\nPublishing notes\n\nBackground: Our distill site had been set up to output to a docs folder, and had GitHub Settings > Pages set to look there rather gh-pages branch. (Julie note: this was a new-to-me capability when we set up the events distill site in Spring 2021 so I had forgotten that was an option). We’ve inititally kept this same set-up for now with our events page in _quarto.yml: output-dir: docs. However, this is sub-optimal; better to not have to commit and push these files but to instead have a GitHub Action generate them upon a commit. So the following is what we did -\n\nDon’t specify output-dir in _quarto.yml. The output directory default is _site/, which is what we’d like.\nIf you currently have a docs/ folder (like we did as we were experimenting), delete it.\nUpdate .gitignore to ignore _site/. At the same time, we have it ignore caches and a .quarto file:\n/.quarto/\n*_cache/\n_site/\nPush these changes, merge into main.\nOn GitHub.com, in your repo, set up GitHub publishing\nFollow instructions from the explore and setup chapter."
  },
  {
    "objectID": "transition-from-rmarkdown.html#troubleshooting",
    "href": "transition-from-rmarkdown.html#troubleshooting",
    "title": "Transition from RMarkdown",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nGitHub Action fails, says you need RMarkdown but you don’t have R code!\nAnd you changed all .Rmds to .qmds!\nYou likely have a few setup code chunks from RMarkdown, that look like this:\n{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = FALSE)\nYou can find them by opening each of your files and having a look, or use GitHub’s search for the keyword knitr"
  },
  {
    "objectID": "learning-development/git.html",
    "href": "learning-development/git.html",
    "title": "Git",
    "section": "",
    "text": "Guidance and tips for version control with Git"
  },
  {
    "objectID": "learning-development/git.html#what-is-it",
    "href": "learning-development/git.html#what-is-it",
    "title": "Git",
    "section": "What is it",
    "text": "What is it\n\nIt is a version control software. It is by far the best of its kind and is widely used by software developers and data scientists."
  },
  {
    "objectID": "learning-development/git.html#what-is-it-for",
    "href": "learning-development/git.html#what-is-it-for",
    "title": "Git",
    "section": "What is it for",
    "text": "What is it for\n\nGit is a version control software that tracks changes to files within a folder that you assign Git to track. It works best with plain text files such as flat data files, code scripts and markdown documents. These folders are known as repositories and can be held and managed securely in a central online place such as GitHub (best for public), GitLab (can be good for either public or private) and Azure DevOps (best for private). We can easily mirror our Azure DevOps repositories in the DfE Analytical Services area on GitHub.\nIt is widely used across DfE and integrates neatly with our use of Azure DevOps, as well as being the current leading version control software in the world of coding with over 87% of 74,298 stack overflow users using it."
  },
  {
    "objectID": "learning-development/git.html#how-to-get-it",
    "href": "learning-development/git.html#how-to-get-it",
    "title": "Git",
    "section": "How to get it",
    "text": "How to get it\n\nDownload it from the Git website.\nGit doesn’t have an IDE, instead it will either integrate with your current IDE such as RStudio or Visual Studio Code, or run in the command line.\nWhen you first try to use Git you may be prompted for a GitHub username and password, if this happens you should generate a Personal Access Token (PAT) and use this as your password."
  },
  {
    "objectID": "learning-development/git.html#best-places-to-start",
    "href": "learning-development/git.html#best-places-to-start",
    "title": "Git",
    "section": "Best places to start",
    "text": "Best places to start\n\n\n\nIf you’re new to Git and are unsure of what it does, then take a look through these Git for humans slides\nDavid Sands’ guide to getting started with Git is a helpful place to start.\nGooey Git by David Sands, provides a very neat overview of using git with R."
  },
  {
    "objectID": "learning-development/git.html#how-to-work-with-git",
    "href": "learning-development/git.html#how-to-work-with-git",
    "title": "Git",
    "section": "How to work with git",
    "text": "How to work with git\n\n\nGit Bash\n\nGit Bash allows you to run git commands without opening another IDE. You’d often need to use Git Bash to set your user settings, amend your proxy settings and clone repositories.\n\n\n\nGit with RStudio\n\nGit with R studio is a neat user interface for git. You don’t need to use any git bash commands, and everything is done using point and click. This is useful for day-to-day version control, but does not support the full functionality of git.\nHowever, you can still run the full suite of git commands by simply typing them in the “Terminal” of RStudio."
  },
  {
    "objectID": "learning-development/git.html#quick-reference-lookup",
    "href": "learning-development/git.html#quick-reference-lookup",
    "title": "Git",
    "section": "Quick reference lookup",
    "text": "Quick reference lookup\n\n\nGitHub have created a cheat sheet for git commands."
  },
  {
    "objectID": "learning-development/git.html#other-resources",
    "href": "learning-development/git.html#other-resources",
    "title": "Git",
    "section": "Other resources",
    "text": "Other resources\n\n\nAvison Ho and Linda Bennett gave this coffee and coding presentation on version controlling SQL with Git.\nHappy Git is a useful (though detailed) guide to setting up and using git.\nAdam Robinson and Zach Waller have produced guidance for how to use git in Azure DevOps (formally VSTS), which gives a detailed guide on how to use version control software in DfE analysis.\nWhile also mentioned above as a resource for learning R, chapter 6 of ESFA’s guide to R and Git is also worth looking at for Git alone.\nMicrosoft have produced documentation on using Git within AzureDevOps.\nFor those wanting to go deeper into understand the variety of git commands and what they do, there is a great online visual resource.\nWe also have a number of helpful sections on using git in practice at the end of our RAP page."
  },
  {
    "objectID": "learning-development/git.html#tips-for-using-git",
    "href": "learning-development/git.html#tips-for-using-git",
    "title": "Git",
    "section": "Tips for using Git",
    "text": "Tips for using Git\n\n\nBranches\n\nDavid Sands has produced a very helpful video on how to use branches in git, which also covers how to tackle merge conflicts if and when they arise:\n\n\n\n\nWhen you create a git project, it will automatically create a “main” (sometimes “master”) branch for you. This is where code that has been QA’d and you are happy with should sit.\n\nIt is good practice to have at least one other branch, we tend to call it “development”. This is the branch where you will be doing most of your work. To open a new branch, navigate to “branches” and click on the blue box highlighted below\n\n\n\n\n\nHaving two separate branches means that if anything goes wrong in the “development” branch, the “main” or “master” branch is still unaffected and runs without issue. This lets you test and QA the code more thoroughly before merging into your main branch.\nWhen working on your project, make sure that you are in the right branch. You can check this by navigating to the “Git” tab in RStudio as demonstrated below.\n\n\n\n\n\n\n\nCommits\n\nOnce you are happy with changes and want them to be in the latest version of your branch for all of your team to see, you can push “commits” up.\n\nWhen you make a change to a file, this will pop up in the “Git” window of your R console. Select the files you want to commit by ticking the “staged” box next to them.\n\n\n\n\n\nThis will bring up a new window. Add a comment describing your additions/changes, and click commit. You will see all the staged files disappear. Then click “Push” to push the committed files up to the online repository for all to use.\n\n\n\n\n\nWhen another member of your team makes a commit and you want to pull this into your local area to check and work off the latest version, click on the blue “pull” button.\n\n\n\n\nCommitting regularly is strongly recommended as each commit is a saved point in time that you can easily roll back to if needed. If you want to know more about how to do this, see the reverting a commit section below.\n\n\n\nPull requests\n\nWhen you have got to a place with the code and your committed changes where you are happy for it to be QA’d, you can open a pull request. This gives your team a chance to QA your changes before merging the branches together.\n\nNavigate to “Pull Requests” in the “Repos” tab of Azure DevOps and click the blue “New pull request” button.\nThis will take you to a new window. Here, you can add:\n\nTitle, tell your team what has changed\nDescription, tell your reviewer what they should check\nReviewers, add multiple if needed.\n\nAs a reviewer, to approve a pull request, follow the link in your email and click “approve” in the blue box. When all reviewers are happy for this to be the new master branch, click “complete”.\n\nCreating pull requests in GitHub follows a broadly similar process and should be intuitive from the above steps for Azure DevOps.\n\n\n\nMerging a branch into another one\n\nIf you want to merge a branch into another without doing a full pull request, you can do this using a terminal.\nThis may happen if you are working on a feature branch, and want to merge the latest changes to the master branch back into your feature branch before opening a PR to master with your own changes. Often this can let you deal with nasty conflicts up front, or allow you to keep working on your feature but update to have something new that’s on master.\nStart off by checking out your desired target branch - git checkout mybranch. Then merge in the branch you want (e.g. master) - git merge master.\n\n\n\nCherry picking\n\nIf you want to cherry pick specific commits for PR, you can do this by cherry picking the commits you want to use, and creating a new branch that has only those new commits that you want.\nTo start off you’ll need to identify the commits you want. In the terminal, run git log --oneline to get a log of commits for your current branch, use git log --online BRANCHNAME to specific the branch for the log. This gives a list of commit hashes and messages (stackoverflow response defining git hashes and commmit ID’s). You can press enter to get more commits, or q to quit\nThen go to the branch you want the commit to appear on and cherry pick your commits. Often, if this is to hop around something on a development to master pr, you would create a second development branch, cherry pick commits to there, and then PR that to master and delete the branch after merging.\nOn the branch you want to PR (i.e. your copy of a development branch purely for merging only cherry picked commits) run git cherry-pick COMMITHASH to add the specified commit, or git cherry-pick HASH1^..HASH4 for a specified list of commits (inclusive).\nHappy days!\n\n\n\nVisualising your tree\n\nYou can use gitk --all to visualise a tree of all previous commits up to this point.\n\n\n\n\n\n\nGetting commit IDs\n\nCommit IDs are the way Git identifies unique commits. They’re really helpful if you ever need to revert back to a previous commit if you’ve made a mistake.\nThere are lots of different ways to find out commit IDs:\n\nVisit the repo in Azure Devops and go to the commit of interest. At the top of the page there is a commit ID you can copy.\nNavigate to the repo in your file explorer, then open up Git Bash and type\n\ngit log --pretty=format:\"%h - %an, %ar : %\nOR\ngit log --pretty=oneline\nThere are a number of customisable versions of this, more information is available on the Git website.\n\n\n\nReverting a commit\n\nMade a mistake and need to revert? No problem! Reverting commits in git creates a new commit reversing your accidental commits, bringing you back to an earlier point in your branch.\nFor rolling back on a branch, you should revert any changes so that you’re not erasing history others might have pulled/cloned. E.g. If you want to revert the last 3 commits on master:\ngit revert --no-commit master~3..master\nThe no commit argument means that it just makes the reverts locally, and you can then commit them all as a single revert commit. If you don’t use --no-commit then it will start doing individual revert commits for you for each commit you’re reverting.\nYou can also revert back to a particular commit ID:\n\nNavigate to the repo in your file explorer, then open up Git Bash and type :\n\ngit revert [PASTE COMMIT ID HERE]\n\nThis opens up a window that asks you to write a commit message. You can skip this step as it automatically writes a revert message for you. Enter :wq which quits the writer window.\nYou can now push these changes to Azure Devops by entering git push into the git window\n\n\n\n\nTagging release versions\n\n\nIt can be useful to tag specific commits or releases at key points in time. For us a common example will be each publication cycle, to tag the version of the code used to process data for a particular release or amendment.\nGuidance on how to tag releases using git can be found on the draft version of the BPI code guidance\n\n\n\nFix: cannot resolve proxy\n\nIf you get this error when trying to pull / push to a repository from a DfE laptop:\nfatal: unable to access 'https://dfe-gov-uk.visualstudio.com/stats-development/_git/ees-analytics-new/': Could not resolve proxy: mwg.proxy.ad.hq.dept\nThen try running the following git command to clear the proxy settings in your git config file:\ngit config --global --unset http.proxy\n\n\n\nCleaning up local branches\n\nEssentially this finds all merged (old) branches, makes sure to not include master or development (can rename or add more if appropriate) and then runs those branches through the delete command. To be safe, run the first two thirds first, to print out the list of what you’ll be deleting:\ngit branch --merged | egrep -v \"(^\\*|master|development)\"\nThen if you’re happy, run the whole line:\ngit branch --merged | egrep -v \"(^\\*|master|development)\" | xargs git branch -d\nThat should be all local branches tidied up. Now to complete the job you can prune the tracking branches you have set up, usually this will just be:\ngit remote prune origin\nThough you can use git remote -v to find other remotes if you have them.\n\n\n\nCreating PATs\n\nPATs or Personal access tokens, are a preferred way to authenticate into repositories through code. Creating a PAT in GitHub is relatively intuitive.\nIn Azure DevOps, you can do this by following Microsoft’s documentation on creating a PAT in Azure DevOps.\n\n\n\nStoring secure variables\n\n\nAzure DevOps\n\nIn Azure DevOps you can securely store variables that are then used by your pipelines by making use of variable groups.\nFirst create a variable group by navigating to Pipelines > Library. Enter any variables you want to store here and make sure to change the variable type to secret if appropriate (i.e. login credentials or PATs).\n\n\n\nThen, in the pipeline you want to use the variables in, go to Variables > Variable groups and link the variable group as shown below. You can then call upon the variables as needed in your pipeline.\n\n\n\n\n\n\nGitHub\n\nIn GitHub you can store sensitive variables as encrypted secrets.\n\n\n\n\nMirroring a repository\n\nThere may be times when you have a repository in one place, such as Azure DevOps, but want to mirror the code and any changes to it in another place, such as GitHub. This can be for many different reasons, though commonly for us it will be to open up our code across government. Azure DevOps doesn’t provide us with easily publicly visible code repositories, however GitHub does.\nTo mirror a code repository from Azure DevOps, use the mirror git repository extension (already installed on dfe-gov-uk instance), make use of the PAT and secure variables sections above and then add a job to your pipeline and enter your parameters in the fields as per the example below:\n\n\n\n\n\n\nFixing the “JSON token 4” error\n\nThis error can appear when you are trying to push changes to Azure DevOps.\nIf it appears and you have not changed your password recently, try locking your laptop and seeing if on re-login it prompts you for a password change.\nIf you have changed changed your password recently, try signing out of Azure and then back in again."
  },
  {
    "objectID": "learning-development/learning-development.html",
    "href": "learning-development/learning-development.html",
    "title": "Learning and Development",
    "section": "",
    "text": "A collection of useful learning resources, and information on resources to get you started\n\n\nAs statistics producers we require a variety of tools to be able to process our data. Below are the recommended tools that will give us the most power to do what we need. These have large user communities in DfE, and are already working in our current IT setup.\nFor best practice when using software and coding in our process, see our guidance on RAP the DfE Good Code Practice guide.\n\n\nGeneral resources\n\nGoogle is the single most powerful learning resource out there, whether it leads you to a Stack Overflow answer to your problem, or to an online training course, it will have your needs covered. We appreciate that it can be daunting and overwhelming at first though, which is why we’re pooling together links to particularly relevant resources on this page. Let us know if there’s any you’d like to see added!\n\nThe DfE Analytics Academy online R training course - walks you through how to get set up with R, as well as setting tasks using DfE data to learn fundamental skills in R.\nHow to QA - a general guide to quality assurance best practice in DfE.\nDfE Data Science resource tool - a bank of learning materials, from coffee and coding talks to online guidebooks.\nESFA guide to using R and Git - take you from the beginning, teaches you how to use RStudio and later on even includes some information on Shiny apps and more complex topics. For more information on RShiny apps, join the R Shiny Developers teams group.\nConnor Quinn’s resources for Data Engineering - for more advanced SQL and database resources this is a fantastic place to go.\nGeneral data science resources - includes plenty of open-source resources for R and SQL, with Python, Git, and shell included in there too.\nAwesome lists and awesome R - another great bank of learning resources.\nData Science week streams - a variety of talks across Data Science within the department.\nDfE Quality Assurance wiki - much of this is aimed at areas that use modelling, plenty of it is applicable to how we QA our data too.\nDavid Sands’ Boons of R and Git - a helpful guide o why R and Git are worth your time.\n\n\n\n\nSupport available\n\nThe Statistics Development Team invites teams to take part in our partnership programme. The programme can help individuals with:\n\nUsing a relevant project to develop new coding skills and improving current confidence\nStreamlining data production processes to free up time for secondary analysis\nImproving the presentation and consistency of statistical products for users\n\nThe partnership programme is a great opportunity to work with the Statistics Development Team, using protected time to work on things that are otherwise usually deprioritised. We understand the pressures of BAU work mean that development time is often hard fit in, but this programme offers designated support and clear project planning from our team so that these improvements can be achieved. Putting in the work at these early stages will save more time and resource in the long run, and we are keen to support as many teams as possible to free up time in the future for even more interesting analysis.\nThe Ask\nWe ask that you/a designated member of your team are given protected time to work on a specific project, with support from us. Some examples of previous projects we have helped support are:\n\nThe automation of the SEN2 release, creating automated QA reports and all EES outputs at the click of a button.\nThe automation of the HoP rolling brief document, removing arduous tasks like copying, pasting, and formatting in Word.\n\nThe time commitment of the programme will be dependent on the size of the work and what level of support is required. Please get in touch with us if you are interested and would like to discuss further.\n\n\n\nFurther information\n\nFor more information on how to use these tools in your production processes, please see the processes and RAP page.\nThis is by no means a finite list of resources, we want this to be added to and for it to develop over time - if you have any resources that you think could be added then we’d love to hear from you.\nIf you are stuck at all, have any questions, want to find a resource, or even just want a second pair of eyes to double check something, contact us using the envelope in the top right corner and we’ll be more than happy to help."
  },
  {
    "objectID": "learning-development/r.html",
    "href": "learning-development/r.html",
    "title": "R",
    "section": "",
    "text": "Guidance and tips for using the programming language R"
  },
  {
    "objectID": "learning-development/r.html#what-is-it",
    "href": "learning-development/r.html#what-is-it",
    "title": "R",
    "section": "What is it",
    "text": "What is it\n\nR is an open-source programming language specifically aimed at statisticians and data analysts."
  },
  {
    "objectID": "learning-development/r.html#what-is-it-for",
    "href": "learning-development/r.html#what-is-it-for",
    "title": "R",
    "section": "What is it for",
    "text": "What is it for\n\nR can be used for almost anything you can think of, notably data analysis, data visualisation, and creating reports and dashboards. It can also be used to extract data from SQL databases and run SQL queries."
  },
  {
    "objectID": "learning-development/r.html#how-to-get-it",
    "href": "learning-development/r.html#how-to-get-it",
    "title": "R",
    "section": "How to get it",
    "text": "How to get it\n\nDownload R (language) and RStudio (IDE) from the DfE software center. We also recommend that you download RTools (a helpful R extension) at the same time.\nThere are usually a couple of different versions available for software on the software center, we’d recommend you always go for the latest (newest) version possible."
  },
  {
    "objectID": "learning-development/r.html#best-places-to-start",
    "href": "learning-development/r.html#best-places-to-start",
    "title": "R",
    "section": "Best places to start",
    "text": "Best places to start\n\n\nThe DfE Analytics Academy host an online R training course. This is a great resource full of reproducible examples using DfE data. The course takes you through initially getting R downloaded, all the way through to developing apps in RShiny.\nThere is also the DfE R training guide, which is a great starting point and reference to guide you through how to get started using R and RStudio.\nAs an alternative, with a number of options for beginners to R, RStudio Education provide a variety of materials to suit different learning styles."
  },
  {
    "objectID": "learning-development/r.html#best-practice",
    "href": "learning-development/r.html#best-practice",
    "title": "R",
    "section": "Best practice",
    "text": "Best practice\n\nTips for reaching best practice in R can be found on our RAP page, with guidance on meeting best practice in RAP for clean final code. This makes it easier to read and pick up if another person is running your code."
  },
  {
    "objectID": "learning-development/r.html#how-to-work-with-r",
    "href": "learning-development/r.html#how-to-work-with-r",
    "title": "R",
    "section": "How to work with R",
    "text": "How to work with R\n\n\nR Projects\n\nWhenever you are using R, you should work in an RProject. This just makes sure you are set up in the correct working directory, so your code is pointing at the right folders and files.\nThis guide for using projects in R is a really useful article to help you set up a project.\nYou can check which project you are working in by looking in the top right hand corner of RStudio:\n\n\n\n\n\n\nOutlines\n\nIn RStudio you can greatly increase the navigability of your code by taking advantage of outlines. More information on folding and navigating outlines in RStudio can be found online, though when using rmarkdown reports, remember to use names first, such as ## Rows that aren't matching: r nrow(joined %>% filter(matching == FALSE)), rather than having the R code first, so that they are easy to discern in the outline.\n\n\n\nrenv\n\nYou should use the renv package for package and version control in R.\nPackages and versions of R regularly update. Over time, this can cause code to break - e.g. if different dependencies are required for later versions of packages to work. Using renv creates a “snapshot” of your code and packages at the time you created it, which anyone can then recreate when they come to use your code.\nThis is really important for reproducibility, and will help you meet elements of great practice with recyclable code for future use.\n\n\nrenv::restore()\n\nSometimes renv::restore() can fail, and when in specific renv-controlled projects install.packages() will fail saying that packages aren’t available even when they clearly are. There are a couple of workarounds we have found that get around this failure.\n\nConfiguring the proxy settings by running the below in R - this also helps if you are getting timeout issues when trying to webscrape with R:\n\nSys.setenv(no_proxy=\"*\") \n\n\nSpecifying the renv library as the install location. It’s a bit of a fudge, though these lines are helpful to get the packages from the renv lockfile installed and you running the project when needed:\n\nmyPath <- .libPaths()[1]\n\nforceInstall <- function(pkg, path) {\nmissing <- suppressWarnings(eval(parse(text= paste0(\"!require(\",pkg,\")\"))))\n\nif(missing == FALSE){\nmessage(pkg, \" is already installed.\")\n} else{\ninstall.packages(pkg, lib = path)\n}\n}\n\nforceInstall(\"jsonlite\", myPath)\n\nrenvPackages <- names(jsonlite::fromJSON(\"renv.lock\", flatten = TRUE)$Packages)\n\ninvisible(lapply(renvPackages, forceInstall, path = myPath))\nMore manual equivalent to use for specific packages:\n.libPaths() # note down output 1, and reuse in the lib argument of install.packages() as below\n\ninstall.packages(\"rmarkdown\", lib = \"C:/Users/swong/OneDrive - Department for Education/Documents/stats-production-guidance/renv/library/R-4.0/x86_64-w64-mingw32\")\n\n\n\n\nUpdating packages in renv\n\nTo update a single package run:\nrenv::update(\"dplyr\")\nTo update all packages run:\nrenv::update()\n\n\n\nInstalling old package versions in renv\n\nThis is surprisingly neat to do. Let’s say you wanted to roll back to version 1.0.2 of dplyr, you would run the following:\nrenv::install(\"dplyr@1.0.2\")"
  },
  {
    "objectID": "learning-development/r.html#quick-reference-lookup",
    "href": "learning-development/r.html#quick-reference-lookup",
    "title": "R",
    "section": "Quick reference lookup",
    "text": "Quick reference lookup\n\n\nIf you want a useful guide for R syntax or functions, then look no further than the R cheat sheets, these can be an invaluable point of reference. Below we’ve included a few particularly relevant ones:\n\nIntroduction to the RStudio environment\nBase R\nImporting data into R\ndplyr for data manipulation\nstringr for string manipulation\nRegex\nRMarkdown\nRShiny\nggplot2 for data visualisations\npurrr for applying functions"
  },
  {
    "objectID": "learning-development/r.html#other-resources",
    "href": "learning-development/r.html#other-resources",
    "title": "R",
    "section": "Other resources",
    "text": "Other resources\n\n\nHere is another free introduction to R course by Quantargo.\nR Markdown: The Definitive Guide, hopefully this one should be relatively self-explanatory!\nData science in education provides a heavily detailed guide for beginners in R learning to process data, with some well written out sections that may be of interest.\nHandy guide to collapsing and sectioning R code for easy navigation in RStudio.\nHere are 5 handy tidyverse functions that you should know if you’re using R to process data. Number two is especially useful for those processing wide data into a tidy format!\nMoJ have produced guidance on writing functions in R\nIf you’re wondering how best to make the jump to R from Excel and SQL, take a look at this coffee and coding presention by David Sands.\nMalcolm Barrett has done some slides on dplyr, ggplot2, and using purrr which may be useful if you’re looking at learning more about any of those packages.\nAlso check out the janitor package, it has some particularly powerful functions that are worth a look for tidying and QA’ing data."
  },
  {
    "objectID": "learning-development/r.html#excel-functions-in-r",
    "href": "learning-development/r.html#excel-functions-in-r",
    "title": "R",
    "section": "Excel functions in R",
    "text": "Excel functions in R\n\nR can do everything you do in excel, but takes out the human error. The reference table below shows how you would carry out popular Excel commands in R.\nR comes in with a built-in dataset called “iris”. We’ll use this for all examples so you can recreate them in your local area.\nREMEMBER: R is case sensitive, so all references to column names/entries need to be as-is in the dataset you are looking at. Functions exist that can translate all your columns to lower or snake case for ease!\n\n\n\n\n\n\n\n\nCommon Excel Task\nExample with iris \nHow to do in R with dplyr\n\n\n\n\nSelect specific columns\nSelect only species and petal length\niris %>% select(Species, Petal.Length)\n\n\nList unique entries in field (column)\nFind the unique entries for the “Species” column in iris\niris %>% select(Species) %>% distinct()\n\n\nFilter/select based on criteria\nFilter for sepal length >4 and sepal width <2.5, but NOT “versicolor” species\niris %>% filter(Sepal.Length > 4 &  Sepal.Width <2.5 & Species != \"versicolor\")\n\n\nFilter for multiple criteria in same column\nFilter for all “setosa” and “versicolor” species\niris %>% filter(Species %in% c(\"setosa\", \"versicolor\")\n\n\nIf else with OR\nCreate new column called “size_group” based on length or width of petal\niris %>% mutate(size_group =if_else( Petal.Length > 4 | Petal.Width >1.5, \"Large\", \"Small\"))\n\n\nMultiple if else\nCreate new column called “flower_price” based on species and petal length\niris %>%  mutate(flower_price = case_when(  Species == \"setosa\" & Petal.Length > 1.5 ~\"top band\",Species == \"versicolor\" & Petal.Length < 4 ~\"low_band\", TRUE ~ \"mid_band\"))\n\n\nCOUNTIF\nCount the number of species if they have a petal length >1.5\niris %>% filter(Petal.Length > 1.5 ) %>%group_by(Species) %>% count()\n\n\nSUMIF\nSum petal width of species if sepal width <3\niris %>% filter(Sepal.Width <3) %>%group_by(Species) %>%summarise(Petal.Width = sum(Petal.Width))\n\n\nVLOOKUP\nLookup to a table called “lookup”\niris %>%  left_join(lookup, by.x=\"Species\", by.y =\"plant_species\")\n\n\nOrder by\nOrder dataset by descending petal width\niris %>% arrange(desc(Petal.Width))\n\n\n\nMore tips for moving from using Excel to using R can be found in the excel-to-R wiki."
  },
  {
    "objectID": "learning-development/r.html#sql-functions-in-r",
    "href": "learning-development/r.html#sql-functions-in-r",
    "title": "R",
    "section": "SQL functions in R",
    "text": "SQL functions in R\n\nR can do a lot of the things that are possible in SQL. The reference table below shows how you would carry out some popular SQL commands in R.\nREMEMBER: R is case sensitive, so all references to column names/entries need to be as-is in the dataset you are looking at. Functions exist that can translate all your columns to lower or snake case for ease!\n\n\n\n\n\n\n\nCommon SQL Task\nHow to do in R (with dplyr)\n\n\n\n\nSELECT * FROM TABLE\ntable %>% select()\n\n\nSELECT ColA, ColB, ColC FROM TABLE\ntable %>% select(ColA, ColB, ColC)\n\n\nSELECT DISTINCT ColA FROM TABLE\ntable %>% select(ColA) %>% distinct()\n\n\nTABLE A LEFT JOIN (TABLE B) ON TABLEA.x = TABLEB.y\ntableA %>% left_join(TableB, by = c(x = y))\n\n\nCASE WHEN x = 1 THEN 1, WHEN x =2 THEN 2, ELSE 0 END AS New_column_name\n%>% mutate (New_column_name = case_when (x == 1 ~ 1, x == 2 ~ 2, TRUE ~ 0))\n\n\nCONCAT(LEA, ESTAB) AS LAESTAB\n%>% mutate(LAESTAB = paste0(LEA, ESTAB))\n\n\nSELECT COUNT(*) FROM TABLE\ntable %>% nrow()\n\n\nSELECT COUNT(ColA) FROM TABLE\ntable %>% count(colA)\n\n\nSELECT Date_column = CONVERT(DATE, Date_column) FROM TABLE\ntable %>% mutate(Date_column = as.Date(Date_column))\n\n\nSELECT Number_column = CONVERT(INT, Number_column ) FROM TABLE\ntable %>% mutate(Number_column = as.numeric(Number_column))\n\n\nSELECT String_column = CONVERT(VARCHAR, String_column ) FROM TABLE\ntable %>% mutate(String_column = as.character(String_column))\n\n\nDROP TableA\nrm(TableA)\n\n\n\nMore tips for moving from using SQL to using R can be found in the SQL-to-R wiki."
  },
  {
    "objectID": "learning-development/r.html#tips-for-using-r",
    "href": "learning-development/r.html#tips-for-using-r",
    "title": "R",
    "section": "Tips for using R",
    "text": "Tips for using R\n\nA selection of handy bits of code and workarounds for common issues. More useful code snippets can also be found in our github repo\n\n\nSpecifying a version of R to use\n\nThis can be done most easily by navigating in RStudio through Tools > Global options > General > Basic > R version (change). It’s likely you’ll need to restart RStudio for the changes to take affect.\n\n\n\n\n\n\n\nRounding\n\nThe base R function of round() rounds 5’s downwards. To round them upwards you can create a custom function like the one below:\nroundFiveUp <- function(x, n){ \n    z = abs(x)*10^n \n    z = z + 0.5 + sqrt(.Machine$double.eps) \n    z = trunc(z) \n    z = z/10^n \n    positiveNegative = sign(x) \n    return(z * positiveNegative) \n}\n\n\n\n\n\n\n\nPassing variables as arguments\n\nThis can be worked around by using a combination of eval() and parse(), as shown in the below function:\nshowFilterLevels <- function(data, meta) {\n  filters <- meta %>%\n    filter(col_type == \"Filter\") %>%\n    pull(col_name)\n\n  levelsTable <- function(filter) {\n    return(eval(parse(text = paste0(\"data %>% select(\", filter, \") %>% distinct()\"))))\n  }\n\n  output <- lapply(filters, levelsTable)\n\n  return(output)\n}\n\n\n\nReverse additive filters\n\nYou might want to filter your dataset based on multiple negative conditions. Normally to filter on multiple conditions, you would use filter(condition1 & condition2). The “filter” function does not work well with negative conditions (i.e. filtering for cases where condition 1 and condition 2 are not met). Instead, you can use subset(!(condition1 & condition2).\n\n\n\nFile locations\n\nStruggling to get files to talk to one another, or get code to find and use another R script? Use here::here() and marvel at it’s wondrous ability to magic away issues.\n\n\n\nInterweaving vectors\n\nThere’s an easy way to interweave multiple vectors into one single vector using c(rbind()). The example below shows two vectors, but you can have even more if you need.\n#Two vectors, x and y\nx <- 1:3\ny <- 4:6\n\n#Run code to interweave\nc(rbind(x, y))\n\n#Output below\n# [1] 1 4 2 5 3 6\n\n\n\nMaking charts interactive\n\nWhen pulling ggplot charts into RMarkdown reports, you can consider making them even more user-friendly and interactive with plotly. Further information on how to make your charts interactive with plotly can be found online.\n#Simple ggplot chart called \"p\"\np <- ggplot(dat, aes(x=xvar, y=yvar)) +\n    geom_point(shape=1)      # Use hollow circles\n\n#Apply ggplotly() to it to make it interactive\nfig <- ggplotly(p)\n\n\n\n\nReplace all values with another\n\nHave you ever needed to replace every value in your data with another? This can come in handy when you are looking at suppression, e.g. converting all NAs to “z” or all values under a certain threshold to “c”.\ndata %>% mutate_all(~ replace(., . == \"Value to replace\", \"Replacement\"))\n\n\n\n\nTemporary groups\n\nThe group_by() function in dplyr is really useful, but can be fiddly if you only want to use it for one operation in a chunk of code. The with_groups() function from dplyr lets you do this, saving you having to group and ungroup data each time.\ndata %>% mutate(annual_average = with_groups(time_period, mean))\n\n\n\n\nFinding package dependencies\n\nOften we’ll take chunks of code and reuse them for new projects. This can lead to building up a long list of packages to install, not all of which end up being used in your new code. The NCmisc package is a really handy way to check which packages and functions are used in your code.\nFirstly, load up all the packages the code has library() commands for, then run the following:\nlist.functions.in.file('your-filename-here.R', alphabetic = TRUE)\n\n\n\nVisualise dependencies\n\nThe depgraph package allows you to plot a graph of all the dependencies in your R project, which can be a useful tool to help you cut down on the number of package dependencies. Briefly, in these graphs you can look for “hot spots” in the network (big bright dots), which represent packages that have many upstream dependencies but are potentially easy to remove because they have few downstream dependencies (that is, only your package depends on them).\nplot_dependency_graph(\n  pkg = multibridge_pkg\n  , suggests = FALSE\n  , option = \"cividis\"\n)\n\n\n\n\nReproducible random numbers\n\nThe set.seed() function generates a sequence of random numbers, starting from the value you define in the brackets. This ensures you get the same sequence of random numbers each time you run set.seed() with the same value, which is helpful to test that your results are reproducible.\n# random sampling\n> sample(LETTERS, 5)\n[1] \"K\" \"N\" \"R\" \"Z\" \"G\"\n> sample(LETTERS, 5)\n[1] \"L\" \"P\" \"J\" \"E\" \"D\"\n\n# reproducible random sampling\n> set.seed(42); sample(LETTERS, 5)\n[1] \"Q\" \"E\" \"A\" \"J\" \"D\"\n> set.seed(42); sample(LETTERS, 5)\n[1] \"Q\" \"E\" \"A\" \"J\" \"D\"\n\n\n\n\nAutomatic logging\n\nThe tidylog package is a really useful tool for providing automated feedback on dplyr and tidyr operations.\nlibrary(tidylog)\n\nfiltered <- filter(mtcars, cyl == 4)\n#> filter: removed 21 rows (66%), 11 rows remaining\nmutated <- mutate(mtcars, new_var = wt ** 2)\n#> mutate: new variable 'new_var' (double) with 29 unique values and 0% NA\n\n\n\nRunning SQL scripts from R\n\nR can be used to execute SQL scripts to extract data from a database as well as querying the database directly via R. For using R to execute a SQL script you’ll need the SQL script/s to be in your R Project and to make a connection via R to the database.\n# Library calls ====\n\nlibrary(odbc)\nlibrary(DBI)\n\n# DB connection ====\n\ncon <- DBI::dbConnect(odbc::odbc(),\n                      Driver = \"ODBC Driver 17 for SQL Server\",\n                      Server = \"server_name\",\n                      Database = \"database_name\",\n                      UID = \"\",\n                      PWD = \"\",\n                      Trusted_Connection = \"Yes\"\n)\n\n# Function to read in sql scripts ====\n\ngetSQL <- function(filepath){\n  con = file(filepath, \"r\")\n  sql.string <- \"\"\n  \n  while (TRUE){\n    line <- readLines(con, n = 1)\n    \n    if ( length(line) == 0 ){\n      break\n    }\n    \n    line <- gsub(\"\\\\t\", \" \", line)\n    \n    if(grepl(\"--\",line) == TRUE){\n      line <- paste(sub(\"--\",\"/*\",line),\"*/\")\n    }\n    \n    sql.string <- paste(sql.string, line)\n  }\n  \n  close(con)\n  return(sql.string)\n}\n\n# Execute SQL query and pull into R ====\n\nmy_table <- dbGetQuery(con, getSQL(\"my_query_script.sql\"))\n\nIf you’re struggling to get your SQL scripts to execute from R, try adding the following two lines to the top of your SQL script to force the formatting required for it to work:\nSET ANSI_PADDING OFF\nSET NOCOUNT ON;\n\n\n\nCan’t find make error\n\n\nThis error is usually due to Rtools not being properly installed, this has become fairly common since it has been dropped from the software centre. There have been several requests to read it, though as of yet none have succeeded. For now there’s a workaround to this.\nYou can install Rtools as a direct download from CRAN. On there, pick the right version of RTools for your version of R, download the file and install.\n\nWhen downloading RTools you may need to confirm that you understand the risks of downloading an .exe file from an unknown source, this is common, as this is a trusted source, you can click accept.\nWhen running the .exe file, Windows Defender may step in and act like it’s not going to let you progress any further. If this happens you’ll need to click “More info” and only then can you select something like “install anyway”.\n\nSet the install location to C:\\rtools40 (it is often this by default)\nNext you need to add it to the PATH variable. We can’t edit this without an admin password, though you can temporarily set it to allow you to restore from renv, by doing it from within the R console.\n\nThis only sets it temporarily for as long as the R session is running, you’ll need to rerun each time you’re in an R session and need it.\n\n\nold_path <- Sys.getenv(“PATH”) Sys.setenv(PATH = paste(old_path, “C:\\rtools40\\usr\\bin”, sep = “;”)) Sys.getenv(“PATH”)"
  },
  {
    "objectID": "learning-development/sql.html",
    "href": "learning-development/sql.html",
    "title": "SQL",
    "section": "",
    "text": "Guidance and tips for accessing data via databases with SQL"
  },
  {
    "objectID": "learning-development/sql.html#what-is-it",
    "href": "learning-development/sql.html#what-is-it",
    "title": "SQL",
    "section": "What is it",
    "text": "What is it\n\nSQL or Structured Query Language, is a programming language used to talk to relational database management systems."
  },
  {
    "objectID": "learning-development/sql.html#what-is-it-for",
    "href": "learning-development/sql.html#what-is-it-for",
    "title": "SQL",
    "section": "What is it for",
    "text": "What is it for\n\nSQL servers are where most of DfE’s data is held, making it ideal for database management.\nSQL provides us with a language primarily for querying databases to extract data, though it is also capable of some basic data processing and analysis."
  },
  {
    "objectID": "learning-development/sql.html#how-to-get-it",
    "href": "learning-development/sql.html#how-to-get-it",
    "title": "SQL",
    "section": "How to get it",
    "text": "How to get it\n\nDownload SSMS from the DfE software center, talk to your team about getting access to the appropriate SQL servers and databases where the data you need to access is held and start writing SQL queries.\nThere are usually a couple of different versions available for software on the software center, we’d recommend you always go for the latest (newest) version possible."
  },
  {
    "objectID": "learning-development/sql.html#best-place-to-start",
    "href": "learning-development/sql.html#best-place-to-start",
    "title": "SQL",
    "section": "Best place to start",
    "text": "Best place to start\n\nAndy Brook’s excellent Introduction to SQL session, giving a visual overview of the basics of querying with SQL:"
  },
  {
    "objectID": "learning-development/sql.html#best-practice",
    "href": "learning-development/sql.html#best-practice",
    "title": "SQL",
    "section": "Best practice",
    "text": "Best practice\n\nHere are some tips to follow best practice in your SQL code, making it easier to read and pick up if another person is running your code. Following best practice guidance will help you to achieve RAP best practice with clean final code\n\nAvoid any trailing whitespace\nAlways capitalize SQL keywords (e.g., SELECT or AS)\nVariable names should be in snake case - lower case words separated by underscores (e.g. pupil_age instead of PupilAge)\nComments should go near the top of your query, or at least near the closest SELECT\nTry to only comment on things that aren’t obvious about the query (e.g. why hardcoded filters are used, how to update them)\nWhere possible, use Common Table Expressions (CTEs) early and often, and name them descriptively (e.g. “pupil_age_table” rather than “p”)"
  },
  {
    "objectID": "learning-development/sql.html#how-to-work-with-sql",
    "href": "learning-development/sql.html#how-to-work-with-sql",
    "title": "SQL",
    "section": "How to work with SQL",
    "text": "How to work with SQL\n\nSSMS is the best tool to get started with writing SQL queries and saving SQL scripts that produce your desired outputs.\nOnce you have saved SQL scripts or are more familiar with writing SQL queries on the fly, you can look at running your scripts or lines of SQL code directly in R. This will streamline your process, saving copying and pasting SQL outputs into csvs, and ultimately help with reaching RAP best practice by aiding production of a single publication production script"
  },
  {
    "objectID": "learning-development/sql.html#quick-reference-lookup",
    "href": "learning-development/sql.html#quick-reference-lookup",
    "title": "SQL",
    "section": "Quick reference lookup",
    "text": "Quick reference lookup\n\n\nw3schools.com offers a useful guide through the most common SQL commands."
  },
  {
    "objectID": "learning-development/sql.html#other-resources",
    "href": "learning-development/sql.html#other-resources",
    "title": "SQL",
    "section": "Other resources",
    "text": "Other resources\n\n\nThis tutorial script by Tom Franklin is a particularly good starting point as it includes the data you are manipulating, so you don’t need to worry about connecting to or getting access to specific databases before you can then run anything. Simply open up Microsoft SQL Server Management Studio and start playing with that query.\nAvision Ho created the this SQL training course.\nThe Khan academy offers a great free introduction to the basics of SQL.\nIt’s also worth taking a look at Jon Holman’s presentation on ‘good to know’ SQL functions.\nMoJ have produced a SQL from square one guide to using CTE’s in SQL as well as running SQL from RStudio\n\nAndy’s follow up intermediate SQL session, covering more advanced features of SQL:"
  },
  {
    "objectID": "learning-development/sql.html#tips-for-using-sql",
    "href": "learning-development/sql.html#tips-for-using-sql",
    "title": "SQL",
    "section": "Tips for using SQL",
    "text": "Tips for using SQL\n\n\nSetting up a SQL area\n\nBefore you set up a SQL database, make sure you have the following information to pass on:\n\nThe name of the database you want to set up - Different servers will have different naming conventions, make sure to check this with the server owner before you confirm the name.\nWho the database owners should be - This will most likely be yourself, but you can have multiple (e.g. your team leader). It can be helpful to have more than one owner, so one can grant permissions when the other is unavailable.\nWho should have access, and what their access levels should be - Users can have read or read/write access. Make sure you have a list of users (with their AD names) and their access levels ready.\nThe database structure - Do you need certain schemas setting up? This will help organise your database. Without schemas, all tables will be saved under [dbo].\n\nThere are a few common servers that statistics producers make use of at DfE. Use the following contacts below to pass on the above information to get your new database set up:\n\nPDR (T1PRMDRSQL,55842) - contact the PDR team\nPDB16 (3DCPRI-PDB16) - raise a request through the service desk under “non-standard” > “any other request”\nAnalyse & Modelling server (T1PRANMSQL,60125) - raise a request on the service desk under the following options:\n\n\n\n\n\n\n\nGiving/getting access\n\nTo gain access to a SQL database, you must have written confirmation from the database owner specifying whether your access is read-only or both read and write.\nIf the area you require access to is in the T1PRMDRSQL,55842 SQL server, contact the PDR team with your permission attached, stating the name of the database you want access to.\nIf the area is in any other server, raise a request through the central IT service portal under “non-standard” > “any other request”. In your request make sure you attach the written confirmation and specify:\n\nThe server name\nThe database name\nWhether it’s read or write access you need\n\n\n\n\nMoving data to different areas\n\nInformation on how to do this in R can be found in our processes and RAP page"
  },
  {
    "objectID": "creating-statistics/ud.html",
    "href": "creating-statistics/ud.html",
    "title": "Open Data Standards",
    "section": "",
    "text": "Guidance on how to structure data files"
  },
  {
    "objectID": "creating-statistics/ud.html#how-to-check-against-these-standards",
    "href": "creating-statistics/ud.html#how-to-check-against-these-standards",
    "title": "Open Data Standards",
    "section": "How to check against these standards",
    "text": "How to check against these standards\n\nAn interactive shiny app has been developed to automate checks against the standards as a final stage of automated quality assurance before upload to EES.\nThis can be run on any data file, though requires the EES metadata to be able to process the file. The app runs on our rsconnect servers, and is only available when using DfE kit. The app is mostly self-explanatory, though if you have any questions about it, or are curious to know more about how it works, the code is available on GitHub, and you can get in touch with us at statistics.development@education.gov.uk.\n\nAll data and EES metadata files must be run through the screening app before uploading to EES.\n\n\n\n“Tidy datasets are all alike but every messy dataset is messy in its own way.” – Hadley Wickham"
  },
  {
    "objectID": "creating-statistics/ud.html#overview-of-ees-data-files",
    "href": "creating-statistics/ud.html#overview-of-ees-data-files",
    "title": "Open Data Standards",
    "section": "Overview of EES data files",
    "text": "Overview of EES data files\n\nFor data to be used with the table tool and charts in EES, it needs to be provided to the following overall specifications:\n\nThe data should be contained in a text file with comma separated values and with the extension .csv.\nThe first row of the data file should contain machine readable column names in snake case.\nThe data should be layed out in line with tidy data principles, consisting of filters (categories) and indicators (values).\nThe file should contain the necessary mandatory columns (i.e. time_period, time_identifier, geographical_level, country_code and country_name);\nThe data file should have an accompanying meta-data csv file, which contains information on the nature of the columns in the data file:\n\nwhether a given column is a filter or indicator;\nhuman readable name for use in tables and charts on EES;\nfilter grouping information;\nnumber of decimal places to display for indicator fields (i.e. allowing a lower precision to be presented in the dervied tables than the underlying data - useful for minimising rounding errors in aggregates);\nunits for indicator fields (e.g. £, %);\n\nThe data should use the appropriate GSS codes for suppressed, low, not available and not applicable entries.\n\nAn example pair of data and meta-data files are illustrated in the files and tables below.\n\n\nExample data file (ees_demo_datafile.csv)\n\n\nNote that the mandatory columns time_identifier, geographic_level and country_code are abridged in the table below to help with displaying in a web page, but are shown in the example file at the link above.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntime_period\n…\ncountry_name\nregion_code\nregion_name\ngender\nschool_phase\nnumber_children\npercent_children\n\n\n\n\n202021\n…\nEngland\n\n\nTotal\nTotal\n1000\n100.000\n\n\n202021\n…\nEngland\n\n\nMale\nTotal\n490\n49.000\n\n\n202021\n…\nEngland\n\n\nFemale\nTotal\n510\n51.000\n\n\n202021\n…\nEngland\n\n\nTotal\nPrimary\n250\n100.000\n\n\n202021\n…\nEngland\n\n\nMale\nPrimary\n131\n52.400\n\n\n202021\n…\nEngland\n\n\nFemale\nPrimary\n119\n47.600\n\n\n202021\n…\nEngland\nE12000001\nNorth East\nTotal\nTotal\n100\n100.000\n\n\n202021\n…\nEngland\nE12000001\nNorth East\nMale\nTotal\n32\n32.000\n\n\n202021\n…\nEngland\nE12000001\nNorth East\nFemale\nTotal\n64\n64.000\n\n\n202021\n…\nEngland\nE12000001\nNorth East\nTotal\nPrimary\n43\n100.000\n\n\n202021\n…\nEngland\nE12000001\nNorth East\nMale\nPrimary\n12\n27.907\n\n\n202021\n…\nEngland\nE12000001\nNorth East\nFemale\nPrimary\n31\n72.093\n\n\n201920\n…\nEngland\n\n\nTotal\nTotal\n956\n100.000\n\n\n201920\n…\nEngland\n\n\nMale\nTotal\n444\n46.444\n\n\n201920\n…\nEngland\n\n\nFemale\nTotal\n512\n53.556\n\n\n\n\n\n\nExample meta-data file (ees_demo_datafile.meta.csv)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncol_name\ncol_type\nlabel\nindicator_grouping\nindicator_unit\nindicator_dp\nfilter_hint\nfilter_grouping_column\n\n\n\n\ngender\nFilter\nGender\n\n\n\nFilter by pupil gender\n\n\n\nschool_phase\nFilter\nSchool phase\n\n\n\nFilter by the phase of the school\n\n\n\nnumber_children\nIndicator\nNumber of children\n\n\n\n\n\n\n\npercent_children\nIndicator\nPercentage of children\n\n%\n1\n\n\n\n\n\n\nNote that for the percent_children column, the underlying data is provided to 3 d.p., but the meta data constrains it to 1 d.p. This means that figures in tables in the publication will be presented to 1 d.p., but users will have access to the higher accuracy in the underlying data. As well as allowing EES to meet different users’ needs, this also helps lower the risk of rounding errors in the underlying data creating unwanted behaviour in charts in EES.\n\nFurther information on all of the requirements for appropriately prepared data files follow in the sections below.\nOnce you have prepared a draft data file, you should always run the file through our EES data file screener. This will check for common issues that may prevent the file from being used appropriately by EES. Note that some issues may not prevent your file from uploading to EES, but would still cause undesired behaviour once on the platform, so it is imperative to screen data files before uploading."
  },
  {
    "objectID": "creating-statistics/ud.html#tidy-data-structure",
    "href": "creating-statistics/ud.html#tidy-data-structure",
    "title": "Open Data Standards",
    "section": "Tidy data structure",
    "text": "Tidy data structure\n\nThe move to the new platform provided the ideal opportunity to standardise and ‘tidy’ up our data to give users the consistency that they ask for. Our standards draw upon the ideas of tidy data - this means applying a logical structure to datasets so they are easier to use and analyse, minimising the time spent cleaning the data before use.\nHere is a quick summary video of what exactly tidy data is.\n\n\n\n\n\nFurther details on tidy data, can be found by reading Hadley Wickham’s academic paper on Tidy Data. The key principles to remember are:\n\nEach variable forms a separate column.\nEach observation forms a separate row.\n\nThe variables (columns) in each of the uploaded data files will fall in to the following two categories: filters and indicators.\n\nIntroduction to indicators\nIndicators are the measureables in any data set. They should be grouped based on the type of measurement, with a column for each different type of measurement. For example, Number of pupils and Percentage of pupils would be two disticnt indicator columns in a data file.\nMore details on indicators in the EES context are provided in the Indicators section below.\n\n\nIntroduction to filters\nA single filter column should contain all the possible filter values for a single data-sub-aggregation. For example, many publications would have an ethnicity_major column containing all the major ethnic breakdowns contained in the data or an fsm column containing the entries FSM and non-FSM.\nIn general, analysts should use a separate column for each filter in accordance with tidy data principles. This is especially the case where data are presented for combinations of filters (i.e. cross tabulations). User testing has shown this to be the most effective way to structure data for the best user experience with the table tool.\n\n\n\n…\nFSM\nSex\nnumber_pupils\n\n\n\n\n…\nTotal\nTotal\n1209\n\n\n…\nTotal\nFemale\n567\n\n\n…\nTotal\nMale\n642\n\n\n…\nFSM\nTotal\n406\n\n\n…\nFSM\nFemale\n203\n\n\n…\nFSM\nMale\n203\n\n\n…\nnon-FSM\nTotal\n803\n\n\n…\nnon-FSM\nFemale\n364\n\n\n…\nnon-FSM\nMale\n439\n\n\n\nWhere data is broken down across combinations of different filters, teams should aim to “complete the matrix”. This means that, for the given filters, all possible filter combinations should have a corresponding data entry. In this way, teams can prevent users getting the ambiguous “No data” result from EES and can instead provide more explicit codes for any missing data (e.g. not applicable, not available, suppressed, etc)\nA possible exception to the above structure is where no filter combinations/cross-tabulations are present in a given data file. For example, this may be the case if a publication requires a highlights level table that shows a result across breakdowns of sex (Male, Female, etc) and Free School Meal status (FSM, non-FSM), but not combinations of the two (Female and FSM, Male and FSM, Female and non-FSM and Male and non-FSM). In this case, analysts may choose to use a overarching collated filter columns named breakdown_topic and breakdown as follows:\n\n\n\n…\nbreakdown_topic\nbreakdown\nnumber_pupils\n\n\n\n\n…\nTotal\nTotal\n1209\n\n\n…\nSex\nFemale\n567\n\n\n…\nSex\nMale\n642\n\n\n…\nFSM\nFSM\n406\n\n\n…\nFSM\nnon-FSM\n803\n\n\n\nWith the above structure, breakdown_topic should be added as the fitler_grouping_column for breakdown in the associated meta data file (and therefore should not have its own row in the meta data).\nTo re-iterate, teams should not use the above format when filter combinations/cross-tabulations are present in the data file they are producing, so breakdown_topic and breakdown should not contain entries such as “Sex and FSM” or “Female and FSM” respectively.\nFilters come in two types: standard filters and additional filters.\nThe standard filters encompass time and geography elements (e.g. time_period, geographic_level, la_code). Specific combinations of these standard filters must be present in your data files and the contents of these filters are required to meet specific standards in order for a data file to be compatible with the table tool in EES.\nAdditional filters are the release specific characteristics that we filter our data on, e.g. school types, learner characteristics, grade thresholds, etc. Some of these filters have recommended column names and entries in order to support consistency in data files across publications. For example ethnicities should have column names of ethnicity_major, ethnicity_minor or minority_ethnic and contents should be limited to the GSS standards. Such guidelines are outlined in the Common harmonised variables section of this page, whilst further information on fiters in the EES context is given in the Filters section below.\n\n\nOptimising filter-indicator combinations\nThe policy of creating tidy data files effectively means optimising your filter-indicator combinations for use within the EES user interface. By doing so, end users will be better able to interact with your data and find the information that they’re looking for.\nThe number of indicators should be kept to a minimum, whilst maintaining different types of measurements as distinct indicators. For example a wide structure might consist of something like the following:\n\n\n\n\n\n\n\n\n\n\n…\nnumber_pupils_passing_95\nnumber_pupils_passing_94\npercentage_pupils_passing_95\npercentage_pupils_passing_94\n\n\n\n\n…\n567\n642\n45.7\n51.8\n\n\n\nCreating a tidy form of this data would look something more like this:\n\n\n\n\n\n\n\n\n\n…\ngrade_range\nnumber_pupils\npercentage_pupils\n\n\n\n\n…\n9 to 5\n567\n45.7\n\n\n…\n9 to 4\n642\n51.8\n\n\n\nThis is a simplified example and your data will likely be more complex, but in making this type of change, you may be able to better identify more optimal ways of organising your data. For example, if you find that restructuring like this creates a lot of empty cells, it may be that the data has incompatible filters and can be separated out into multiple data files."
  },
  {
    "objectID": "creating-statistics/ud.html#data-format",
    "href": "creating-statistics/ud.html#data-format",
    "title": "Open Data Standards",
    "section": "Data format",
    "text": "Data format\n\nThese standards give you the power to format the data in a way that best meets the needs of the users. There are only a handful of formatting standards to follow to ensure best practice and consistency across all of our data.\n\nData files must in comma separated values (.csv) format, and use UTF-8 encoding. You can specify this when saving the file in Excel, or exporting from elsewhere.\n\nIf you need to use commas within a cell, then you must add a text delimiter such as quotes to your file to define each cell - this is often done automatically for you, though if you’re unsure then you can open up your csv file in a text editor such as notepad to check.\nYou should also ensure that your data follows the GSS Standards on symbols, though be aware to ignore the ask that symbols are included in separate cells from the data, which is unpractical and unrealistic.\n\n\nFile names\n\nFile names should only include numbers, letters, underscores or hyphens. Special characters must be avoided; for example, the following characters \\ / : * ? \" < > | [ ] & $ , . + are all considered special characters and are used for specific tasks in an electronic environment, which can lead to confusion in some systems. The use of non-English language letters such as á, í, ñ, è, and õ, should also be avoided.\nFile name should ideally be no more than 35-50 characters, file names that try to give too much information end up having the reverse affect and users skim over and get less value than from a more concise name. File names that extend beyond 200 characters will likely cause issues for users using the files in other programs.\nThe metadata file should have exactly the same name as the data file, with a suffix of ‘.meta’. E.g. mydatafile.csv and mydatafile.meta.csv.\nYou should avoid references to time periods in the file name as this information is shown elsewhere and this can make it harder for users to make use of the newer versions of files in future years. File names should be recyclable year on year.\nIn general you should avoid including the geographic level in the file name, unless it is a file that is specifically different (e.g. a file for school level data only).\n\nFor use with EES all file names should be in lower case and avoid special characters or spaces. Any upper case characters in file names will be forced to lower case by EES, and will appear as lower case to the users.\n\n\n\n\nVariable names\n\nVariable names must be in the first row of your file as the header row, must not include spaces, and ideally be formatted in snake_case for ease of use.\nAvoid starting variable names with a numeric character.\nAs with file names, you should avoid any special characters; for example, the following characters \\ / : * ? \" < > | [ ] & $ , . + are all considered special characters and are used for specific tasks in an electronic environment, which can lead to confusion in some systems. The use of non-English language letters such as á, í, ñ, è, and õ, should also be avoided.\nVariable names should ideally be kept below 25-35 characters as long names are often cut off when viewing the data file and generally fail to get the information required across to users. It is a balance between giving enough information so it’s clear what it refers to and giving so much that it’s unhelpful. Remember to make use of your public data guidance and methodology for expanding on details.\n\n\n\nHow to export data with UTF-8 encoding\n\nMost of the time our data is exported as a .csv file it will have UTF-8 encoding by default. However, there are times when this isn’t the case, and therefore we’ll quickly run through how to check this below in each of Excel, SQL, and R.\nExcel\nExcel tends to save all .csv files as UTF-8, however this is not always the case, particularly if there are symbols in the file (such as £). To ensure that it saves with UTF-8 encoding you can select the following when saving a file:\nFile > Save As > CSV UTF-8 (Comma delimited) (*.csv)\nSQL\nFor saving results out of SQL as a .csv file there isn’t an option to specify the encoding, therefore the best bet is to either open the file in Excel and specify that as above, or to run your SQL query/read your data into R and follow the guidance below.\nR\nWhen writing .csv files out of R, you’ll mostly likely be using either write.csv() from base R, or write_csv() from the readr package. For the first one, you can specify encoding using encoding = like the following example:\nwrite.csv(my_data, file = \"my_data_file.csv\", encoding = \"UTF-8\")\nFor write_csv(), which some of you may be using for increased processing speed, the function automatically encodes as UTF-8 format, meaning that you don’t have to do anything different!"
  },
  {
    "objectID": "creating-statistics/ud.html#how-much-data-to-publish",
    "href": "creating-statistics/ud.html#how-much-data-to-publish",
    "title": "Open Data Standards",
    "section": "How much data to publish",
    "text": "How much data to publish\n\nYou should publish as many years of data that you have and is practicable.\nIf you are not providing a full timeseries for any reason, you must link to the older published data from your publication release page, and make sure that it’s omission is explained in your methodology and metadata documents."
  },
  {
    "objectID": "creating-statistics/ud.html#deciding-what-should-be-in-a-file",
    "href": "creating-statistics/ud.html#deciding-what-should-be-in-a-file",
    "title": "Open Data Standards",
    "section": "Deciding what should be in a file",
    "text": "Deciding what should be in a file\n\nExplore Education Statistics is designed to give production teams the freedom of controlling what data users can access, and how they access it. It is expected that most releases on the platform will have multiple data files, and teams have control over how they break these files up.\nThe first key consideration is that the table tool will only create tables from a single a data file, and cannot use multiple files as sources. Therefore any data that you want to compare within a single table must in the same data file. The table tool itself is there to allow users to narrow down the amount of data they have to absorb and to be able to efficiently take away key statistics.\nA useful way to judge how to break up data files is to consider whether all of the data in the file is appropriate to show side-by-side in the same table. If there are data that are conceptually different or may be confusing to compare side by side, then these should be in separate data files. Any data file uploaded to EES is usable by all users in the table tool, and users will be able to download the exact same files as you upload.\nWe generally recommend fewer large files over a larger number of smaller files. If you think you are having issues with file size please tell us so that we can investigate and work towards a solution with you."
  },
  {
    "objectID": "creating-statistics/ud.html#file-size",
    "href": "creating-statistics/ud.html#file-size",
    "title": "Open Data Standards",
    "section": "File size",
    "text": "File size\n\nThere are no character or size limits in a csv file and there is no size limit for EES, though the larger a file is, the longer it will take to upload and process. Also remember that the files you upload are the files that users will download, consider the software they may access to (e.g. Excel) and whether the size of your files are compatible with this.\nExcel has a cell character limit of 32,760 and a row limit of 1,048,576. It is best to avoid exceeding these as some end users may struggle to open the file. One good way to cut the file down is to split after a certain number of years, or to separate out different geographic levels into separate files, providing school level data as a separate file for example. With the data all being in a tidy format these are then easy enough for secondary analysts to stitch back together if needed.\nA rough guide to file size would be:\n\nAnything under 10mb is relatively small\n10mb to 100mb is a fairly common file size that most teams have\n100mb to 500mb is a large file and will struggle to upload if not compressed to a zip folder.\n500mb and over are very large, and sometimes may struggle to compress small enough to upload.\n1gb or more in size is larger than any we have seen before and will likely need testing in the platform first.\n\nContact us if you have any issues, or files that might be over 1gb."
  },
  {
    "objectID": "creating-statistics/ud.html#data-symbols",
    "href": "creating-statistics/ud.html#data-symbols",
    "title": "Open Data Standards",
    "section": "Data symbols",
    "text": "Data symbols\n\nIn line with the GSS guidance on symbols, special values should be replaced with symbols in the following situations:\n\n\n\n\n\n\n\n\n\nSymbol\nUsage\nExample\nObsolete equivalents\n\n\n\n\nz\nWhen an observation is not applicable\nNo data for at gender level for boys at an all-girls school\n\n\n\nx\nWhen data is unavailable for other reasons\nData for an indicator is not collected in a certain region\n:\n\n\nc\nConfidential data\nData has been suppressed\n\n\n\nlow\nRounds to 0, but is not 0\nRounding to the nearest thousand, 499 would otherwise show as 0. Only use 0 for true 0’s\n~\n\n\nu\nWhen an observation is of low reliability\nData for a local authority is identified as missing returns so is removed from regional and national totals\n\n\n\n\nIf you have any other conventions you’ve used in previous publications, or a scenario that isn’t covered above, check the GSS guidance (ignoring the part around separate columns for symbols), and contact us."
  },
  {
    "objectID": "creating-statistics/ud.html#mandatory-ees-metadata-columns",
    "href": "creating-statistics/ud.html#mandatory-ees-metadata-columns",
    "title": "Open Data Standards",
    "section": "Mandatory EES metadata columns",
    "text": "Mandatory EES metadata columns\n\n\n\n\n\n\n\n\ncolumn\ndetails\n\n\n\n\ncol_name\nThis must exactly match the name of the corresponding column in the dataset.\n\n\ncol_type\nThis must be either ‘Filter’ or ‘Indicator’.\n\n\nlabel\nThis is the version of the column name that the users will see on the platform, therefore you must fill this in and not leave it blank. For example, pupil_headcount may be ‘Number of pupil enrolments’. You should aim to keep these short and descriptive, but have the freedom to decide what is best to do for your users.\n\n\nindicator_grouping\nThis column gives production teams the option to add subheadings to group indicators in order to benefit the user. If this column is left blank, all indicators will be presented as one list of individual square radio boxes with no subheadings.\n\n\nindicator_unit\nIf this column is left blank then this will be a number by default, alternatively you can use either of the following units for financial or percentage measures - “£”, “£m”, “%”, “pp”.\n\n\nindicator_dp\nThis column allows you to set decimal place formatting for each of your indicators. If you leave it blank the platform will default to 2 d.p\n\n\nfilter_hint\nThis column gives you the option to add in a hint such as ‘Filter by school type’ for the filter to make the service easier for the users to navigate. If you leave the column blank, no hint will appear. Do not duplicate the column name here, as it will just appear twice\n\n\nfilter_grouping_column\nThis column should be blank unless you are wanting to group your filters. When you are wanting to group your filters this column should contain the exact name of the column/variable that you wish to group by. It is good practice to use the same variable name as that you are grouping, with _group appended at the end, i.e. ‘filter’ and ‘filter_group’\n\n\n\nNote that if you are using percentage points (pp) you must include a clear explanation in your release and methodology, so that users can understand what you are referring to."
  },
  {
    "objectID": "creating-statistics/ud.html#example-ees-metadata",
    "href": "creating-statistics/ud.html#example-ees-metadata",
    "title": "Open Data Standards",
    "section": "Example EES metadata",
    "text": "Example EES metadata\n\n\nEach row represents a corresponding column in the data file.\n\n\n\n\n\n\n\n\n\n\n\n\ncol_name\ncol_type\nlabel\nindicator_grouping\nindicator_unit\nindicator_dp\nfilter_hint\nfilter_grouping_column\n\n\n\n\ngender\nFilter\nGender\n\n\n\nFilter by pupil gender\n\n\n\nschool_phase\nFilter\nSchool phase\n\n\n\nFilter by the phase of the school\n\n\n\nnumber_children\nIndicator\nNumber of children\n\n\n\n\n\n\n\npercent_children\nIndicator\nPercentage of children\n\n%\n1\n\n\n\n\n\n\n\nThe corresponding data file.\n\n\n\n\n\n\n\n\n\n\n\ntime_period\n…\ncountry_name\ngender\nschool_phase\nnumber_children\npercent_children\n\n\n\n\n2018\n…\nEngland\nMale\nPrimary\n240\n26.7\n\n\n2018\n…\nEngland\nFemale\nPrimary\n200\n22.2\n\n\n2018\n…\nEngland\nTotal\nPrimary\n440\n48.9\n\n\n2018\n…\nEngland\nMale\nSecondary\n240\n26.7\n\n\n2018\n…\nEngland\nFemale\nSecondary\n220\n24.4\n\n\n2018\n…\nEngland\nTotal\nSecondary\n460\n51.1\n\n\n2018\n…\nEngland\nMale\nTotal\n480\n53.3\n\n\n2018\n…\nEngland\nFemale\nTotal\n420\n46.7\n\n\n2018\n…\nEngland\nTotal\nTotal\n900\n100.0"
  },
  {
    "objectID": "creating-statistics/ud.html#time-columns",
    "href": "creating-statistics/ud.html#time-columns",
    "title": "Open Data Standards",
    "section": "Time columns",
    "text": "Time columns\n\nWe use the two columns, time_period and time_identifier, to generalise time across our underlying datasets. All data files must contain these. This is a important for general useability of our data, as well as being critical in driving the charts and tables in the Explore Education Statistics platform and making explicit reference to the time in which our measurements relate to. This is a compulsory element of any official statistics dataset.\nIf you think that your data can’t follow this format, please contact statistics.development@education.gov.uk with details so that we can discuss this.\n\ntime_period must contain either a four digit year, or a 6 digit year.\ntime_period must be numeric. This allows the platform to understand ranges and order periods in a logical manner.\nsix digit time_periods must represent consecutive years - e.g. 201718, not 201619.\nIf you’re referring to a single term you should use the academic year not the calendar year in the time_period column.\nConceptually different years cannot be mixed in the same dataset.\nConceptually different year breakdowns (e.g. term, quarter, month), can be mixed with a full year of the same type using a filter column.\n\n\n\nSpecific time standards\n\nProducers should not mix different types of years in the same dataset. This is to prevent any chance of confusion for users selecting time periods with similar labels in the table tool. For example, you cannot have Academic year and Calendar year data in the same data file. You also cannot mix yearly breakdowns (e.g. full year, quarters, months, or terms) in the time identifier column. Instead, where it makes sense to mix these within a data file you should use a filter column as shown below. Note the use of ‘Total’, this is a part of the standards for filters.\n\n\n\ntime_period\ntime_identifier\nquarter\n\n\n\n\n201718\nAcademic year\nTotal\n\n\n201718\nAcademic year\nQ1\n\n\n201718\nAcademic year\nQ1-2\n\n\n\n\n\n\ntime_period\ntime_identifier\nmonth\n\n\n\n\n2017\nCalendar year\nTotal\n\n\n2017\nCalendar year\nJuly\n\n\n\nIf your row of data spans multiple years (e.g. is a cumulative sum between 2010 and 2018), the starting year should be made clear in the name of the indicator, with the year of the end of the time period listed as the time identifier. For example if you had been recording the number of enrolments in a Local authority since from the start of the 2010/11 Academic year to the end of the 2017/18 Academic year, your data would look like the example on the right.\n\n\n\ntime_period\ntime_identifier\nstarts_since_201011\n\n\n\n\n201718\nAcademic year\n190\n\n\n201617\nAcademic year\n173\n\n\n\n\n\n\nList of allowable time values\n\nAll time_period values should be numeric only, below the number of digits (either 4 or 6) is defined per time_identifier below. Do not include dashes or slashes in six digit years.\nYou can only mix time_identifiers if they appear within the same table below. If they are in separate tables then they should not be mixed.\n\n\n\nAcceptable time_identifier value\nCorresponding time_period\n\n\n\n\nCalendar year\n4 digits\n\n\n\n\n\n\nAcceptable time_identifier value\nCorresponding time_period\n\n\n\n\nReporting year\n4 digits\n\n\n\n\n\n\nAcceptable time_identifier value\nCorresponding time_period\n\n\n\n\nAcademic year\n6 digits\n\n\n\n\n\n\nacceptable time_identifier value\nCorresponding time_period\n\n\n\n\nFinancial year\n6 digits\n\n\n\n\n\n\nAcceptable time_identifier value\nCorresponding time_period\n\n\n\n\nFinancial year Q1\n6 digits\n\n\nFinancial year Q2\n6 digits\n\n\nFinancial year Q3\n6 digits\n\n\nFinancial year Q4\n6 digits\n\n\n\n\n\n\nAcceptable time_identifier value\nCorresponding time_period\n\n\n\n\nPart 1 (April to September)\n6 digits\n\n\nPart 2 (October to March)\n6 digits\n\n\n\n\n\n\nAcceptable time_identifier value\nCorresponding time_period\n\n\n\n\nTax year\n6 digits\n\n\n\n\n\n\nAcceptable time_identifier value\nCorresponding time_period\n\n\n\n\nAutumn term\n6 digits\n\n\nSpring term\n6 digits\n\n\nSummer term\n6 digits\n\n\n\n\n\n\nAcceptable time_identifier value\nCorresponding time_period\n\n\n\n\nAutumn and spring term\n6 digits\n\n\n\n\n\n\nAcceptable time_identifier value\nCorresponding time_period\n\n\n\n\nJanuary\n4 digits\n\n\nFebruary\n4 digits\n\n\nMarch\n4 digits\n\n\nApril\n4 digits\n\n\nMay\n4 digits\n\n\nJune\n4 digits\n\n\nJuly\n4 digits\n\n\nAugust\n4 digits\n\n\nSeptember\n4 digits\n\n\nOctober\n4 digits\n\n\nNovember\n4 digits\n\n\nDecember\n4 digits\n\n\n\n\n\n\nAcceptable time_identifier value\nCorresponding time_period\n\n\n\n\nWeek 1\n4 digits\n\n\nWeek …\n4 digits\n\n\nWeek 52\n4 digits\n\n\n\n\n\n\n\nRemember\n\n\n\nYou must include time_period and time_identifier columns in your data files.\nYour data must match the allowable values above.\nUse ‘Reporting year’ if your data does not fit in other categories, i.e. collected on a specific day.\nIf you have different types of year such academic, calendar, and financial, these should be in separate files.\nUse filters to add more detail if you have multiple time breakdowns in the same file (quarter/full year).\nWhere a measure spans multiple years, you should name the starting year, and set the time_period as the year published."
  },
  {
    "objectID": "creating-statistics/ud.html#geography-columns",
    "href": "creating-statistics/ud.html#geography-columns",
    "title": "Open Data Standards",
    "section": "Geography columns",
    "text": "Geography columns\n\nWe publish at a number of different geography breakdowns and these vary from publication to publication. Every publication in the new platform must include the three compulsory geography columns - geographic_level, country_code and country_name in its data files. These are compulsory as the data we are producing must lie within a country boundary.\nThe geographic_level column should describe the level of data present in that row. Therefore data for a collection from a specific local authority would have ‘Local authority’ as the geographic_level, while a National aggregation would have ‘National’ as the geographic_level.\nTeams should make sure that they are regularly checking their geography codes if they are not using a lookup from a maintained database (such as in the PDR). ONS have the Open Geography portal, which can be a useful way of checking these. There is a wealth of data on there, though Local authority boundaries can be hard to find, they can be found using the tabs at the top – Boundaries > Administrative Boundaries > Counties and Unitary Authorities.\nIf you have data from an unknown location, the standard is to use ‘Not available’ as name, and ‘x’ as the code/s, this clearly marks that the geographical data for that row is unavailable, and does so in a consistent way with the wider GSS. If you have a unique variation of a certain location, e.g. ‘Outside of England and unknown’, we may be able to add these in as exceptions. Locations like this would have a code of ‘z’ as no widely used code is applicable, please get in touch with us to discuss it further if you think this might apply to you.\nWe expect that all geography codes will be based on the Open Geography Portal and run checks against this for various levels in the data screener, please contact us if you have data that doesn’t match this.\n\nWhere you have data for a legacy LA that does not have a 9-digit new code, leave those cells as blank instead.\n\n\n\nDifferent measures of geography\n\nWhen using geographies that can be measured in multiple ways, you can achieve this by including a filter such as level_methodology in the example below to state how you have measured the geographic level. For example, at Local authority level you may have data that was measured by the residence of the pupil and the location of the school:\n\n\n\n\n\n\n\n\n\n\n\ngeographic_level\nold_la_code\nla_name\nnew_la_code\nlevel_methodology\nheadcount\n\n\n\n\nLocal authority\n373\nSheffield\nE08000019\nPupil residence\n689\n\n\nLocal authority\n373\nSheffield\nE08000019\nSchool location\n567\n\n\n\n\n\n\nAllowable geographic levels\n\nAll rows must have country_code and country_name completed, regardless of geographic level. The additional required columns by level are shown below. You do not have to publish at every level, this is a guide that covers every level that can be published in the platform.\nWhere you have multiple geographic levels in a file, leave any not applicable columns blank for other rows. For example, region_name and region_code should be blank for national rows. Some levels do fit into a hierarchy, for example local authorities all have a region, in these cases you should include the higher level information too. So for a local authority row, the region and country columns would all be completed as well as the la columns.\n\n\n\n\n\n\n\n\ngeographic_level\nrequired columns\nnotes\n\n\n\n\nNational\nNo additional columns\n\n\n\nRegional\nregion_code, region_name\n\n\n\nLocal authority\nold_la_code, new_la_code, la_name\nIt is usually good practice to include the Regional aggregations where possible given the direct link between Local authorities and Regions.\n\n\nRSC region\nrsc_region_lead_name\nFor RSC region data, we generally define them into lead RSC regions where the majority of the data is from.\n\n\nParliamentary constituency\npcon_code, pcon_name\n\n\n\nLocal authority district\nlad_code, lad_name\n\n\n\nLocal enterprise partnership\nlocal_enterprise_partnership_code, local_enterprise_partnership_name\n\n\n\nEnglish devolved area\nenglish_devolved_area_code, english_devolved_area_name\n\n\n\nOpportunity area\nopportunity_area_code, opportunity_area_name\n\n\n\nWard\nward_code, ward_name\n\n\n\nMAT\ntrust_id, trust_name\nNote that Trust ID is shown as Group ID on GIAS when looking at a Trust. MATs also have a ‘company number’, this can be included but is not mandatory.\n\n\nSponsor\nsponsor_id, sponsor_name\nNote that Sponsor ID is shown as Group ID on GIAS when looking at a Sponsor.\n\n\n\n\nEnglish devolved area is used to refer to combined authorities, mayoral combined authorities and the Greater London Authority.\n\nPlanning area, School, Provider, and Institution level data will upload as normal to EES, though will not be read into the table tool or data blocks if they are mixed in with other levels. All data, including these levels are accessible in the downloadable files for users to explore in the same format as they are uploaded.\nFor Provider, any data files that only consist of this level are able to be uploaded and will be usable in the table tool. This solution is still not ideal, though it will allow you to include additional filters at provider level. Wherever there are multiple values per provider this should be marked as a filter, and where there is a single value per provider this should be marked as an indicator.\nFor School, any files consisting of school-level data should be standalone data files (that will work in the table tool, not ancillary files) and these should all be passing the EES data screener. They should also include LA level information so that users can see this when searching.\n\n\n\n\n\n\n\n\ngeographic_level\nrequired columns\nnotes\n\n\n\n\nSchool\nschool_name, school_urn, school_laestab, old_la_code, new_la_code, la_name\n\n\n\nProvider\nprovider_name, provider_ukprn\n\n\n\n\nFor Planning area and Institution data, any data files that only consist of these levels should be uploaded as an ancillary file rather than a data file.\n\n\n\n\n\n\n\n\ngeographic_level\nrequired columns\nnotes\n\n\n\n\nPlanning area\nNo required columns, though we recommend both planning_area_code and planning_area_name\n\n\n\nInstitution\nNo required columns, though we recommend you include institution_id and institution_name to make data matching easier\n\n\n\n\n\nIf you have a level that isn’t covered above, please contact statistics.development@education.gov.uk with details and example data.\n\n\n\n\nUsing School or Provider as a filter\n\nProvider / School breakdowns can work as a filter column in your data file but only if it is the only filter in the file. We’d recommend using school_name or provider_name as the filter, and then including the code as well, such as Malton School (URN: 121681) or Malton School (UKPRN: 10004165). You should also include LA level information so that users can see this when searching.\nThis approach will work for basic filtering of providers and schools but it may not be performant in the table tool and the number of choices made available to users may be overwhelming (especially for schools, or data set to national level).\n\n\n\nUnknown geographic codes\n\n\n\n\n\n\n\n\n\nGeographical code\nUsage\nExample\n\n\n\n\nz\nWhen a geography code is not applicable\nUsing custom geographies like “Scotland, Wales and Northern Ireland” as a group. This has no standardised geography code so will not be applicable\n\n\nx\nWhen a geography code is unavailable\nData is missing, the geography is unknown so no code is available\n\n\n\n\n\n\n\nRemember\n\n\n\nYou must have the minimum expected geography columns, country_code and country_name.\nYou must also have the additional columns required for all geographies included in your file.\nThe additional columns must exactly match the names above.\nYou do not have to publish at every level in the guide, publish the selection of levels you feel appropriate.\nYou should regularly check that you are using the most up to date geography names and codes.\nAside from blanks, no two geographic locations should have the same code.\nYou can mix geographies in the same file, and should avoid separating files by geography unless size is an issue."
  },
  {
    "objectID": "creating-statistics/ud.html#ethnicity",
    "href": "creating-statistics/ud.html#ethnicity",
    "title": "Open Data Standards",
    "section": "Ethnicity",
    "text": "Ethnicity\n\n\nOverview\n\nRace is a protected characteristic under the Equality Act 2010 and can include colour, nationality, ethnic or national origins. Data collected on ethnicity is self-identified and captures a person’s feelings of cultural heritage and belonging. Everyone may have slightly different ideas and feelings about what ethnicity encompasses, race and nationality may, or may not, be a part of a persons’ self-identified ethnicity.\nThis guidance has been written by collating the most up to date advice and guidance from the following sources:\n\nGovernment Statistical Service (GSS)\nOffice for National Statistics\nCabinet Office\nCommission on Race and Ethnic Disparities (CRED) report\n\n\n\n\nGSS ethnicity categories\n\nEthnicity breakdowns should be presented within the standard field names in any data files containing ethnicity breakdowns: ethnicity_major, ethnicity_minor or ethnicity_detailed. The first two are outlined in reference to the GSS guidelines on ethnic groupings below, whilst the third is for any ethnicity fields containing finer grained breakdowns than described in ethnicity_minor below.\nThe GSS publish standards on how to collect ethnicity data based on research conducted for the UK Census. The current guidelines (shown below) were developed as part of the 2011 Census and were unchanged in the 2021 census. We aim to follow as closely as reasonable to the GSS standards and guidance.\n\n\n\n\n\n\n\nethnicity_major\nethnicity_minor\n\n\n\n\nWhite\nEnglish/Welsh/Scottish/Northern Irish/British\n\n\n\nIrish\n\n\n\nGypsy or Irish Traveller\n\n\n\nAny other White background\n\n\nMixed/Multiple ethnic groups\nWhite and Black Caribbean\n\n\n\nWhite and Black African\n\n\n\nWhite and Asian\n\n\n\nAny other Mixed/Multiple ethnic background\n\n\nAsian/Asian British\nIndian\n\n\n\nPakistani\n\n\n\nBangladeshi\n\n\n\nChinese\n\n\n\nAny other Asian background\n\n\nBlack/African/Caribbean/Black British\nAfrican\n\n\n\nCaribbean\n\n\n\nAny other Black/African/Caribbean background\n\n\nOther ethnic group\nArab\n\n\n\nAny other ethnic group\n\n\nUnknown\nUnknown\n\n\n\nNote that these standards are written from the perspective of creating survey questions, i.e. the data collection phase. Where teams are trying to aggregate existing categories up to match the GSS guidance, careful consideration of how and where differing systems may or may not match with the guidance is necessary.\nWe recommend two alternative methods of ordering the above ethnic groups when reporting on ethnicity statistics:\n\nAlphabetical: use in tables and when listing ethnic groups (with ‘Other ethnic group’ and sometimes ‘Unknown’ as a final category)\nIn expected order of size (with largest first): useful in charts and visualisations as it makes data and patterns easier to read\n\n\n\n\nReporting on broad ethnic minorities catageories (e.g. BAME)\n\nPublished in March 2021, the report of the Commission on Race and Ethnic Disparities made a number of suggestions on how we discuss and report on race in the UK.\nOne of the major elements was around aggregation of ethnic minorities into a single over-arching group (in particular BAME):\n\nRecommendation 24: Disaggregate the term ‘BAME’ Stop using aggregated and unhelpful terms such as ‘BAME’, to better focus on understanding disparities and outcomes for specific ethnic groups.\n\nThe reasons for this approach are two-fold:\n\nGrouping separate ethnic minorities into a single over-arching group can mask differing trends that may be present in the underlying data for groups experiencing different pressures and environments within UK society.\nThe phrasing ‘Black and Minority Ethnic’ and ‘Black, Asian and Minority Ethnic’ give an emphasis to specific ethnic groups whilst excluding others. This could be misleading or diminish consideration of the unnamed groups within the statistics.\n\nBased on this guidance, the following is how teams should aggregate and write about ethnic minority groups.\nStatistics producers should avoid where possible the practice of reporting aggregates grouping together disparate ethnic groups. Instead, statistics should be reported individually for the recommended top-level groups:\n\nWhite\nMixed/Multiple ethnic groups\nAsian/Asian British\nBlack/African/Caribbean/Black British\nOther ethnic group\n\nWhere there is a reasonable need to publish or report statistics for a full aggregation of ethnic minorities (such as reporting on existing historical targets), official guidance is as follows:\n\nUse ‘ethnic minorities’ to refer to all ethnic groups except the white British group. This term includes white minorities, such as Gypsy, Roma and Irish Traveller groups. For comparisons with the white group as a whole, use ‘ethnic minorities (excluding White minorities)’."
  },
  {
    "objectID": "publishing-statistics/dashboards.html",
    "href": "publishing-statistics/dashboards.html",
    "title": "Best practice for publishing dashboards",
    "section": "",
    "text": "Guidance for publishing Official statistics dashboards"
  },
  {
    "objectID": "publishing-statistics/dashboards.html#user-needs",
    "href": "publishing-statistics/dashboards.html#user-needs",
    "title": "Best practice for publishing dashboards",
    "section": "User needs",
    "text": "User needs\n\nWhen designing a government service, always start by learning about the people who will use it. If you do not understand who they are or what they need from your service, you cannot build the right thing.\nUnderstanding as much of the context as possible gives you the best chance of meeting users’ needs in a simple and cost effective way.\nThe real problem might not be the one you originally thought needed solving. Testing your assumptions early and often reduces the risk of building the wrong thing.\nServices designed around users and their needs:\n\nare more likely to be used\nhelp more people get the right outcome for them - and so achieve their policy intent\ncost less to operate by reducing time and money spent on resolving problems\n\nSee the service manual for more information on learning about your users and their needs."
  },
  {
    "objectID": "publishing-statistics/dashboards.html#tools-software",
    "href": "publishing-statistics/dashboards.html#tools-software",
    "title": "Best practice for publishing dashboards",
    "section": "Tools / software",
    "text": "Tools / software\n\nWhen you make a decision about technology, you’re making a significant investment. The choices you make will have a huge impact on your ability to create, iterate and operate the service in a sustainable way. We should be choosing tools and technology that let us create a high quality service in a cost effective way and minimise the cost of changing direction in future.\nThe most common dashboard options available to us are:\n\nR Shiny\nPython Dash (or other Python-based alternatives)\nPowerBI\n\nSome considerations to think about when choosing the tooling / software for a dashboard:\n\nwill it be open source? (Service standards 12 and 13)\nwhat skills do your team already have, or are already developing?\ncan you reuse anything that someone else has already done?\ndo you have flexibility in formatting and styling?\nwill you be able to maintain it long term?\ndoes it give the flexibility required to meet accessibility requirements?\nwhat costs will it involve? (Consider learning and development time and courses as well as hosting)\nwill it allow you to develop automated testing and CI to QA our dashboards?\ndoes it align with the AF expectation to move towards R and Python for analysis?\n\nFor statistics production teams we’d recommended using R Shiny. We feel that it best meets the service standards, it aligns with the departments RAP strategy for the use of R in in Official Statistics, and the general direction of the government analytical community. It takes advantage of transferable knowledge and shared resources to minimise the costs and maximise the shared benefits.\nWhile we recommend R Shiny, teams can use other tools as long as you can justify it against Service Standard 11. Choose the right tools and technology.\nThe guidance on this page will focus on R Shiny. However, if you are using PowerBI you should also make use of the department’s PowerBI Dashboard standards, and aim to make use of reusable configurations where possible to ensure that duplication of effort across the department is minimised."
  },
  {
    "objectID": "publishing-statistics/dashboards.html#accessibility",
    "href": "publishing-statistics/dashboards.html#accessibility",
    "title": "Best practice for publishing dashboards",
    "section": "Accessibility",
    "text": "Accessibility\n\nGovernment services must work for everyone who needs to use them. Public sector organisations have a legal duty to consider everyone’s needs when they’re designing and delivering services. Making a website or mobile app accessible means making sure it can be used by as many people as possible. This includes those with:\n\nimpaired vision\nmotor difficulties\ncognitive impairments or learning disabilities\ndeafness or impaired hearing\n\nAccessibility means more than putting things online. It means making your content and design clear and simple enough so that most people can use it without needing to adapt it, while supporting those who do need to adapt things.\nThe accessibility regulations came into force for public sector bodies on 23 September 2018. They say you must make your website or mobile app more accessible by making it ‘perceivable, operable, understandable and robust’. The full name of the accessibility regulations is the Public Sector Bodies (Websites and Mobile Applications) (No. 2) Accessibility Regulations 2018. The accessibility regulations build on your existing obligations to people who have a disability under the Equality Act 2010 (or the Disability Discrimination Act 1995 in Northern Ireland).\nThese regulations apply to all dashboards created for Official statistics. All dashboards should:\n\nhave an accessibility statement\nfollow the guidance below for testing against WCAG 2.1 AA accessibility standard\nuse open data that is already available via EES\n\nAnalysts should familiarise themselves with the gov.uk guidance on service accessibility"
  },
  {
    "objectID": "publishing-statistics/dashboards.html#governance",
    "href": "publishing-statistics/dashboards.html#governance",
    "title": "Best practice for publishing dashboards",
    "section": "Governance",
    "text": "Governance\n\nAll teams developing dashboards to accompany Official Statistics should contact the Statistics Development Team for advice on the level of approval required as there may be times when HoP approval is needed in addition to team/unit leader approval. Approvals should be sent to the Statistics Development Team when asking for a new dashboard to be hosted on shinyapps.io.\nThe standards for dashboards, and department strategy are maintained by the Central Statistics Standards Unit and governed by the Statistics Leadership Group, which is made up of all senior statisticians owning Official Statistics publications in the department.\nRegular reflection on how teams are doing and finding ways to improve is an important part of good governance. We recommend that Senior Statisticians responsible for dashboards ensure that they are regularly reviewed, covering:\n\ntesting and quality assurance\naccessibility\nperformance against user needs\noverall coherence with central standards and strategy found on this page"
  },
  {
    "objectID": "publishing-statistics/dashboards.html#iterative-development",
    "href": "publishing-statistics/dashboards.html#iterative-development",
    "title": "Best practice for publishing dashboards",
    "section": "Iterative development",
    "text": "Iterative development\n\nUsing agile methods means getting your service in front of real users as soon as possible. Then observing and generating data on how they use it and iterating the service based on what you’ve learned. Because you’re not specifying everything up front before you’ve developed an understanding of what users need, agile methods reduce the risk of delivering the wrong thing.\nTeams should aim to get a working version of their dashboard out to users as soon as possible to prototype the design and content.\nIteration isn’t just for the early stages of a service’s development and services are never ‘finished’. Using agile methods means getting real people using your service as early as possible. Then making improvements throughout the lifetime of the service.\nMaking improvements means more than doing basic maintenance like fixing bugs in code, deploying security patches and keeping call centre scripts up to date. If that’s all you do, you’ll be fixing symptoms rather than underlying problems. And over time, the service will stop meeting user needs.\nContinuous improvement means you can respond to changes in user needs, technology or government policy throughout the lifetime of the service. So rather than having to be replaced, the service stays relevant until it’s ready to be retired."
  },
  {
    "objectID": "publishing-statistics/dashboards.html#code-testing",
    "href": "publishing-statistics/dashboards.html#code-testing",
    "title": "Best practice for publishing dashboards",
    "section": "Code testing",
    "text": "Code testing\n\nTesting is a way to capture desired behaviour of your code, in such a way that you can automatically verify that it keeps working the way you expect over time. It is essential for making sure that code works the way that you intend it to, and keeps working even after you make changes to the code so that your users have access to a stable service. You need to test your service regularly as part of quality assurance (QA) to make sure that it:\n\nis easy to use for anyone who needs to use it, regardless of the device they’re using\nis stable, secure and works quickly, regardless of how many people need to use it\ncan be iterated quickly to meet changes to user needs or the political environment\n\nTests can come in a variety of shapes and sizes, good starting points for analysts new to testing are the Duck Book, and DfE good code practice.\nYou should aim to automate as much of your testing as possible and run your test suite as part of continuous integration (where your tests form part of your codebase). By testing your code automatically every time you make a change, you’ll be able to find defects more quickly. Getting fast feedback means you can respond to any problems quickly and make changes when you need to. You can also spot defects before they develop into bigger problems that are more complicated and expensive to fix.\nFor dashboards created in R Shiny, we strongly recommend a mix of unit tests and UI tests (integration), run using GitHub Actions for continuous integration (CI). All applications should have an appropriate level of test coverage before being published. More information and details on how to get started with this can be found in the testing R Shiny section below."
  },
  {
    "objectID": "publishing-statistics/dashboards.html#assessing-engagement",
    "href": "publishing-statistics/dashboards.html#assessing-engagement",
    "title": "Best practice for publishing dashboards",
    "section": "Assessing engagement",
    "text": "Assessing engagement\n\nWork out what success looks like for your service and identify metrics which will tell you what’s working and what can be improved, combined with user research. For dashboards this will likely be things like the number of users and interactions with what you have created.\nDefining what “good” looks like and identifying appropriate metrics means that you’ll know whether the service is solving the problem that it’s meant to solve.\nCollecting the right engagement data means you’ll be alerted to potential problems with your service. And when you make a change to the service, you’ll be able to tell whether it had the effect you expected. In practice this will often mean setting up analytics and feedback surveys for dashboards and monitoring the data you get back.\nAt a minumum you should be requesting feedback from users via a survey hosted on the dashboard and reviewing this on a regular basis. An example of this kind of feedback survey is the beta banner survey on Explore Education Statistics.\n\n\n\nGoogle Analytics is a free service that collects information on who visits your webpage and how they interact with it. You can set up basic Google Analytics for your published dashboard in a few simple steps outlined in this article: Add Google Analytics to a Shiny app and view a more complex example in this example file. If you’re planning to publish a dashboard, or to set up Google Analytics for a published dashboard, please contact statistics.development@education.gov.uk."
  },
  {
    "objectID": "publishing-statistics/dashboards.html#peer-review",
    "href": "publishing-statistics/dashboards.html#peer-review",
    "title": "Best practice for publishing dashboards",
    "section": "Peer review",
    "text": "Peer review\n\nPeer review is a quality assurance activity, where an analyst other than the original author, views and tests the usage of a product or specific piece of code. This allows a fresh pair of eyes to take a look at your work. It validates that you have taken a correct approach and may highlight errors. This constructive feedback helps you to improve the quality. It provides confidence in your work, and ensures that it is fit for purpose.\n\nDashboards must always be peer reviewed within the team they are created.\nDashboards should also be peer reviewed by analysts outside of the subject area of the team.\n\nThe Central Statistics Unit has a number of analysts experience with R Shiny dashboards and are happy to review any dashboards created, contact statistcs.development@education.gov.uk if you’re interested in this. For more guidance on how to peer review, see the peer review section of the Duck Book."
  },
  {
    "objectID": "publishing-statistics/dashboards.html#internal-only-dashboards",
    "href": "publishing-statistics/dashboards.html#internal-only-dashboards",
    "title": "Best practice for publishing dashboards",
    "section": "Internal only dashboards",
    "text": "Internal only dashboards\n\nIt’s possible to publish dashboards that are only accessible to those on DfE kit, to do this you will need to publish via the departments RSConnect servers.\nYou will need:\n\nA finished app, in line with the guidance on this page\nThe code to be in a Git repository in the dfe-gov-uk Azure DevOps space\n\nTo publish the app, you’ll need to set up a pipeline in Azure DevOps, guidance for how to do this can be found in the R community teams area.\nAccess to applications on RSConnect are locked down by default, once the pipeline is set up and you’ve deployed the app you’ll need to request for its access to be opened up by using an RSConnect request on ServiceNow.\nIf you’re running the app from an internal database, you’ll need to contact the database owner to set up a local login, and then store those as variables against your specific app in rsconnect. You can raise a request to do this via ServiceNow and selecting ‘Change app variables’."
  },
  {
    "objectID": "publishing-statistics/dashboards.html#public-dashboards",
    "href": "publishing-statistics/dashboards.html#public-dashboards",
    "title": "Best practice for publishing dashboards",
    "section": "Public dashboards",
    "text": "Public dashboards\n\nThe majority of dashboards made to support and augment our Official Statistics will be public facing. For public facing shiny apps you should publish via shinyapps.io. The statistics development team manage a subscription for this and can help you get set up.\nYou will need:\n\nA finished app that meets the accessibility and styling standards (see our Dashboard procedure checklist)\nCode in the dfe-analytical-services GitHub repo\nApproval from your DD\nIf the data underlying the dashboard is currently unpublished, you will need to create dummy data to use in GitHub until the data becomes published (see dummy data guidance section).\n\nTo set up a new app, send the above to statistics.development@education.gov.uk. If your code is not yet hosted in the dfe-analytical-services area you can request for the repository to be moved at the same time as sending approvals.\n\n\nDummy data\n\nWhen creating a public dashboard, all code and data will be hosted in the dfe-analytical-services GitHub repo. This is a public repo, meaning anything stored in here is publicly available. Therefore if you are creating a dashboard with previously unpublished data, you should provide dummy data for the GitHub repo, and only add the real data on your publication date.\nYour dummy data should:\n\nUse the exact same structure and variable names as your real data\nUse random values in place of real values (one example of how to do this is using the rnorm() function)\nSimulate the types of suppression, missing data or anomalies seen in your real data, to ensure the dashboard can account for these.\n\n\n\n\nTesting with unpublished data\n\nWhile you must use dummy data in your GitHub repo, it is understandable that we should test the dashboard works with the real data before it goes live.\nThis can be done using the .gitignore file alongside the datafiles_log.csv and commit hooks explained in the Stopping accidental data uploads guidance. You can view the example files our template repository.\nThe .gitignore file is a plain text file that tells git to ignore specified files in commits and pushes to the repo. Therefore, the first step when wanting to test unpublished data in a dashboard is to add the unpublished data file names to the .gitignore file.\nAdding the file name alone will ensure it is ignored no matter where in the project area you save it (i.e. in any folder). Once this is done, you can add your unpublished data file to your local area, run the app locally, and make edits/commits without uploading the data to Github.\nThis .GitIgnore guidance page has great guidance on how you can utilize wildcards to capture all the files you might want to ignore.\nIf you have any questions on this process please do contact us at statistics.development@education.gov.uk."
  },
  {
    "objectID": "publishing-statistics/dashboards.html#how-to-start",
    "href": "publishing-statistics/dashboards.html#how-to-start",
    "title": "Best practice for publishing dashboards",
    "section": "How to start",
    "text": "How to start\n\nThere are a lot of resources already available to support you when working with R Shiny, if you’re new, then this blog post provides a gentle introduction.\nOur template shiny app repository is a useful starting point for all public facing dashboards in the department. Please see the dashboard template section for guidance on what the dashboard template includes and how to use it.\n\nFor more advanced shiny knowledge it’s worth taking a look at the guide to engineering production-grade shiny apps.\nFinally, you should seek to make use of the community that is already out there, see what others are doing, ask them questions and for advice on any decisions or problems that you’re facing, and share what it is that you’re doing. - The Statistics Development Team are experienced with R Shiny and happy to help or offer advice, and there is the DfE R community on teams. - There is a bank of tips and tricks stored in the DfE R teams area too. - Going beyond DfE there’s a wealth of resources and communities online, including Stack Overflow discussions, cross government slack channels (e.g. #R and #Shiny on govdatascience.slack.com) and even tweets about R Shiny on twitter.\n\n\nDashboard procedure checklist\n\nThis checklist outlines the standard procedure for teams who are wishing to produce a public R shiny dashboard.\nGetting set up:\n\nCreate an account on GitHub\nAsk the Statistics Deveopment Team to create you a repository in the DfE analytical services area, providing the name of the dashboard and the GitHub accounts of anyone who will be contributing to the code. You should aim to have two analysts working on the code development and a line manager for review purposes. Further colleagues with review responsibilities (policy colleagues, G6 and above, etc.) can be given access to a demo-site, rather than the repository (see guidance for this below in ‘Setting up a development/demo dashboard area’).\nClone the repo to your device so you can develop your code. Open the repo page in GitHub, click the green ‘Code’ button, and copy the URL it provides. Then, open R Studio on your device, click file > new project > version control > git, paste the repository URL you copied from GitHub, give your local project area a name, and choose where to save it (i.e. on your computer’s C: drive, outside of the OneDrive-synced folders).\n\nOnce you’re set up, there are certain parts of the code you need to update:\n\nIn the global.R script, update all of the site URL’s and EES publication names to your own.\nIn the ui.R script, update the tags$title(), the information in the meta_general(), and the secondary text in shinyGovstyle::header().\nGot to the .github > workflows folder, and open the deploy-shiny.yaml file. At the bottom, update the appName in rsconnect::deployApp() - this is what will appear in the URLs (i.e. must align with the links in global).\nUpdate the ‘Support and feedback’ tab (in R > standard_panels.R) with your teams information. We also recommend creating a feedback form for users of your dashboard, and adding a link to that on this page.\nUpdate the README.md file (you can do this easily directly in GitHub). This is the file that renders below your repo in GitHub for users to see.\nBegin adding your own dashboard content. If you copy and paste any parts of the code (i.e. to create new tabs) you must change all of the IDs so there are no repeated IDs in the UI, otherwise the app will run with no UI elements. You should add UI and unit tests as you develop your code as a form of automated QA (see our guidance on UI tests and guidance on unit tests).\n\nYou must contact the statistics development team for the following:\n\nTo add the shinyapps.io secret and token to your GitHub repo, therefore enabling the app to be hosted on shinyapps.io.\nTo create an area for your team in Google Analytics, to track the user analytics of your dashboard.\n\nSetting up a development/demo dashboard area:\n\nWhile developing your dashboard, you may want a private, demo-version to share with policy or senior colleagues for review and feedback. This version must use either published data or dummy data and can not use unpublished data, since this cannot be uploaded to GitHub until the day of publication (see our dummy data guidance for public dashboards).\nEnsure that prior to contacting the statistics development team, you have updated all of the URL’s and other items listed above.\nYou must contact the Statistics Deveopment Team to add the shinyapps.io secret and token to your GitHub repo, therefore enabling the app to be hosted on shinyapps.io. Once this is done you will have a browser link you can use to access the dashboard. We can make this private such that there is a list of approved viewers who must log in to view the dashboard - please provide the email addresses of any colleagues who you wish to have access to the private version during development.\n\nYou must have done the following before a dashboard can be published (the statistics development team must review and approve that these have been met):\n\nAccessibility testing the dashboard and updating the accessibility statement. The accessibility testing guidance later in this section outlines how teams can do this.\nYou should test how your dashboard appears and performs on mobile devices. you can do this by opening your dashboard in chrome/edge, right clicking anywhere on the page and selecting ‘inspect’. you will then see a new panel on the right hand side of your screen. To see your dashboard how a mobile user would, click the mobile/tablet button (see the image below).\n\n\n\n\n\nSetting up UI and unit tests (UI tests are a part of the automated QA process and will run via GitHub actions each time you create a pull request). See our guidance on UI tests and guidance on unit tests.\nPerformance testing your dashboard. See our guidance on performance testing.\nThe underlying data for the dashboard must still be uploaded to EES in the tidy data format to be used in the table tool (check this using our data screener)\nDecide where you are going to provide the public the link to your dashboard. You can easily add a link to your EES publications. If you have a draft release that is going out on the same day as the dashboard, you can add the link into your EES draft while the shinyapps.io page is still private. This is because the link will not change when the dashboard is made public, the log-in screen will simply be removed."
  },
  {
    "objectID": "publishing-statistics/dashboards.html#standards-to-follow",
    "href": "publishing-statistics/dashboards.html#standards-to-follow",
    "title": "Best practice for publishing dashboards",
    "section": "Standards to follow",
    "text": "Standards to follow\n\nWe expect all dashboards to follow a minimum set of standards to ensure coherence between our products and a minimum standard of quality for our end users.\nThese standards are constantly evolving, and all feedback and contributions are welcome, contact us at statistics.development@education.gov.uk.\n\n\nAccessibility testing\n\nIn line with recent legislation for public sector websites, all dashboards need to meet the latest Web Content Accessibility Guidance.\nAs a minimum we expect all dashboards to be checked using the two tools below (lighthouse and shinya11y) and have an accessibility statement before being published.\nYour statement should be written in line with the accessibility statement guidance, and you can make use of a template accessibility statement provided by .gov.uk.\nLighthouse in Google Chrome is an easy way to quickly rate your accessibility. Open your app in Chrome, right click anywhere on the page and select “Inspect”. From there, navigate to “Lighthouse” in the top grey bar, and click “Generate report”. This generates scores for accessibility, best practices and SEO for your application or web page:\n\n\n\nTo complement this, we recommend also using the shinya11y package to look at accessibility across your dashboard. Simply install and load the package, then include use_tota11y() at the top of your UI script. This brings up an interface that helps you examine different accessibility aspects in your app, like colour contrast, alt-text and what screen readers will detect:\n\n\n\nAutomated tools can’t check for everything and there’s no substitute for giving your dashboard a manual check. You should consider what users need from your dashboard and ensure that that information is accessible to all. For example, can someone using a screen reader get the same information as you can see on the screen from a downloadable csv or from the alt text that you have provided? Everything that you can see, you should also be able to read with a screen reader. Use the Edge narrator tool to test out how your dashboard works in practice.\nOne example of a dashboard for Official statistics that meets these regulations is the SCAP LA school places scorecards app. Their accessibility statement is clearly labelled, explains what checks have been carried out, what the known limitations are and the plans in place to fix them:\n\n\n\n\n\n\n\nStyling\n\n\nAll dashboards should have a link to the source code, and information about who to contact for feedback/issues. You should be familiar with and follow the gov.uk style guide as appropriate.\nTeams should pick from the gov.uk design system colours when creating dashboards. The style sheet in our template repository makes use of these colours, though this can be extended if needed to suit your needs. Be careful when choosing colours, and make sure that colours have sufficient contrast to be placed next to each other to meet WCAG AA standards using the colour contrast checker.\n\nCharts using ggplot2 and plotly can take custom palettes using the scale_fill_manual() function, e.g. below:\n# Create colour palette using recommended colours (based on gov.uk design system)\n\ndfe_colours <- c(\n  \"#12436D\", #`blue`\n  \"#F46A25\",#`orange`\n  \"#801650\",#`maroon`\n  \"#28A197\" #`turquoise`\n  )\n\n# Create chart using palette\n\nggplot(aes(y=value, x=\"\",\n                 fill = factor(rating),\n                 text = paste(rating, \": \", value, \"%\"))) +\n      geom_bar(stat=\"identity\", position = position_fill(reverse = TRUE))+\n      scale_fill_manual(values = dfe_colours)\n\nFurther examples are given on the Using Explore Education Statistics guidance page.\nYou can use in-line CSS to make these style changes, or make edits to the style sheet. Editing the style sheet is a neater solution if you want to apply changes across your app, and keeps your UI code clean. You can find out how styles are configured by running your app, right clicking and selecting “Inspect” to view the element you wish to change. You can then find these lines in the CSS stylesheet and change a number of things including fonts, font colours and background colours.\nThe SCAP LA school places scorecards app is one example of a public facing dashboard that meets these styling requirements.\n\n\n\n\n\n\nTesting R Shiny\n\nTo ensure that they are reliable, dashboards should have an appropriate amount of automated tests before they can be published. We recommend using a mix of UI and unit tests, but the number and type of tests that you need to run will depend on the content of your application.\nFurther guidance on setting up testing can be found in the DfE good code practice guide. Also see our guidance on testing R code on the learning resources page.\n\n\nPerformance testing\n\nPerformance profiling represents a chance to breakdown how different elements within your dashboard perform relative to each other. This consists of running through a set of actions on a local run of your dashboard and timing each one. A useful tool for performing these tests is profvis, which carries out all the timings and visualisation of the results for you, whilst all you have to do is run the app and step through the actions that you want to profile.\nThe basic steps are as follows.\nWith your dashboard repository open in RStudio, run the following commands from the R console\ninstall.packages(\"profvis\")\nprofvis(shiny::runApp())\nThen go through a set of interactions in your dashboard (e.g. navigate to the dashboard page, step through changing the selected choices in each input field, switch between any different tabs and cycle through the relevant inputs again). Once you’ve performed a representative range of actions in the dashboard, close the window and go back to the RStudio window.\nAfter several seconds (depending on the range of actions you performed), a visualisation will appear in the main RStudio editor window showing the results of the profiling.\nThe profvis results are shown in the flame profiling chart. The top half of the chart shows any processing time measurements above 10ms for each line of code. It can be useful to focus in on lines that have measured times above 10ms by selecting “Hide lines of code with zero time” from the options menu in the top right.\n\n\n\nLines with timings of greater than about 5-100ms may warrant further investigation to see if they warrant some optimization. Common routes to optimising code are:\n\navoid any data processing in server.R, e.g. avoid using the summarise() function;\nuse reactive() elements to minimise repeated calls of given functions;\nuse memoise() to cache results of more intensive functions (e.g. ggplot) to minimise repeated calls.\n\nThe documentation for the profvis package can be found here: Profvis documentation\nWhilst profvis can help identify any bottlenecks, this will ideally be complemented in the future by full load testing of dashboards, whereby the behaviour of dashboards under real-life high demand scenarios can be tested. However, this type of testing is unavailable whilst our applications are hosted on ShinyApps. We will offer support on load testing once we move dashboards on to our own server systems.\n\n\n\nUI Tests\n\nUser interface (UI) tests should be used for all apps. These tests should check that:\n\nYour app loads up correctly\nContent appears as expected when you switch between tabs\nContent updates as expected when you change inputs\n\nThe shinytest package is a really easy way to create these tests on an RShiny app. Simply load in the package and run shinytest::recordTest() to open up the testing environment to get started.\nEach test should produce one “expected results” JSON file. You can track particular elements of your app by holding CTRL and clicking on an element in the testing window.\nFor example, the SCAP LA school places scorecards app has tests that check that the app functions as expected when different combinations of filters are selected.\nEach test is separated out by comments, clearly stating what is being tested. - app\\(setInputs()** tells the UI test to select an input in the app  - **app\\)snapshot() tells the UI test which outputs to capture (i.e. which outputs you’d expect to change and want to test)\n::: {.cell-output-display}  :::\nThe expected outputs are saved in a UI_tests-expected folder, and every time you run a UI test, the outputs will be compared to these expected snapshots.\nAn example of a basic shiny test to check that your app loads up correctly can be found in our shiny template repo.\n\n\n\nUnit Tests\n\nUnit tests should be used for apps that contain custom functions created from scratch, or that rely on existing functions being combined to interact in a certain way.\nUnit testing checks, for a set of defined variables, that the output is always the same when you run your custom function/s. This ensures that if slight tweaks are made to your function, or functions within packages you are using are updated, that your custom function still works.\nFor example, our QA app has many custom functions that we create to screen files before upload to EES. We have a series of dummy files that we have created to either pass or fail certain tests. Unit tests are written to check that these files always pass or fail as expected.\n\n\n\nTests and deployment\n\nBoth UI and unit tests need to be added to your app’s deployment pipeline. This ensures that the app will not be published if any of the tests fail.\nWe recommend using Github Actions to deploy the latest code whenever a push to your master branch occurs - this ensures that the published version of your app stays up to date.\nYou should also use GitHub Actions to run the automated tests for your app, which we recommend are done on at least every pull request.\nIf you’ve started from our template repository then all of this will be mostly set up for you to tweak and expand on, but if you haven’t then you’ll need to add the yaml files from the .github/workflows folder to your repository.\nGitHub actions are already well documented and their own guidance should be able to walk you through anything you need. That being said, if there’s anything else you’d like to see here let us know.\n\n\n\n\n\nConnecting to databases\n\nWe don’t yet have a database server set up that can be accessed by public facing dashboards, though we are working to put this in place. In the meantime, there a few alternative options for storing data that the dashboard can run off.\n\nStore the data within the repo (e.g. CSV files in a /data folder). Note that only published data should be stored in a repo. If your working on a dashboard that uses unpublished data then please see the dummy data section for guidance.\nUse Google sheets\nUse Dropbox\n\nIf you are running an internal-only app then you can connect to our internal SQL servers, information on how to do this is in the R community teams area.\n\n\n\nSecure variables\n\nSee our Git page for guidance on storing secure variables in repositories."
  },
  {
    "objectID": "publishing-statistics/dashboards.html#whats-in-the-template",
    "href": "publishing-statistics/dashboards.html#whats-in-the-template",
    "title": "Best practice for publishing dashboards",
    "section": "What’s in the template",
    "text": "What’s in the template\n\nThe template provides code for a basic interactive dashboard, with an example line chart using drop-downs for education level and geographic levels. It also includes an example accessibility statement (this is a requirement for all public dashboards and must be filled in, see the Accessibility and Accessibility testing sections earlier in this guidance), and a ‘Support and feedback’ page with suggested contact information and links.\n\n\n\nGoogle analytics\n\nThe template has a google_analytics.html file which is set up to track all basic metrics, plus the inputs from both drop-downs. To set this up with your own app you will need a new tracking tag (the long number in the gtag()) which the statistics development team can provide you with. Please contact us in order to set this up.\nIf you are hosting your dashboard at multiple URLs (i.e. to cope with expected high traffic) then all URLs will be tracked using one tracking tag and analytics for all URLs will all appear as one in the same report.\n\n\n\nData files log\n\nThe datafiles_log.csv file is a record of all of the data files saved in the repo, and whether or not the data is published. You should log all data files here and accurately record whether the data is published, unpublished or reference data.\n\n\n\nStopping accidental data uploads\n\nIf you see any of the following errors, it is because you are trying to commit a data file to the GitHub repo that hasn’t been recorded as published:\nError: data/test_data.csv is not recorded in datafiles_log.csv.\nError: data/test_data.csv is not logged as published or reference data in datafiles_log.csv and is not found in .gitignore.\nThe template uses commit hooks and a datafiles_log.csv file. Commit hooks run automatically whenever you try to commit changes, and prevent any unpublished data being uploaded to the GitHub repo (see the public dashboards and dummy data sections) by checking the datafiles_log.csv file.You should therefore record all data in the datafiles_log and record whether it is published, unpublished or reference dara. If you try to commit a file that is not recorded or is recorded as unpublished, git will not allow the commit. If you would like to save an unpublished data file locally to test the dashboard you should use the .gitignore file to ensure git ignores this file in your commits (see the testing with unpublished data guidance)."
  },
  {
    "objectID": "publishing-statistics/ees.html",
    "href": "publishing-statistics/ees.html",
    "title": "Using Explore Education Statistics",
    "section": "",
    "text": "Guidance for how to use the features in the Explore Education Statistics platform\nExplore Education Statistics (EES) is the Department’s official statistics dissemination platform, designed to make DFE’s published statistics and data easier to find, access, use and understand.\nThe EES platform consists of two applications:\nBoth applications were released to Minimal Viable Product (MVP) standard in March 2020, we will be iterating and improving the functionality based on user feedback throughout 2020 and 2021.\nMaintenance and use of the platform is supported by the Statistics Development Team."
  },
  {
    "objectID": "publishing-statistics/ees.html#environments",
    "href": "publishing-statistics/ees.html#environments",
    "title": "Using Explore Education Statistics",
    "section": "Environments",
    "text": "Environments\n\nAs stated above, EES consists of two parts. We also have four versions (environments) of EES, the banner for the admin part of each environment will inform you which environment you are on, this is also colour coded:\n\nDevelopment - Green - where changes are first merged in, and often the first time different pieces of work from different developers will interact properly\nTest - Pink - where our developers can carry out manual testing of any new features to make sure things work as expected\nPre-production - Yellow - a sandbox area for analysts to carry out functionality testing\nAdmin pre-production - https://admin.pre-production.explore-education-statistics.service.gov.uk\nPublic pre-production - https://pre-production.explore-education-statistics.service.gov.uk\nProduction - Red - the real service, anyone creating real releases that they intend to publish to the public should be using this environment\nAdmin - https://admin.explore-education-statistics.service.gov.uk\nPublic - https://explore-education-statistics.service.gov.uk\n\nThere is no overlap between the environments and content created on one cannot be moved to any other.\n\nIf you are bookmarking links, please be careful to bookmark the links below exactly as they are shown. Often when signing in you will be redirected via other url’s as a part of the authentication process, and bookmarking those may lead to errors.\n\nTeams can use the pre-production environment to familiarise themselves with the platform and test out what is possible. The core functionality across the environments is identical except for new changes, which are deployed through the different environments before they make it to production.\nOn the pre-production environment, all analysts have full permissions to create publications and releases, and can see everything else that other analysts are making. This is unique to the pre-production environment, on the production environment analysts will only have access to releases that they have been granted specific access to.\nWhen accessing the pre-production environment you may be asked for a username and password, these are as follows: dfe, dataresearch.\n\nThe pre-production environment is not suitable for unpublished data. Unpublished data should only be uploaded to the production environment.\n\n\nGetting access to admin\nAccess to the production and pre-production admin services is limited to DfE AD accounts only and users have to have been invited to the service by either the Statistics Development Team (for full access) or an existing user (for pre-release access). Invites to the service are sent out via email using gov.uk Notify.\nTo be invited to the service for full access teams need to email the Explore Statistics Mailbox, stating who needs access, what permissions they require (analyst or approver), and for which publications these apply. This email should be sent by the Team Leader, or accompanied with the relevant Team Leader’s approval. Once access has been granted you will receive an email inviting you to use the platform.\n\nJobshare emails can not be used to access EES. Specific personal emails should be used instead, in the same way as you sign in to windows on your machine."
  },
  {
    "objectID": "publishing-statistics/ees.html#roles-and-permissions",
    "href": "publishing-statistics/ees.html#roles-and-permissions",
    "title": "Using Explore Education Statistics",
    "section": "Roles and permissions",
    "text": "Roles and permissions\n\n\nThe Statistics Development Team are responsible for setting up and maintaining user permissions during the beta phase. Change requests will be monitored via their main mailbox - explore.statistics@education.gov.uk.\nThe following roles exist within EES admin and are assigned to a specific release:\n\nPre-release\nAny user invited for pre-release is given a pre-release user role. During the hours of pre-release they can:\n\nPreview the release page, including downloading files\nPreview the table tool page for that release\n\n\n\n\nAnalyst - contributor\nAny analyst working on a release within EES admin will have the contributor role. They can:\n\nEdit release details\nUpload data and other files\nCreate footnotes, datablocks and charts\nEdit and comment on release content\nInvite PRA users\nMove the release status between draft and ready for higher review\n\n\n\n\nAnalyst - approver\nThe responsible statistician for a statistics release will have the approver role, allowing them to sign off releases for publication. This will usually be the responsible G5 or G6 for the statistics publication. They can do everything a contributor can, as well as:\n\nMove the release status between draft, ready for review and approved\nSchedule the release for publication (either immediately or for a specific date)\n\n\n\nThere is also a publication owner role, which is assigned at publication level to a users account:\n\nPublication owner\nThis permissions level gives publication owners control over their publications. They can do anything a contributor can for all releases within the publication. On top of this the publication owner also has access to:\n\nManage publication level details\nCreate new releases within a publication\nCreate an amendment of the latest published release within a publication\nCancel an amendment before it is published\n\n\n\n\nBAU\nThe administrative role:\n\nThis role is assigned to a user and gives full access including administrative tools, typically only used by the Statistics Development Team and EES developers.\n\n\nSee below for a diagram of the responsibilities of each role as part of the publication process in EES:"
  },
  {
    "objectID": "publishing-statistics/ees.html#requesting-a-new-publication",
    "href": "publishing-statistics/ees.html#requesting-a-new-publication",
    "title": "Using Explore Education Statistics",
    "section": "Requesting a new publication",
    "text": "Requesting a new publication\n\nIf you have not published on EES before, or if you’re creating a brand new publication, you will need to contact us to create the publication for you before you can get started.\nThe hierarchy of content within EES is as follows -\n\n\n\n\n\n\n\n\n\nPublications are organised into topics and themes (as shown on the EES Find Statistics page), and then within each publication there are releases - where the latest release includes the latest statistics for that publication. For example:\n\n\n\nLevel\nExample\n\n\n\n\nTheme\nPupils and Schools\n\n\nTopic\nPupil absence\n\n\nPublication\nPupil absence in schools in England\n\n\nRelease\n2018/19\n\n\n\nEach publication should have a lead statistician’s name and contact details attached to it as a requirement of the Code of Practice. You may use a team email address but the name and telephone number of a named statistician should also be provided.\nMethodology documentation is also attached at a publication level within EES - meaning one standalone piece should be written to cover all releases for the given publication within the service.\nIf you want to request a new publication, please be prepared to give the following:\n\nThe heading and subheading that you want the publication to sit under in our site (take a look at the current structure here), feel free to either use existing ones, or suggest new ones\nThe exact title of the publication\nA summary of less than 160 characters (including spaces) that describes your publication series\nIf the methodology already exists elsewhere and you have a URL for it, or if you want to create one\nTeam name\nTeam email address\nLead statistician name\nLead statistician contact number\nThe time period of the release you’re creating\nWhether they are National statistics, an ad-hoc publication, or official statistics\nList of email addresses of analysts who need access to the release and at what permission levels\n\nPublication details can be managed by publication owners or via requests to the Explore Statistics Mailbox."
  },
  {
    "objectID": "publishing-statistics/ees.html#admin-dashboard",
    "href": "publishing-statistics/ees.html#admin-dashboard",
    "title": "Using Explore Education Statistics",
    "section": "Admin dashboard",
    "text": "Admin dashboard\n\n\nUse Google Chrome or Microsoft Edge to access and use the admin part of Explore Education Statistics.\n\nWhen you enter the service you’ll see the admin dashboard, here what you can see will be dependent on your access permissions i.e. you’ll only see the publications that you have been granted access to. Within the test environment users are set up with full permissions (i.e. they can see/do everything) though in our production environment this will be restricted.\nThe Statistics Development Team will be responsible for setting up and maintaining user permissions during the beta phase. Change requests will be monitored via their EES mailbox - explore.statistics@education.gov.uk.\n\n\n\nWithin this dashboard you can view and manage existing publications, including creating and editing their releases. You can use the drop down lists to find releases by theme/topic/publication or use the draft and scheduled releases tabs to see releases that are in progress."
  },
  {
    "objectID": "publishing-statistics/ees.html#external-user-access",
    "href": "publishing-statistics/ees.html#external-user-access",
    "title": "Using Explore Education Statistics",
    "section": "External user access",
    "text": "External user access\n\nAccess to EES for users outside of DfE is difficult as the authentication and security on the service relies on the DfE Azure Active Directory and associated infrastructure. It is possible to request that external users from other government organisations have access, and they can then be added as collaborating analysts on a release or as pre-release viewers.\nIf you have external users you’d like to request access for, please send the following to explore.statistics@education.gov.uk, at least two weeks in advance of requiring access. Due to the dependency on DfE’s digital security we cannot guarantee access or how long it may take.\n\nEmail addresses of users to be added\nReason for access\nLength of time access is needed"
  },
  {
    "objectID": "publishing-statistics/ees.html#data-and-files",
    "href": "publishing-statistics/ees.html#data-and-files",
    "title": "Using Explore Education Statistics",
    "section": "Data and files",
    "text": "Data and files\n\nHere you will update your data files and accompanying metadata. You need to make sure that the data has passed through our data screener checks before trying to upload it.\n\nAll data files are accessible in the downloadable files for users to explore in the same format as they are uploaded.\n\n\n\nSubject titles\n\nYou’ll need to give a ‘subject title’ to each data file you upload. The subject name should be a simple user-friendly title for the data included within the file - it is what users will see wherever the file is referenced within EES. The actual file name and data guidance can include more technical / coverage information.\nWhen adding a subject name think about the general user and how the subjects will appear in the service:\n\nYou don’t need to include the publication name in the subject name as this is always already implied within EES\nYou don’t need to list what filters are in each file in the title, users can see this in the data guidance\nYou don’t need to include the date ranges covered in each file in the title, users can see this in the data guidance\nYour subject names should be short and snappy, clearly explain what is in each file. Some good examples of this in practice are included below:\n\nEarly years provision by provider type\nExclusions and suspensions by pupil characteristics\nITT new entrants by subject and training route\n\n\nYou can make changes the subject title for your data file after it has been uploaded if needed using the ‘Edit title’ option.\n\n\n\nUploading files\n\nWhen uploading files you have a choice between uploading as separate CSV files or as a combined ZIP file.\nFor data files greater than 80mb we recommend uploading as a ZIP file.\nOnce you click to upload the file a ‘Status’ will be visible that shows the progress of the import process. It will go through the following stages:\n\nQueued\nValidating\nImporting\nComplete\n\nThis may take a little while depending on the size of your file and if there are numerous files queued for import. You cannot view the dataset or use it to create tables/charts until this status is ‘COMPLETE’.\n\nIf you believe your file is ‘stuck’ please contact explore.statistics@education.gov.uk, with details of the file and the release that you are uploading to.\n\n\n\n\nOrdering filters and indicators\n\nTo save time when creating tables and charts, and to aid users who view your data themselves via the table tool, you can now save custom orders for your filters and indicators. You can do this in the data and files page after uploading underlying data files, via the ‘reorder filters and indicators’ tab. Once there just choose which file you want to reorder and then click and drag the items until they’re in the order you want them to show in the table tool. This then becomes the default order for this filter or indicator and will apply in all charts and tables automatically.\n\n\n\n\n\n\nAncillary file uploads\n\nAny files you want to make available for users to download but aren’t intended the table tool should be added as an ancillary file upload. These files will need to meet all requirements of the new accesibility regulations before they can be published.\nExamples of ancillary files may be:\n\nInfographic pages\nSupplementary data that isn’t intended for the table tool\nAdditional technical documentation\n\nFor ensuring that spreadsheets are accessible see the guidance from .gov.wales, and this blog post that walks you through some ways that you can recreate the experience of using spreadsheets.\n\nAny data files that only consist of Planning area, and/or Institution level data should be uploaded as an ancillary file, rather than as a data file.\n\n\n\n\nPublic data guidance\n\nHere you should also create your public data guidance document, this replaces the information that would have previously been uploaded as a pdf and is designed to help users understand and use the data they download from your release.\n\n\n\nThe document will automatically update as you add new data files to your release, however you will need to add an overview of all the data included in the release and short summaries for each data file before the release can be published.\nA list of variables in each file with an associated label (taken from metadata uploads) and associated footnotes will also be displayed for each file.\n\n\n\n\nReleases cannot be published without a completed metadata document. If not filled in an error will be flagged during sign off.\n\n\n\n\nReplacing data\n\nIf you just need to change the subject title for your data file you do not need to go through the whole replacement process, just click the ‘Edit title’ option.\nHowever, if you notice a mistake in your data file you can replace it with another. When replacing a data file the platform will attempt to recreate any data blocks and footnotes that were built using the previous file.\n\nThe replacement file must contain the exact same column names and types as the original. For example, a character column named “date” must also be replaced with a character column named “date”. A numeric column named “date” will not work in the replacement.\n\n\n\n\nThe first step is to upload the new file.\n\n\n\nOne you’ve chosen and uploaded your replacement file it will need to go through the usual import process before it can check if retaining existing data blocks and footnotes will be possible.\n\n\n\nOnce the upload is finished a report will appear which highlights whether existing data blocks and footnotes can be replaced successfully. If you want to keep any data blocks and footnotes you’ve built you will need to make sure that your replacement data file still contains the information (indicators, filters, geographic_levels and time_periods) that was used to create them.\n\n\n\nIf it’s not possible for a data block or footnote to be recreated using the replacing data file a warning will appear and you’ll be prompted to either edit or delete them before completing the replacement.\n\n\n\n\nRemember to double check any data blocks or footnotes that were recreated by the platform before publishing your release."
  },
  {
    "objectID": "publishing-statistics/ees.html#footnotes",
    "href": "publishing-statistics/ees.html#footnotes",
    "title": "Using Explore Education Statistics",
    "section": "Footnotes",
    "text": "Footnotes\n\nFootnotes are added via footnotes tab - rather than writing multiple tables and assigning individual footnotes, you write footnotes and assign them to certain indicators and filters so they appear when users select them in the table builder. For example in the below, the footnote “This is a footnote” is assigned to “Headcount” indicator for all options within the “School type” filter.\n\n\n\nIf you’d rather, you can assign a footnote to the whole data file by ticking this box.\n\n\n\nYou can assign the same footnote across multiple data files.\n\nWe recommend that you only add footnotes once you are certain the data file is final. If you have to delete the data file, all the assigned footnotes will be deleted alongside it."
  },
  {
    "objectID": "publishing-statistics/ees.html#data-blocks-tables-and-charts",
    "href": "publishing-statistics/ees.html#data-blocks-tables-and-charts",
    "title": "Using Explore Education Statistics",
    "section": "Data blocks (tables and charts)",
    "text": "Data blocks (tables and charts)\n\nA data block is a smaller cut of data from your original file that you can embed into your publication as a presentation table, build charts from, or link users directly to.\n\n\nTables\n\nHere you can create data blocks, using the admin table tool to create and save your summary tables. Remember to use the reorder table headers tool to restructure your table however you want it before you save.\nOnce you’re happy with your table, give it a title and some source information before clicking save. The source should be the source of the data used to create the data file that was then used for the data block table, for example ‘School Census’.\nThe manage data blocks page will list all the data blocks you have created, highlighting which have charts, are used in content and are saved as highlight tables.\n\n\n\n\n\nFeatured tables\n\nYou can also choose to highlight a data block table as a ‘featured table’ which means it will show in a list of featured tables within the table tool. This is designed to help users get to tables of interest more quickly (without having to create tables themselves).\nThere is an option to choose if a table is a ‘featured table’ when saving each data block, here you can name the table and add a description giving the table coverage:\n\n\n\nEach featured table will then be listed to the user within the table tool. Featured tables do not have to be embedded within your release content to be included in this list.\n\n\n\n\n\n\nFast track links\n\nAny data block tables that are created and saved within the admin app will also be assigned a ‘fast-track link’, this url can then be used throughout your release as a way to direct users to specific tables (within the table tool) more quickly so they can interact and explore the data further. It will appear at the top of the page like this:\n\n\n\nWhen your release is published, any embedded data block tables within the release will have an ‘explore data button’ beneath them which will utilise these fast track links to quickly direct users to the table within the table tool so they can explore the data further. You can also use fast-track links as a hyperlink within release commentary (without having to embed the data block).\nIn your fast-track titles, you don’t want to overload information, but still want to direct the user to the right place. Remember they can go back to the table tool through your featured tables to change filters and indicators as needed.\nFast-track titles should explain:\n\nWhat the table is showing in the simplest terms\nWho/Where the data covers (e.g. characteristic groups and geography levels)\nWhen the data in the table is reported for\n\nHere are a few examples of good fast-track titles in EES:\n\nNumber of Schools and Pupils, by School Type, 2015/16 to 2020/21\nAbsence Rates by School Type, 2016/17 to 2020/21\nFree School Meals, by Region, 2015/16 to 2020/21\n\n\nWhat is the difference between a fast-track link and a permalink?\nEES also offers ‘permalinks’ for any table created in the table tool which allows a user to save a link to a permanent, static, version of a table they have created. Analysts can make use of these permalinks when answering queries or in PQ and FOI responses.\nFast-track links are similar to permalinks however instead of linking to a static version of a table they link to an ‘active’ version of the table within the table tool - meaning users can interact and change what’s shown in the table from within the table tool if they choose to.\n\n\n\n\n\nCharts\n\nAfter building and saving a data block table you will see a ‘Chart’ tab appears. This tab will take you to the EES chart builder, where you can choose to add a chart to your data block.\nThe first step to creating a chart is choosing the chart type, currently the EES chart builder can build line charts, horizontal/vertical bar charts (including stacked and clustered) and maps.\nAfter choosing your chart type you then need to work through the following stages to build your chart. In each stage you’ll be shown a live preview as you make changes.\n\n\nChart configuration\n\nWithin the ‘chart configuration’ tab you can add a title, alt text, move the legend and change chart dimensions.\n\nMake sure to review your chart dimensions before you publish. Users should be able to read the labels on the axes and see the legend without having to scroll.\n\n\n\n\nNote, within the vertical and horizontal bar chart types you can also create stacked bar charts by clicking the ‘Stacked bars’ option within the chart configuration tab\n\n\n\nData sets\n\nHere is where you add data to the chart. You can add each series one at a time or all together.\n\n\n\n\n\n\nLegend\n\nYou can edit the chart legend, and styling of your series via the Legend tab.\n\n\n\n\nTo select specify custom colours outside of the defaults, you can double click on the colour codes at the bottom of the colour picked until you get to the type of code you’re wanting to input (e.g. hex code) and then enter the code manually.\n\n\n\n\nX axis (major axis)\n\nHere is where you configure the x-axis: You can alter gridlines, labels, sort, limit and add reference lines.\n\n\n\n\n\n\n\n\n\n\nOption\nWhat it does\n\n\n\n\nSize of axis\nChange the width of the space given to axis tick labels\n\n\nShow grid lines\nTurn grid lines on and off\n\n\nShow axis\nTurn the axis on and off, you can also add a unit to the axis tick labels\n\n\nSorting\nChange how the data within the chart is sorted\n\n\nTick display type\nAlter how often axis tick labels are shown, labels will automatically skip values where there are too many to show without overlapping\n\n\nAxis range\nAlter the range of data shown in the chart\n\n\nLabel\nAdd an axis label, you can also choose the width for the space given to it\n\n\nReference lines\nAdd/remove reference lines to the chart\n\n\n\n\n\n\nY axis (minor axis)\n\nThen follow a similar process for the y axis configuration, play around until the chart looks how you want it to.\n\n\n\n\n\n\n\n\n\n\nOption\nWhat it does\n\n\n\n\nSize of axis\nChange the width of the space given to axis tick labels\n\n\nGroup data by\nChange how the data within the chart is grouped\n\n\nShow grid lines\nTurn grid lines on and off\n\n\nShow axis\nTurn the axis on and off, you can also add a unit to the axis tick labels\n\n\nSorting\nChange how the data within the chart is sorted\n\n\nTick display type\nAlter how often axis tick labels are shown, labels will automatically skip values where there are too many to show without overlapping\n\n\nAxis range\nAlter the range of data shown in the chart\n\n\nLabel\nAdd an axis label, you can also choose the width for the space given to it\n\n\nReference lines\nAdd/remove reference lines to the chart\n\n\n\n\n\n\nChanging chart type\n\nIf you create your chart and then change your mind as to what chart type would be best you can just click to change it and it will try to save all the options that you had applied previously.\n\n\n\n\nRemember to save your chart when you’re done.\n\n\n\n\nMaps\n\nYou can create maps too, currently this is possible for regional, LA and LAD data.\nYou can change the boundaries you are plotting onto via the “chart configuration” tab, the latest boundary file will automatically be selected, but if you are visualising historic data, you may want an older boundary file. Please contact us if the boundary you want to plot is unavailable.\n\n\n\nThen to create a map, add the cuts of data you want to display in the “data sets” tab of the chart builder.\n\n\n\nYou can change the colour scale of the chart in the “legend” tab.\n\n\n\n\n\n\nOther chart types\n\nYou should only use complex charts where there is a clear user need, as simple charts are the easiest for users to understand. If you have a an infographic or a chart that is too complex to build within our chart builder you can use the ‘Choose an infographic as alternative’ option to upload an image to your data block or use the Add embed block feature to embed an R-Shiny based plot (see the section on embedded blocks for further information).\nInfographic alternatives should be .svg format and you can use the sizing options within the data block editor to size your image appropriately.\n\nAccessibility matters for infographics too, consider the following if you do need to upload an image -\n\nKeep them simple\nUse colours that are available in EES - see our visualisation guidance for more details\nDon’t put borders around images\nRead the GSS guidance on the use of colour in visualisations and follow the steps provided to check your visualisations\nTry to avoid adding text to your images other than axis labels and limited annotations. Titles and headings can be added in the “chart configuration” tab instead\n\n\nYou can use R to create infographics and the following code gives an example of how to create a basic line chart or stacked bar chart using the appropriate GSS sequential colour palette.\n# Load the necessary libraries\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# This is the GSS standard categorical colour palette\ngss_categorical_palette <- data.frame(\n  names = c('Dark Blue', 'Turquoise', 'Dark pink', 'Orange', 'Dark grey', 'Light purple'),\n  hex = c(\"#12436D\",    '#28A197', \"#801650\", \"#F46A25\", \"#3D3D3D\", \"#A285D1\"),\n  id = c(1,2,3,4,5,6))\n\n# Set up a dummy data-set.\n# Note the line factor(...,levels=...) allows you to order your filter values in\n# the final plot based on the ordering entered into the levels keyword. If left,\n# it'll default to alphabetical.\ndata <- data.frame(\n  time_period=c(\"2018/19\",\"2018/19\",\"2018/19\",\"2018/19\",\"2018/19\",\"2018/19\",\n                \"2019/20\",\"2019/20\",\"2019/20\",\"2019/20\",\"2019/20\",\"2019/20\",\n                \"2020/21\",\"2020/21\",\"2020/21\",\"2020/21\",\"2020/21\",\"2020/21\"),\n  Filter=c(gss_categorical_palette$names,\n            gss_categorical_palette$names,\n            gss_categorical_palette$names),\n  indicator1=sample(4:16,18,replace=TRUE) +\n    c(gss_categorical_palette$id,gss_categorical_palette$id,gss_categorical_palette$id)*3\n  ) %>%\n  mutate(\n    time_period=as.factor(time_period),\n    Filter=factor(Filter,levels=gss_categorical_palette$names)\n    )\n\n# Create a line chart\nggplot(data, aes(x=time_period, y=indicator1, group=Filter, colour=Filter )) +\n  geom_line(size=1.2) +\n  scale_color_manual(values=gss_categorical_palette$hex) +\n  theme_classic() +\n  theme(\n    legend.position = \"bottom\",\n    text = element_text(size = 14, family = \"Arial\"),\n    strip.text.x = element_text(size = 20)\n  ) +\n  ylab(\"Indicator 1\") +\n  xlab(\"Time period\")\n\n# Create a stacked bar chart\nggplot(data, aes(x=time_period, y=indicator1,  fill=Filter )) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(values=gss_categorical_palette$hex) +\n  theme_classic() +\n  theme(\n    legend.position = \"bottom\",\n    text = element_text(size = 14, family = \"Arial\"),\n    strip.text.x = element_text(size = 20)\n  ) +\n  ylab(\"Indicator 1\") +\n  xlab(\"Time period\")\nThe above code should produce something along the lines of the following plots:"
  },
  {
    "objectID": "publishing-statistics/ees.html#content",
    "href": "publishing-statistics/ees.html#content",
    "title": "Using Explore Education Statistics",
    "section": "Content",
    "text": "Content\n\nIn the content tab you can now start creating your release, embedding the data blocks you’ve created as you go.\n\nYou can use the page view toggles, that float in the bottom left of the page, to jump between edit and preview mode for the release and to view a preview of the table tool.\n\nUse the ‘Add secondary stats’ button to add a data block to your headline stats section.\nUse the ‘Key stats’ options to add key statistic tiles to your release. For each tile you first have to have created a data block that contains only one number.\n\n\n\nAfter embedding a key stat tile you can then edit it to add trend information and a description of what the indicator is.\n\n\n\n\n\n\n\nElement\nContent\n\n\n\n\nIndicator name\nAutomatically generated from your data\n\n\nLatest value\nAutomatically generated from your data\n\n\nTrend\nA short one-sentence description of the trend; try to avoid only stating the change from the previous year and talk about the longer-term trend where appropriate\n\n\nGuidance title\nE.g. ‘What is NEET?’ or ‘What are permanent exclusions?’\n\n\nGuidance text\nA simple description in plain English of what the indicator is\n\n\n\nYou can then create accordion sections to start adding your main release commentary. These sections are made up of text blocks and data blocks which can be reordered as needed.\n\n\nDrafting text\n\n\nDo not use footnotes in the text of your content. They’re designed for reference in print, not web pages. If the information in the footnotes is important, include it in the body text. If it’s not, leave it out.\n\nAny data tables should be included as data blocks, however you can also embed static html tables within a text box. These should only be used to present textual tables or for any small presentations of data that are not possible to do in a data block at the moment.\n\nYou can create static html tables for presenting information that isn’t embedded in a data block. However, remember that all of the data included or referred to in your content should be available (or createable) from the downloadable open data files.\nWhile a release is in draft mode, comments can be added to text to help teams collaborate. Simply highlight the text you want to comment on and click on the speech bubble in the editing bar to add a comment.\n\n\n\nComments can be edited at a later date, and can also be marked as resolved so that you can see which comments have been addressed and which are still outstanding.\nWhen someone is editing a text box, it will now be instantly frozen for all other users preventing two users from editing the same block of text at the same time. You will be able to see the name of the user who is making edits, and will see the edits coming through every few seconds as their changes autosave."
  },
  {
    "objectID": "publishing-statistics/ees.html#embedding-r-shiny-blocks",
    "href": "publishing-statistics/ees.html#embedding-r-shiny-blocks",
    "title": "Using Explore Education Statistics",
    "section": "Embedding R-Shiny blocks",
    "text": "Embedding R-Shiny blocks\n\nIf you need to include a type of chart that isn’t possible using the standard EES chart options, for example an interactive chart with filters, you can embed a block to display a custom R-Shiny produced chart.\nTo embed a shiny chart, you’ll first need to create an R-Shiny application containing the chart using the DfE tiny-shiny template and get it hosted on our DfE GitHub and ShinyApps accounts. More details on both of these are available in the tiny-shiny section of this guidance.\nOnce you’ve got the R-Shiny app set up and hosted, you can embed it using the Add embed block button in the content area. This will give you the option to enter a URL, where you can enter the URL of the shiny app. Valid URLs to use in the embed block dialogue box are limited to only those on the DfE ShinyApps server (and the internal rsconnect when needed for draft publications).\n\n\n\nThe EES interface for embedding a Shiny chart"
  },
  {
    "objectID": "publishing-statistics/ees.html#glossary",
    "href": "publishing-statistics/ees.html#glossary",
    "title": "Using Explore Education Statistics",
    "section": "Glossary",
    "text": "Glossary\n\nOur glossary on EES is a growing page that helps us to standardise how refer to key terms and phrases across all of Official statistics - https://explore-education-statistics.service.gov.uk/glossary.\n\n\nAdding new definitions\n\nContact us at explore.statistics@education.gov.uk, with the title and definition and we can add this for you. It’s worth having a check on the glossary for similar or related terms, and whether you should be looking to harmonise with other teams.\n\n\n\nLinking to definitions\n\nYou can link to any term in the glossary by appending the glossary url with #name-of-definition, replacing any spaces with hyphens.\nFor example, to link to the definition for ‘Respite care’, you would use the following link:\nhttps://explore-education-statistics.service.gov.uk/glossary#respite-care\nYou can test this works by typing the url into your browser, it should take you to that specific definition on the glossary page. If you’re unsure at all, or have special characters in the title of your glossary entry, please ask us for support on getting the right link.\n\n\n\nLinking from your release\n\nWhen writing your release content, highlight a word or phrase and click the link icon in the text editor bar.\n\n\n\nThen, paste your glossary url into the box that appears.\n\n\n\nThat’s it, the system will automatically recognise that the link is for the glossary and will do the rest. You can then change to the preview mode to see how this would then appear to public users, and test that the box appears with the definition."
  },
  {
    "objectID": "publishing-statistics/ees.html#sign-off",
    "href": "publishing-statistics/ees.html#sign-off",
    "title": "Using Explore Education Statistics",
    "section": "Sign off",
    "text": "Sign off\n\nOnce you’re happy with your release you need to go to the sign off page and change it’s status in order to move it through the release pipeline.\nThere are three statuses:\n\nIn draft (where the production team work on drafting the release)\nReady for higher review (where the senior statistician checks over the release before approving)\nApproved for publication (after approval has been given, releases in this status will be published on their scheduled date)\n\n\nOnly users with ‘approver’ permissions(#Roles_and_permissions) (usually G6 or above) can sign off the release for publication.\n\n\n\nErrors and warnings\n\nThere’s quite a few things to remember to do as you build your release so to help ensure you haven’t missed anything a release checklist is also available via the sign off page\nThe checklist can be accessed by clicking to edit release status.\nRemember to check over it before you submit your release for approval as a release that has outstanding warnings on it will not be able to be published.\n\n\n\n\n\n\nHow to approve a release\n\nReleases are approved via the sign off tab. The release date is also set during this stage of the process. All releases scheduled for a specific date will be published at 9:30am on that day.\n\n\n\nThe approver has the ability to approve the release to be published on a specific date or to publish as soon as possible. Publishing as soon as possible is useful for publishing amendments to existing releases.\n\nThis page also gives you the expected release url which may be useful to know for other things, for example, sending to the web team to add to your gov.uk announcement page.\n\n\n\n\nNext release expected\n\nYou also have the option to add a date for when the next release is expected. This will appear at the top of a release page and give users an idea of when to expect the next release in the publication series. You can provide the planned month and year of the next release within this publication.\nIf this is added but then needs to be changed or removed later in the year it is easy to do so, by creating an amendment and setting a new next release expected date on sign-off."
  },
  {
    "objectID": "publishing-statistics/ees.html#pre-release-access",
    "href": "publishing-statistics/ees.html#pre-release-access",
    "title": "Using Explore Education Statistics",
    "section": "Pre-release access",
    "text": "Pre-release access\n\nPrior to each release going live the production team are also able to grant pre-release access to a named group of users 24 hours before it goes live. These users do not require full access to the whole admin service. They will be able to see preview versions of any releases they have been granted access to.\nThis preview is only accessible for the 24 hours before the publication date, the emails may go out to users before then. We expect teams will continue to send an email at 09:30 on pre-release day, including any additional briefing and the link to the pre-release area.\n\nJobshare emails should not be sent invites for pre-release. The personal emails for the specific individuals should be used instead, as jobshare emails do not have active accounts with DfE to access EES.\n\n\nPre-release access via Explore Education Statistics is currently limited to DFE users only, if you need to share your release with external users you will need to do so outside of the system.\n\n\n\n\n\nEES PRA one pager\n\n\n\n\n\n\n\n\n\n\n\nInviting users for pre-release access and building the public pre-release list can be found within the ‘Pre-release access’ tab on the dashboard.\nOnce the release has been marked as approved, go to the ‘Pre-release access’ tab and add the relevant email addresses to grant pre-release access. All invited users will receive an email to say that they have been given pre-release access and will get a url where the preview release will be available.\n\n\n\nYou should also create the public facing pre-release access page by clicking the ‘Public access list’ tab.\n\n\n\nAfter creating your pre-release access list a text editor will appear where you can list the roles that have been given early access to the release. This list will then appear in the list of file downloads at the top of each release."
  },
  {
    "objectID": "publishing-statistics/ees.html#release-notes",
    "href": "publishing-statistics/ees.html#release-notes",
    "title": "Using Explore Education Statistics",
    "section": "Release notes",
    "text": "Release notes\n\nWhen publishing a new amendment you should add a ‘release note’ to your release so users can be informed of what has changed:"
  },
  {
    "objectID": "publishing-statistics/ees.html#methodology-formatting",
    "href": "publishing-statistics/ees.html#methodology-formatting",
    "title": "Using Explore Education Statistics",
    "section": "Methodology formatting",
    "text": "Methodology formatting\n\nSubheadings make it easier for your users to navigate through your methodology. When editing text blocks in your methodology, you can do this by highlighting your subheading and selecting “Heading 3” in place of “Paragraph”:\n\n\n\nYou can add further subheadings underneath this but try to limit the number of subheadings per accordion to 10 at the most. Too many subheadings will make it tricky for users to find what they are looking for."
  },
  {
    "objectID": "publishing-statistics/ees.html#methodology-images",
    "href": "publishing-statistics/ees.html#methodology-images",
    "title": "Using Explore Education Statistics",
    "section": "Methodology images",
    "text": "Methodology images\n\nYou can add images to methodology pages via the content editor.\n\n\n\nWhen uploading an image you will need to add alt text via by clicking the eye symbol, you may also choose to add an image caption.\n\n\n\n\nAccessibility matters for uploaded images too, consider the following if you do need to upload an image -\n\nKeep them simple\nUse GDS colours\nDon’t put borders around images\nEnsure there is a high enough colour contrast ratio between elements. You can use a colour contrast checker to check the colours you’re using\nTry to avoid adding text to your images other than axis labels and limited annotations."
  },
  {
    "objectID": "publishing-statistics/ees.html#publication-management",
    "href": "publishing-statistics/ees.html#publication-management",
    "title": "Using Explore Education Statistics",
    "section": "Publication management",
    "text": "Publication management\n\nUse this page to change the details for your publication, such as the contact information or to add links to legacy releases on gov.uk.\nAny updates here will affect all releases in the series and will be published immediately.\n\nIt is possible to change the publication title via this page, however this should be used rarely and will not affect the publications url if one or more published releases exist."
  },
  {
    "objectID": "publishing-statistics/ees.html#create-new-release",
    "href": "publishing-statistics/ees.html#create-new-release",
    "title": "Using Explore Education Statistics",
    "section": "Create new release",
    "text": "Create new release\n\nAfter finding the publication you want to create a release for, just press the button to create a new release.\nCurrently the following types of release can be created in EES:\n\nNational Statistics (includes OSR tick mark logo at the top of the release page)\nOfficial Statistics\nAdhoc Statistics\n\nWhen creating a release you will be asked to fill in some release summary fields.\n\nThe time period for the release should reflect the time period of the data that this latest release adds to the time series."
  },
  {
    "objectID": "publishing-statistics/ees.html#managing-legacy-releases",
    "href": "publishing-statistics/ees.html#managing-legacy-releases",
    "title": "Using Explore Education Statistics",
    "section": "Managing legacy releases",
    "text": "Managing legacy releases\n\nPast publications on other services can be added to the previous releases links that appear on the top right of a release page by using the ‘Manage legacy releases’ section. In here you can add links to previous releases and choose the order in which they appear.\nThis section can be found by publication owners in the publication management section."
  },
  {
    "objectID": "publishing-statistics/embedded-charts.html",
    "href": "publishing-statistics/embedded-charts.html",
    "title": "Creating embedded visualisations",
    "section": "",
    "text": "Guidance for creating and embedding R-Shiny visualisations in EES publications"
  },
  {
    "objectID": "publishing-statistics/embedded-charts.html#when-to-use-an-embedded-chart",
    "href": "publishing-statistics/embedded-charts.html#when-to-use-an-embedded-chart",
    "title": "Creating embedded visualisations",
    "section": "When to use an embedded chart",
    "text": "When to use an embedded chart\n\nEES provides a wide range of inbuilt chart options and will always be the first preference for static line, bar and geographical charts. This helps us to clearly maintain consistent styling and accessibility levels across the site.\nHowever, there are some instances where you might want to publish something that we can’t provide through EES. Example use cases would be:\n\ninteractive charts controlled by drop-down filters;\nchart types not provided by EES, e.g. sankey diagrams, box plots, waffle charts, pie charts, dumbbell charts, etc."
  },
  {
    "objectID": "publishing-statistics/embedded-charts.html#tools",
    "href": "publishing-statistics/embedded-charts.html#tools",
    "title": "Creating embedded visualisations",
    "section": "Tools",
    "text": "Tools\n\nWe currently only support custom charts created using R-Shiny. These should be created with ggplot and plotly. We provide a template example of a demo R-Shiny/ggplot chart on the DfE Analytical Services GitHub site, which is described below."
  },
  {
    "objectID": "publishing-statistics/embedded-charts.html#review-and-authorisation",
    "href": "publishing-statistics/embedded-charts.html#review-and-authorisation",
    "title": "Creating embedded visualisations",
    "section": "Review and authorisation",
    "text": "Review and authorisation\n\nTo get a custom chart approved for embedding within a publication, you’ll need to get it reviewed by the Statistics Development team (in addition to your standard approval chain)."
  },
  {
    "objectID": "publishing-statistics/embedded-charts.html#the-dfe-tiny-shiny-template",
    "href": "publishing-statistics/embedded-charts.html#the-dfe-tiny-shiny-template",
    "title": "Creating embedded visualisations",
    "section": "The DfE Tiny-Shiny template",
    "text": "The DfE Tiny-Shiny template\n\nOur template tiny shiny app repository should be used a starting point for all embedded shiny charts.\nTo get an app set-up for use with EES, you’ll need the Statistics Development Team team to create a repo for the app within the DfE Analytical Services area on GitHub."
  },
  {
    "objectID": "publishing-statistics/embedded-charts.html#whats-in-the-template",
    "href": "publishing-statistics/embedded-charts.html#whats-in-the-template",
    "title": "Creating embedded visualisations",
    "section": "What’s in the template",
    "text": "What’s in the template\n\nThe template provides code for some basic interactive plots. Each example plot is contained with one of the existing branches below for demonstration purposes:\n\ndemo-interactive-bar\ndemo-interactive-line"
  },
  {
    "objectID": "publishing-statistics/embedded-charts.html#working-with-data",
    "href": "publishing-statistics/embedded-charts.html#working-with-data",
    "title": "Creating embedded visualisations",
    "section": "Working with data",
    "text": "Working with data\n\nAs with the full dashboards, the embedded charts currently require the underlying data to be either included within the app repository on GitHub or uploaded elsewhere publicly accessible such as Google Drive or Dropbox. This currently means that any embedded charts being developed will need to use either dummy data or previously published data until the moment of publication. At the point of the parent release going live, the chart can then be updated with the latest data. Do not upload unpublished data to GitHub, Google Drive or Dropbox.\nAs described earlier, where you need to use unpublished data in your chart prior to publication, you can either a) run the chart locally in R-Studio (without pushing the unpublished data to GitHub) or b) create a DevOps/rsconnect deploy of your app, which can be temporarily used as the embed block URL. Note, this will need updating to a URL to the public dashboard on ShinyApps ready for publication.\nWe are currently developing a route to allow charts via R-Shiny apps to be hosted on DfE servers, such that draft publications will be able to incorporate embedded charts with the unpublished data. The data itself will then be accessed either from a SQL database on DfE servers."
  },
  {
    "objectID": "publishing-statistics/embedded-charts.html#specific-design-recommendations-for-embedded-plots",
    "href": "publishing-statistics/embedded-charts.html#specific-design-recommendations-for-embedded-plots",
    "title": "Creating embedded visualisations",
    "section": "Specific design recommendations for embedded plots",
    "text": "Specific design recommendations for embedded plots\n\nExample code for producing an embeddable shiny chart is given in the template tiny shiny app repository. The following recommendations should be followed in adapting this code:\n\nFigures should be produced using plotly/ggplot2\nFigure lengths and heights should be in the range 6-10cm\nText sizes in plots should be no smaller than 12pt\nPlotly overlays should be turned off\n\nExample code for creating charts using ggplot can be found in the Using Explore Education Statistics guidance"
  },
  {
    "objectID": "publishing-statistics/examples.html",
    "href": "publishing-statistics/examples.html",
    "title": "EES - good practice examples",
    "section": "",
    "text": "Examples of good practice in EES, from file names to content"
  },
  {
    "objectID": "publishing-statistics/examples.html#files",
    "href": "publishing-statistics/examples.html#files",
    "title": "EES - good practice examples",
    "section": "Files",
    "text": "Files\n\nFiles can be downloaded from multiple areas across the platform and often users will judge their contents based on the name alone. For display names, it’s important we make it as clear as possible to users as to what each file contains without cluttering the title with information that is already available from the page around it, saving detailed coverage for the data guidance.\n\n\nFile names\n\nFull guidance for naming files.\nThe Education and training statistics for the UK release has some good examples of file names which clearly explain what is in the file, while falling well under 35-50 characters in length, e.g.:\n\nuk_schools.csv\nuk_expenditure.csv\nuk_pupils.csv\n\nThe file names do not have time periods in them, making them easier for users to make use of newer versions in future\n\n\n\nSubject names\n\nFull guidance for naming subject files.\nThe School Workforce Census applies this guidance well, with short and simple titles that make sense to a non-expert, e.g.:\n\nTeacher pay\nTeacher retention\nSubjects taught\n\nThese titles are not cluttered with geographies and time periods, which automatically populate in the subject metadata.\n\n\n\nSupporting files\n\nFull guidance for using supporting files in EES.\nThe Initial Teacher Training performance profiles publication is one example of needing to upload a file outside of the regular data/metadata structure. Their provider-level tables also contain national and regional data, which is not supported in EES at the time of writing. The file has a clear title, and data guidance clearly explains what is in the file."
  },
  {
    "objectID": "publishing-statistics/examples.html#data-guidance",
    "href": "publishing-statistics/examples.html#data-guidance",
    "title": "EES - good practice examples",
    "section": "Data guidance",
    "text": "Data guidance\n\nThe public data guidance is a key element of your release, to help direct users to the right file to download or build tables with. It is frequently highlighted by users of our stats as a really helpful element of EES. You will be prompted to fill in data guidance in the release checklist. Any release that does not have a complete public data guidance will not be blocked from approval and publishing.\n\n\nPublic data guidance\n\nFull guidance for public data guidance.\nThe School Workforce Census, along with having sensible brief file names, also has great examples of useful data guidance, which explain what is in each file without overloading the user with information:\n\n\n\n\n\n\nPublic data guidance - overview\n\nFull guidance for public data guidance.\nThe NEET annual brief is a good example of a public metadata overview section done well. It follows the EES template, goes into just the right amount of detail, and is easy to understand.\n\n\n\nNEET data guidance on EES."
  },
  {
    "objectID": "publishing-statistics/examples.html#charts-and-tables",
    "href": "publishing-statistics/examples.html#charts-and-tables",
    "title": "EES - good practice examples",
    "section": "Charts and tables",
    "text": "Charts and tables\n\nCharts and tables are key ways to highlight important information and stories in your release. They should be clear, contain few footnotes that are essential to interpreting the chart or table, and have good descriptive alternative text so users with screen readers can understand what is being visualised.\n\n\nOther infographics\n\nFull guidance on using charts built outside of EES.\nThe Further Education: outcome based success measures release contains infographics that cannot be built in EES. They are saved as SVGs so render clearly on any device, and follows the same colour palette as the rest of the release.\n\n\n\n\n\n\nCharts and footnotes\n\nFull guidance on creating charts, and guidance on creating footnotes.\nThe Widening participation in higher education publication has a good example of a chart built with a long timeseries in the chart builder, with sparing use of footnotes. For example below, a line in the chart indicates a point where comparisons cannot be made, and a key caveat around the comparability of years is included as a footnote, which is needed to interpret the data and chart accurately.\n\n\n\n\n\n\nAccessibility and alt-text\n\nGood alt-text descriptions in charts will not just repeat the title of the chart, but instead describe the type of chart, what the data coverage is, and what trends can be seen in the chart to a user accessing the page with a screenreader.\nThe school workforce census has a good example of alt-text for one of their charts. The associated alt-text for the chart below is: “Line chart showing the percentage of all teachers taking absence across all state funded schools in England between the academic years 2014/15 and 2018/19. The chart shows a fall from 55.7% to 54.0% in this period.”\n\n\n\n\n\n\nFeatured tables\n\nFull guidance on creating featured tables.\nGood featured tables have short, easy to understand titles, and point users to commonly requested tables or other tables that might be interesting to a wide range of users. For example, the pupil absence in schools: autumn term release has a good example of a clear title, with further information (including date and geographic coverage) left in the description. Leaving these out of the main title makes it much easier for users to navigate through multiple featured tables:"
  },
  {
    "objectID": "publishing-statistics/examples.html#content",
    "href": "publishing-statistics/examples.html#content",
    "title": "EES - good practice examples",
    "section": "Content",
    "text": "Content\n\nClear, concise content is required to direct your users to the right place, and keep them engaged with your release. Our content guidance page contains a raft of great advice on how to structure your release and write for the general public.\n\n\nHeadlines\n\nFull guidance on creating a headline section\nThe Education, health and care plans release has a good example of a headlines section. There are a sensible number of key statistics, and the summary below gives an overview of trends without diving into the numbers and overwhelming the user.\n\n\n\nThe Exclusions release has a good example of custom explanations under key stat tiles to show users exactly what the numbers are describing:\n\n\n\n\n\n\nAccordion content\n\nFull guidance on writing content for accordions\nThe parental responsibility measures release has good examples of writing for the public in accordion content. Content in each accordion is short and follows the “pyramid” principle of having essential information at the top, summarising the trend, then going into detail at the bottom.\n\n\n\nActive subheadings\n\nFull guidance on using active headings and titles\nThe EHCP release has some great examples of active subheadings within accordions, which explain the overall trends without overloading users with detail.\n\n\n\nGlossary links\n\nThe summary of the CIN / CLA outcomes release has examples of this in action.\n\n\n\nMethodology\n\nFull guidance on creating a methodology in EES.\nGood methodologies will broadly cover topics in our recommended methodology template. The Graduate outcomes (LEO) methodology broadly follows this outline, making use of effective formatting in EES to help users navigate through accordions, although definitions can be moved to the EES glossary.\nThe Key stage 4 destinations methodology makes good use of annexes to show changes to their methodology over time."
  },
  {
    "objectID": "publishing-statistics/examples.html#approvals-and-amendments",
    "href": "publishing-statistics/examples.html#approvals-and-amendments",
    "title": "EES - good practice examples",
    "section": "Approvals and amendments",
    "text": "Approvals and amendments\n\nKeeping track of processes for approving and amending releases is crucial for transparency. Internally, there should be clear paper trail of who has signed off the release, and externally, users need to know if anything in the release has changed from the last time they saw it.\n\n\nPublic amendment notes\n\nFull guidance for creating public amendment notes.\nThe Pupil absence in England - Autumn and Spring terms publication has some good examples of release notes.\nThese notes clearly explain to the user what has changed, which files were affected and at what level:\n\n\n\n\n\n\nInternal release status notes\n\nFull guidance for creating public amendment notes.\nThe COVID attendance publication has fortnightly releases at the time of writing, and the team have a good process for sign-off. This includes detailed information at each stage to confirm who has signed off, who has requested an action be taken, and who has carried out the action."
  },
  {
    "objectID": "publishing-statistics/pub.html",
    "href": "publishing-statistics/pub.html",
    "title": "How to publish",
    "section": "",
    "text": "Guidance for how to publish different types of statistics"
  },
  {
    "objectID": "publishing-statistics/pub.html#how-to-publish",
    "href": "publishing-statistics/pub.html#how-to-publish",
    "title": "How to publish",
    "section": "How to publish",
    "text": "How to publish\n\n\n\n\nEES create release one pager"
  },
  {
    "objectID": "publishing-statistics/pub.html#publication-checklist",
    "href": "publishing-statistics/pub.html#publication-checklist",
    "title": "How to publish",
    "section": "Publication checklist",
    "text": "Publication checklist\n\nBefore releasing statistics for the first time you may want to discuss the new process with key stakeholders and/or pre-release users to make them aware of the new service. You should also inform the Explore Statistics Mailbox and HoP Office teams.\nBefore you start creating a release in the platform you should have:\n\nAnnounced the upcoming release via gov.uk\nSent metadata form to HoP\nContacted the BAU team so we can support you with your first release\nProduced your tidy csv data files with appropriate disclosure control\nProduced metadata files for each csv data file\nRan your data and metadata through our screener checks\n\nBefore you publish a release you have created in the platform you should have:\n\nChecked all the data has loaded successfully\nWritten footnotes\nWritten content (including tables and charts)\nCreated a data guidance document\nCreated a public pre-release access list\nEnsured methodology information is either linked off to or attached to the release\nPassed the release for higher review (senior sign-off)\nPreviewed your release\nScheduled the release date\nInvited your PRA list to preview 24 hours before it goes live\nRaised a web ticket for the associated gov.uk page\n\n\nWord templates for the data guidance, pra-list, and content can be found on sharepoint."
  },
  {
    "objectID": "publishing-statistics/pub.html#linking-to-gov.uk",
    "href": "publishing-statistics/pub.html#linking-to-gov.uk",
    "title": "How to publish",
    "section": "Linking to gov.uk",
    "text": "Linking to gov.uk\n\nYou will need to arrange a gov.uk statistics publication page so that it links to EES. Here is how to do that:\nTwo days ahead of publication, you’ll need to raise a ticket with the Digital communications (gov.uk) team and ask them to create a new gov.uk statistics page with a link to EES, connect it to the announcement and add to any collections.\nIn your request, you’ll need to include:\n\ntitle, summary sentence and ‘detail’ for the new page – you can include a link to previous releases if you want it to be the same\nthe link for your EES release – if you don’t have it you can update the ticket when the link is available\nthe link for the announcement\nthe link of any gov.uk collections it needs to be added to\nan email with clearance from your deputy director\nan email confirming communications are happy for it to go if it’s for stats that aren’t pre-announced or it’s an update to stats made after publication – so that they can prepare reactive lines\n\nHere are examples of how the page will look like:\n\nPrimary School Performance Tables 2018\nHigher Education Student Statistics 2018 to 2019\n\n\nYou can find what the link to your EES release will be by looking at the ‘Sign off’ page within the release dashboard on EES.\n\n\n\n\nText to update the collection page:\nIn addition, you will also need to raise a ticket with the Digital communications (gov.uk) team to update your collection page/s with the following text:\n\nFrom [publication date], the Department for Education will be publishing the [publication title] on a new statistics site, Explore Education Statistics (EES).\n\nWhen you raise the ticket please ensure that all the documents you submit are in an accessible format as stated in the accessibility guidance. There is also guidance on accessibility for Excel workbooks in Teams."
  },
  {
    "objectID": "publishing-statistics/pub.html#how-to-publish-1",
    "href": "publishing-statistics/pub.html#how-to-publish-1",
    "title": "How to publish",
    "section": "How to publish",
    "text": "How to publish\n\nAhead of publication, you’ll need to raise a ticket with the Digital communications (gov.uk) team and ask them to create a new release (or add to a series if this already exists).\n\nIn your request, you’ll need to include:\n\ntitle, summary sentence and ‘detail’ for the new page\nthe link for the announcement\nthe link of any gov.uk collections it needs to be added to\nan attachment with the accessible data files\nan email with clearance from your deputy director\n\nWhen you raise the ticket please ensure that all the documents you submit are in an accessible format as stated in the accessibility guidance. There is also guidance on accessibility for Excel workbooks in Teams."
  },
  {
    "objectID": "publishing-statistics/pub.html#publication-checklist-1",
    "href": "publishing-statistics/pub.html#publication-checklist-1",
    "title": "How to publish",
    "section": "Publication checklist",
    "text": "Publication checklist\n\n\nBefore you start creating your release you should have:\n\nAnnounced the upcoming release via gov.uk\nSent metadata form to HoP\n\nBefore you publish a release you should have:\n\nChecked that the data meets accessibility requirements, ideally as a .csv file, or an accessible Excel file where this is not possible\nWritten footnotes where appropriate\nPassed the release for higher review (senior sign-off)\nSent the final files and sign-off email to the digital communications (gov.uk) team"
  },
  {
    "objectID": "publishing-statistics/pub.html#how-to-publish-2",
    "href": "publishing-statistics/pub.html#how-to-publish-2",
    "title": "How to publish",
    "section": "How to publish",
    "text": "How to publish\n\nWe recommend that teams use R Shiny to build and publish apps. Shiny apps are easily made accessible, and underlying code for Shiny apps can be published alongside for transparency.\nMore information to follow."
  },
  {
    "objectID": "publishing-statistics/pub.html#publication-checklist-2",
    "href": "publishing-statistics/pub.html#publication-checklist-2",
    "title": "How to publish",
    "section": "Publication checklist",
    "text": "Publication checklist\n\nMore information to follow, contact the Statistics Development team in the meantime."
  },
  {
    "objectID": "understanding-users/user-eng.html",
    "href": "understanding-users/user-eng.html",
    "title": "User engagement",
    "section": "",
    "text": "Guidance on understanding and engaging with the users of published statistics"
  },
  {
    "objectID": "understanding-users/user-eng.html#user-hub",
    "href": "understanding-users/user-eng.html#user-hub",
    "title": "User engagement",
    "section": "USER hub",
    "text": "USER hub\n\nThe USER hub is now available on the GSS website, this is a central resource to help producers of statistics develop the knowledge, skills and techniques needed to engage effectively with their audiences."
  },
  {
    "objectID": "understanding-users/user-eng.html#improving-your-own-engagmenent",
    "href": "understanding-users/user-eng.html#improving-your-own-engagmenent",
    "title": "User engagement",
    "section": "Improving your own engagmenent",
    "text": "Improving your own engagmenent\n\nDownload this top tips document produced for the GSS, as a starting point for understanding how you can improve your user engagement.\nThrough our work engaging users on EES we have built up a list of interested users who have stated a willingness to be contacted about opportunities to be involved in user testing of our statistics on the platform, if you have any suggestions for things for us to test on EES with these users, please contact explore.statistics@education.gov.uk.\nMore advice and guidance will follow in this space. In the meantime, if you’re interested in user engagement please contact Heather Brown."
  },
  {
    "objectID": "understanding-users/user-eng.html#case-studies",
    "href": "understanding-users/user-eng.html#case-studies",
    "title": "User engagement",
    "section": "Case studies",
    "text": "Case studies\n\n\nExplore Education Statistics service\n\nExplore Education Statistics was born from a discovery project, where the emphasis of the discovery was to understand who the users of the Department’s official statistics are, what they need, and where the DfE are currently meeting, exceeding or failing to meet those needs. We spoke to over 90 users directly, via 1 to 1 sessions or workshops and had over 130 survey responses. We used this research to create user personas and user stories which we then assessed ourselves against to see how well we were meeting those needs - the result of this was a recommendation that we needed to do something better. Our discovery report is published on gov.uk.\nFollowing the discovery we moved through to the alpha phase, where we built prototypes and carried out extensive user testing to firm up the functionality that might be required - focussing on different user journeys and the user experience at each step. We then passed a GDS service assessment where our approach was tested against the GDS service standard before moving into the private beta phase where we started building the service for real. We user-tested every bit of the journey thoroughly and used feedback from users to iterate on the functionality we were making available. User testing was primarily through 1 on 1 sessions where users would be set activities to work through and we would watch how the user clicked through each part of the relevant journey and to ask what they might expect to see at any different steps of the process - both when creating/publishing statistics releases and using releases after publishing. We also ran workshops and carried out user surveys to collect as much evidence as possible, for more information on this take a look at the write up of our private beta phase on Hive IT’s website.\n\n\n\n\n\n\n\n\n\nIn March 2020 we wrapped up the build of the service and were given the green light via a GDS service assessment to move into our public beta phase. That’s when we started using the service for real and teams started publishing statistics via EES only. Ongoing user feedback has been really important throughout public beta as it has helped us move the service from a minimal viable product to one that works in the best way possible for everyone. We also use this engagement to help us understand how well we are meeting our KPIs, which we review regularly to see how well we are meeting the original aims of the service thinking back to our original discovery and what users told us they needed. There are a number of ongoing feedback routes open to users during the public beta phase of the service:\n\nBeta banner (service focus) Users can submit feedback through the beta banner from any EES page, and responses are managed by the statistics development team. Feedback so far has mostly been aimed at the service functionality more generally but we do regularly get publication specific feedback which we share with the relevant teams.\nFormal user testing (service focus) Our EES team will speak to users via user testing sessions to help inform future iterations to functionality.\nIn-release feedback requests (publication focus) Some teams have been including specific calls for feedback within their release pages e.g. - https://explore-education-statistics.service.gov.uk/find-statistics/apprenticeships-and-traineeships\nGoogle analytics We collect user analytics to help us understand what users are doing with our statistics. This information is shared with production teams via our EES analytics app.\n\nFor more information, get in touch with the team at explore.statistics@education.gov.uk.\n\n\n\nSchool places local authority scorecard\n\nIn 2021 the annual ‘Local Authority School Places Scorecard’ publication was cancelled, due to Covid- 19, allowing time for user-engagement and development of the scorecard. This is a dashboard publication allowing users to select a specific local authority in England, to view it’s progress in providing quality school places. Firstly, internal feedback was sought and received, and generally users found the Scorecard a useful tool. Longer-term additions were identified, however short-term development was also needed to improve the accessibility of the Scorecard so this was the first developmental focus. The Scorecard has been previously published as an excel-based dashboard, however this method of publication was no longer viable due to new rules and regulations for official statistics publications. A new platform was therefore needed and R shiny was suggested as an accessible platform. A new version of a previously published scorecard was produced in R shiny. This was then published externally to gather feedback from users to check they could obtain the required information. The scorecard contained a link to a short survey and over 90 internal and external users responded (after email invitations were sent allowing a month to complete). Most users found the R shiny version easier to use compared to the excel based dashboard which was positive. Suggestions for improvement were gathered and quite a few users mentioned they missed the one-page format of the excel scorecard (the R shiny version has tabs to get to some visualisations) and found some of the newer charts slightly confusing. Therefore solutions were proposed e.g. a downloadable one page PDF summary and alternative charts/clearer guidance. Development work is still ongoing with the new R shiny scorecard due for publication in June 2022. When published this should include improvements to address the most frequent suggestions mentioned in the survey, to ensure users can gather the information they need from the scorecard. For any further information contact Natalie Paterson in the Pupil Place Planning Data team.\n\n\n\nCIN-CLA outcomes statistical release\n\nIn 2020 we created a new statistical release which incorporated changes to the annual Outcomes for children looked after by LAs statistical release and outcomes within the Characteristics of children in need statistical release, proposed by the department in September 2020. Improving these statistics was a commitment made at the end of the CIN review. As part of the review of the National Statistics, an ad-hoc release was published (Outcomes of children in need including looked after children) and we asked users to submit feedback on the proposals through the running of a consultation via Gov.UK to which people could respond (Children in need and looked after children statistics: proposed changes). We involved policy colleagues (including policy analysts) in the proposed changes ahead of publishing. We engaged with colleagues across the department to identify known users and user groups and notified them of the request for feedback on the proposals We also followed up with a reminder as we got closer to the deadline. As part of this process, we had a meeting with the main stakeholders (the board of the National Association of Virtual School Heads). These key were very keen to respond to the proposals but were having difficulty with resource and time to provide a comprehensive response, so we agreed to have a meeting to talk through everything and we took notes. Reaching out to users and actively engaging with them produced a great result - we received a wide range of feedback from a range of sources including previously unknown users. We received external and internal feedback. We published the results of the feedback on the proposals on gov.uk, including a summary of the feedback received and what we were able to incorporate into the new publication. This was not an official Government consultation and we had to negotiate with gov.uk on how to publish the documents. We were advised that going forward, it would be preferable for user engagement of this type to be published alongside the statistical releases as part of the new EES platform. For any further information contact Bree Waine."
  },
  {
    "objectID": "understanding-users/user-eng.html#what-is-user-engagement",
    "href": "understanding-users/user-eng.html#what-is-user-engagement",
    "title": "User engagement",
    "section": "What is user engagement?",
    "text": "What is user engagement?\n\n\n\n\n\nThe ONS have also published ten top tips to help improve user engagement."
  },
  {
    "objectID": "understanding-users/user-eng.html#user-engagement-successes",
    "href": "understanding-users/user-eng.html#user-engagement-successes",
    "title": "User engagement",
    "section": "User engagement successes",
    "text": "User engagement successes"
  },
  {
    "objectID": "understanding-users/user-eng.html#consultations",
    "href": "understanding-users/user-eng.html#consultations",
    "title": "User engagement",
    "section": "Consultations",
    "text": "Consultations\n\nIf you are considering changes to your publication and are contemplating a formal consultation do get in touch with HOP office early on to discuss.\nTo read more about consultations for background information please see the following two links:\n\nCode of Practice on Consultations\nConsultation principles: guidance - WWW.GOV.UK\n\nWith the first of the above links, please bear in mind this was written back in 2008 so certain aspects may have been updated but the background and principles do remain the same.\nSome examples of previous consultations are included below:\n\nOutcome and experience data - Office for Students\nConsultation on Data Futures and data collection - Office for Students\nSurveys on childcare and early years in England - GOV.UK (www.gov.uk)\nProposed cessation of ‘Income related benefits: estimates of take-up’ statistics - GOV.UK (www.gov.uk)\nProposals for a new statistical series to count unemployed claimants - GOV.UK (www.gov.uk)"
  },
  {
    "objectID": "understanding-users/user-eng.html#surveys",
    "href": "understanding-users/user-eng.html#surveys",
    "title": "User engagement",
    "section": "Surveys",
    "text": "Surveys\n\nWe routinely publish statistical releases, but who is using these and why? It’s important to understand your user types and need, so we (public and department) get best value from what we do. Using these insights can help us to continually improve our products and services. Having a survey with your releases is a great way to glean this feedback. Examples of statistical publication surveys, as well as ONS top tips on user surveys are below/attached. It would be great to include your examples too, as well as capture your lessons learned and tips, so do send these to us. If you do want further advice, please contact Heather Brown or Ian Hewson.\nUser survey and questionnaire design top tips (word document)\nResults from survey of statistics users (word document)\n\n\nExamples\n\nHigher Education Institutions Enrolments and Qualifications statistical bulletins - readership survey September 2019 (economy-ni.gov.uk)\nFurther Education & skills/Apprenticeships and traineeships release feedback survey - IH (Edit) Microsoft Forms (office.com)\nHigher Education Statistics - Department for Education - Citizen Space\nStatistics-and-data_user-feedback-survey_Land-and-Property-Data-Team_RoS.._.pdf"
  },
  {
    "objectID": "creating-statistics/rap-managers.html",
    "href": "creating-statistics/rap-managers.html",
    "title": "RAP information for managers",
    "section": "",
    "text": "This guidance is to help answer questions about RAP and act as a tool for anyone managing those implementing RAP."
  },
  {
    "objectID": "creating-statistics/rap-managers.html#analyst-leaders",
    "href": "creating-statistics/rap-managers.html#analyst-leaders",
    "title": "RAP information for managers",
    "section": "Analyst leaders",
    "text": "Analyst leaders\n\nThose giving senior sign off on publications and running analytical functions, usually G6 and SCS, analyst leaders will:\n\nensure their analysts build RAP learning and development time into work plans\nhelp their teams to work with DDaT professionals to share knowledge\npromote a “RAP by default” approach for all appropriate analysis\nwrite and implement strategic plans to develop new analyses with RAP principles, and to redevelop existing products with RAP principles\nlead their RAP champions to advise analysis teams on how to implement RAP\nhelp teams to incorporate RAP development into workplans\nidentify the most valuable projects by looking at how much capability the team already has and how risky and time-consuming the existing process is\ncommunicate the benefits of RAP to analysts, managers, and users"
  },
  {
    "objectID": "creating-statistics/rap-managers.html#analyst-managers",
    "href": "creating-statistics/rap-managers.html#analyst-managers",
    "title": "RAP information for managers",
    "section": "Analyst managers",
    "text": "Analyst managers\n\nRoughly equivalent to Team Leaders and G7, analyst managers will:\n\nwork with security and IT teams to give analysts access to the right tools\nwork with security and IT teams to develop platforms that are easy for analysts to access, flexible and responsive to the needs of analysts\nwork with security, IT, and data teams to make sure that the tools data analysts need are available in the right place and are easy to access\nbuild extra time into projects to adopt new skills and practices where appropriate\nlearn the skills they need to manage software\nevaluate RAP projects within organisations to understand and demonstrate the benefits of RAP\nmandate their teams use RAP principles whenever possible"
  },
  {
    "objectID": "creating-statistics/rap-managers.html#analysts",
    "href": "creating-statistics/rap-managers.html#analysts",
    "title": "RAP information for managers",
    "section": "Analysts",
    "text": "Analysts\n\nAnalysts working on analysis in government will:\n\nuse open-source tools wherever whenever appropriate\nopen source their code\nwork with data engineers and architects to make sure that source data are versioned and stored so that analysis can be reproduced\nlearn the skills they need to implement RAP principles\nengage with users of their analysis to demonstrate the value of RAP principles and build motivation for development\ndeliver their analysis using RAP"
  },
  {
    "objectID": "creating-statistics/rap-managers.html#what-is-rap",
    "href": "creating-statistics/rap-managers.html#what-is-rap",
    "title": "RAP information for managers",
    "section": "What is RAP",
    "text": "What is RAP\n\nQuestions on what RAP is and why analysts need to care about it.\n\n\nWhat is RAP, is it just using R?\n\nNo. Reproducible Analytical Pipelines (RAPs) are automated statistical and analytical processes. They incorporate elements of software engineering best practice to ensure that the pipelines are reproducible, auditable, efficient, and high quality.\nDoing RAP is doing analysis using the best methods available to us, which is an expectation of the statistics code of practice.\nThe tools we recommend for statistics production RAP are SQL, Git and R. Other suitable alternatives that allow you to meet the core principles can also be used, but you should check this with the Statistics Development Team first. Ideally any tools used would be open source, Python is a good example of a tool that would also be well suited, though is less widely used in DfE and has a steeper learning curve than R.\nUsing R for parts of the process does get you close to a lot of the RAP principles with little effort, which is why we recommend it as one of the tools you should use.\nMore details and learning resources for the recommended tools can be found in our appropriate tools guidance.\n\n\n\nIs this specific to DfE?\n\nNo – RAP is a cross government strategy, and all departments are expected to use this way of working. See the analytical function page on RAP to see other examples of departments utilising RAP and seeing the benefits.\nHere is a great blog post from NHS digital on ‘Why we’re getting our data teams to RAP’.\nRAP is also a strategic objective of Analysis function strategy for 22-25:\n\ndelivering the Reproducible Analytical Pipelines (RAP) Strategy and action plan to embed RAP across government, ensuring our processes are automated, efficient, and high quality which frees up resource to add value and insight in our analysis.\n\n\n\n\nI’m overwhelmed by all the steps, is RAP really necessary?\n\nThe levels within RAP good practice are in line with what a lot of teams are doing already, take time to understand what the different steps mean and don’t panic about the quantity of them as they’ve intentionally been broken down into the smallest level that was sensible.\nStatistics publications are some of the most important pieces of statistics work that the department does. It’s important we get that data right; RAP can help us automate the production and QA of outputs in a way that gives us the most confidence in the statistics and causes the least burden for you.\n\n\n\nWill implementing RAP lead to a disconnect with the data and ‘black box’ processes?\n\nNot at all. When fully implemented and accompanied with the relevant skills, RAP has the opposite effect as each stage of the process is clearly written as code.\nWe recognise there is a sizeable skill gap, and that until this is addressed there can be a risk of feeling like code is a black box. This isn’t a reason to avoid RAP though, instead it’s a big reason why we need to push ahead with prioritising upskilling ourselves to implement it.\n\n\n\nTeams vary, and what my team does is different to others, if I’m happy with my approach, can I ignore some of the RAP steps?\n\nNo, you should not ignore any of the steps. If you think any of the steps aren’t applicable to you, talk to the Statistics Development Team so we can understand more about the processes in your area. It may well be that you’re meeting it without realising, there’s a misunderstanding, or there’s something more we can add to the guidance.\nIf you have unique or nuanced processes, RAP helps you document these and make your area more resilient to turnover of people. RAP is all about automating the process and documenting it in a standardised way to make it easily reproducible."
  },
  {
    "objectID": "creating-statistics/rap-managers.html#getting-started",
    "href": "creating-statistics/rap-managers.html#getting-started",
    "title": "RAP information for managers",
    "section": "Getting started",
    "text": "Getting started\n\nQuestions about how to get started with RAP.\n\n\nCan I leave the R stuff to others in my team whilst I focus elsewhere?\n\nNo. Anyone undertaking any analytical processes should now be using RAP processes, and coding is a critical analytical skill. RAP is a cross-government strategy and there is an expectation in all departments for all analysts to move to this way of working.\nWe all must ensure that analysis is reproducible, transparent, and robust using coding and code management best practices (GSG competency framework).\n\n\n\nImplementing RAP takes time to setup initially, how can we prioritise it?\n\nThere is a clear expectation that this is the direction for analysis in government, ultimately, it’s a part of the new digital skills required for the role of analysts. If we’re not prioritising improving our analysis in line with RAP principles, we’re not approaching our work correctly.\nWe have support from senior leadership, and this is a department priority, so you should be building in time for it. If you are having difficulties prioritising RAP after talking with your line management chain, please get in touch with the Statistics Development Team.\nIn the long term, implementing RAP will significantly reduce the time it takes to run your pipeline, and so while it requires time upfront, it creates more time in the future to prioritise other things. It also improves the quality and reproducibility of our work, giving numerous business benefits."
  },
  {
    "objectID": "creating-statistics/rap-managers.html#tools-for-rap",
    "href": "creating-statistics/rap-managers.html#tools-for-rap",
    "title": "RAP information for managers",
    "section": "Tools for RAP",
    "text": "Tools for RAP\n\nQuestions about what tools and software to use when applying RAP principles.\n\n\nDo I need to rewrite existing SQL code into R?\n\nNo. In fact, we recommend you don’t necessarily do this!\nSQL is a useful tool in its own right and some processes are better using SQL code executed on the databases.\nWhat we recommend, is that all of your code is within a single R project, and the SQL scripts are executed via R, this helps with documenting the process, but keeps the SQL code and benefits of doing heavy processes on the database side. See the final question in this ‘Tools for RAP’ section for more information.\n\n\n\nI’m sometimes limited by the access and tools I have (ESFA servers, EDAP, Databricks), is there anything that can be done about this?\n\nThe first step is to let us (the Statistics Development Team) know so we can understand the wider landscape and escalate. There isn’t really a quick fix, but the first step is raising awareness.\n\n\n\nWhat happens if we can’t reproduce our current processes using R?\n\nThis is highly unlikely and is more likely to be from a lack of knowledge of what is possible in R – if you’re struggling to reproduce processes, please contact the Statistics Development Team so they’re aware of your processes and can help you implement RAP principles.\n\n\n\nR isn’t always the quickest tool for processing data, can we use SQL instead?\n\nYes. We recommend different tools for different purposes, SQL should be used for querying source data and large data processes, R should be used for more complicated data manipulation, QA, and analysis. There’s a grey area in the middle where you can do some things in either tool, sometimes you’ll need to test for yourself which way is faster (e.g., linking datasets or transforming tables).\nSQL scripts should be run in an automated way using R, instead of manually running them and copying the outputs. The difference we’re talking about here is whether you process data on the database server or on the machine you’re running R. A simplistic rule of thumb is do large scale processing on the database side (e.g., filtering and aggregating), and then only bring the data you need for manipulation / complicated processing into R."
  },
  {
    "objectID": "creating-statistics/rap-managers.html#implementing-rap",
    "href": "creating-statistics/rap-managers.html#implementing-rap",
    "title": "RAP information for managers",
    "section": "Implementing RAP",
    "text": "Implementing RAP\n\nQuestions on how to implement RAP.\n\n\nHaving a single script for code doesn’t seem the best way to do it, why are you suggesting this?\n\nThis is a misconception of our guidance that we will be clarifying and improving the phrasing of. The two steps this refers to are:\n\nCan the publication be reproduced using a single code script?\nAre data files produced via single code script(s) with integrated QA?’\n\nWe’re not suggesting all code lives in a single script. These steps in the RAP guidance are to encourage the repository being structured so that one clicks of a button can run the entire process from the source data through to the final output in order.\nThis means that you should have one ‘centralized’ script that details all of the different scripts in your repository. This single run script then provides a single reference point for where all of your code and scripts live, and in what order they’re executed, which is fantastic piece documentation to have!\n\n\n\nHow do I dual run for QA if our process is in code?\n\nYou don’t need to be dual running if your process is automated, it’s not the best way to QA. See our guidance on QA for more details on how you can approach it or talk to us if you’re unsure.\n\n\n\nShould I have separate repositories or branches in Git for each release?\n\nMore information on recommended ways of working with Git can be found in our guidance on repositories.\nIn short, a single repository should be used for all releases of your publication, there’s no need to have multiple as all the history is saved within previous commits.\n\n\n\nWe should have plain text documentation to accompany the process, code and comments don’t feel like enough?\n\nYes, you should have some plain text documentation, this is a part of the guidance on RAP and a part of the ‘documentation’ step to ‘good’ practice.\nThe README in your repository is the place for traditional ‘desk notes’ and text explanations of bits of the process and context required, we have guidance on writing READMEs on the statistics production website."
  },
  {
    "objectID": "creating-statistics/rap-managers.html#learning-about-rap",
    "href": "creating-statistics/rap-managers.html#learning-about-rap",
    "title": "RAP information for managers",
    "section": "Learning about RAP",
    "text": "Learning about RAP\n\nQuestions learning more about RAP and developing skills.\n\n\nCan I look at what other people are doing?\n\nAbsolutely. Currently the best way to do this is to ask other teams to share code directly with you. If we can all make more progress with using Git, then this will make it much easier to share repositories and have code open by default for interested analysts to browse.\nWe are also starting up a knowledge share series, so keep an eye out for that and make sure to contribute yourselves. We’d also encourage analysts to make more use of teams to post questions and ask about other people in our area doing similar types of analysis, no question is too big or too small!\n\n\n\nI don’t have the skills to implement RAP, how do I get them?\n\nSee the top section on the support on offer!\nPlus, if you’re ever unsure at all, you can always contact statisics.development@education.gov.uk who will be able to help you find resources that work for you or do bespoke training for your team’s needs."
  },
  {
    "objectID": "creating-statistics/rap.html",
    "href": "creating-statistics/rap.html",
    "title": "RAP Guidance for Statistics Producers",
    "section": "",
    "text": "Guidance for how to implement the principles of Reproducible Analytical Pipelines (RAP) into our production processes"
  },
  {
    "objectID": "creating-statistics/rap.html#our-scope",
    "href": "creating-statistics/rap.html#our-scope",
    "title": "RAP Guidance for Statistics Producers",
    "section": "Our scope",
    "text": "Our scope\n\nWe want to focus on the parts of the production process that we have ownership and control over – so we are focussing on the process from data sources to publishable data files. This is the part of the process where RAP can currently add the most value - automating the production and quality assurance of our outputs currently takes up huge amount of analytical resource, which could be better spent providing insight and other value adding activity. \n\n\n\nIn Official Statistics production we are using RAP as a framework for best practice when producing our published data files, as these are the foundations of our publications moving forward. Following this framework will help us to improve and standardise our current production processes and provide a clear ‘pipeline’ for analysts to follow. This will have the added benefit of setting a clear and defined world of tools and skills required, making learning and development that much clearer and easier. To get started with RAP, we first need to be able to understand what it actually means in practice, and be able to assess our own work against the principles of RAP.\nImplementing RAP for us will involve combining the use of SQL, R, and clear, consistent version control to increase efficiency and accuracy in our work. For more information on what these tools are, why we are using them, and resources to help up-skill in those areas, see our learning resources page.\nThe collection of, and routine checking of data as it is coming into the department is also an area that RAP can be applied to. We have kept this out of scope at the moment as the levels of control in this area vary wildly from team to team. If you would like advice and help to automate any particular processes, feel free to contact us."
  },
  {
    "objectID": "creating-statistics/rap.html#how-to-assess-your-publication",
    "href": "creating-statistics/rap.html#how-to-assess-your-publication",
    "title": "RAP Guidance for Statistics Producers",
    "section": "How to assess your publication",
    "text": "How to assess your publication\n\nThe checklist provided in the publication self-assessment tool is designed to make reviewing our processes against our RAP levels easier, giving a straightforward list of questions to check your work against. This will flag potential areas of improvement, and you can then use the links to go to the specific section with more detail and guidance on how to develop your current processes in line with best practice.\nSome teams will already be looking at best practice, while others will still have work to do to achieve the department’s baseline of good and great practice. We know that all teams are starting this from different points, and are here to support all teams from their respective starting positions."
  },
  {
    "objectID": "creating-statistics/rap.html#where-we-need-to-focus",
    "href": "creating-statistics/rap.html#where-we-need-to-focus",
    "title": "RAP Guidance for Statistics Producers",
    "section": "Where we need to focus",
    "text": "Where we need to focus\n\nMost teams have already made progress with their production of tidy data files, and the release of the automated screener has now tied up that end point of the pipeline that we are all currently working towards. The standard pipeline for all teams will roughly resemble this:\n\n\n\nThe key now is for us to build on the work so far and focus on how we improve the quality and efficiency of our production processes up to that point. To do this, we need to make a concerted effort to standardise how we store and access our data, before then automating what we can to reduce the burden of getting the numbers ready and see the benefits of RAP. The exact meaning of this will vary within teams."
  },
  {
    "objectID": "creating-statistics/rap.html#how-to-get-started",
    "href": "creating-statistics/rap.html#how-to-get-started",
    "title": "RAP Guidance for Statistics Producers",
    "section": "How to get started",
    "text": "How to get started\n\nMeasure your publication against the RAP levels using our self assessment tool. This will give you a good starting point and initial points to work on to progress to the next level of RAP.\nOnce you’ve assessed your publication, have a look through our guidance below to narrow down how you can get started with improving those parts of your process.\nThe Statistics Development Team invites teams to take part in our partnership programme to develop their skills and implement RAP principles to a relevant project. Visit our page on getting started with the partnership programme for more details."
  },
  {
    "objectID": "creating-statistics/rap.html#all-source-data-stored-in-a-database",
    "href": "creating-statistics/rap.html#all-source-data-stored-in-a-database",
    "title": "RAP Guidance for Statistics Producers",
    "section": "All source data stored in a database",
    "text": "All source data stored in a database\n\n\n\n\nWhat does this mean?\nWhen we refer to ‘source data’, we take this to mean the data you use at the start of the process to create the underlying data files. Any cleaning at the end of a collection will happen before this.\nIn order for us to be able to have an end-to-end data pipeline where we can replicate our analysis across the department, we should store all of the raw data needed to create aggregate statistics in a managed Microsoft SQL Server. This includes any lookup tables and all administrative data from collections prior to any manual processing. This allows us to then match and join the data together in an end-to-end process using SQL queries.\nAs far as meeting the requirement to have all source data in a database, databases other than SQL may be acceptable, though we can’t support them in the same way.\nWhy do it?\nThe principle is that this source data will remain stable and is the point you can go back to and re-run the processes from if necessary. If for any reason the source data needs to change, your processes will be set up in a way that you can easily re-run them to get updated outputs based on the amended source data with minimal effort.\nSQL is a fantastic language for large scale data joining and manipulation; it allows us to replicate end-to-end from raw data to final aggregate statistics output. Having all the data in one place and processing it in one place makes our lives easier, and also helps us when auditing our work and ensuring reproducibility of results.\nHow to get started\n\nFor a collection of relevant resources to use when learning SQL, see our learning resources page, and for guidance on best practice when writing SQL queries, see the writing code and documentation sections on this page, as well as the guides immediately below on how to setup and use a SQL database.\n\n\nHow to set up a SQL working area\n\nThere are a few different options, depending on where you want your new area to exist. Visit our SQL learning page for details.\n\n\n\nMoving data to different areas\n\nIf your data is already in SQL, you can use this snippet of R code to move tables from one area (e.g. the iStore) to another (e.g. your team’s modelling area) to ensure all data are stored in a database.\nlibrary(odbc)\nlibrary(dplyr)\nlibrary(dbplyr)\nlibrary(DBI)\n\n# Step 1.1.: Connect to source server -------------------------------------------\ncon_source <- dbConnect(odbc(),\n                     Driver = \"SQL Server Native Client 11.0\",\n                     Server = \"Name_of_source_server\",\n                     Database = \"Source_database\",\n                     Trusted_Connection = \"yes\"\n)\n\n# Step 1.2.: Connect to target server\ncon_target <- dbConnect(odbc(),\n                        Driver = \"SQL Server Native Client 11.0\",\n                        Server = \"Name_of_target_server\",\n                        Database = \"Your_target_database\",\n                        Trusted_Connection = \"yes\"\n)\n\n# Step 2.1.: Pull the table from the source database\ntable_for_transfer <- tbl(con_source,in_schema(\"schema_name\", \"table_name\")) %>% collect()\n\n# Step 2.2.: Copy table into target database \ndbWriteTable(con_target,\"whatever_you_want_to_call_new_table\", table_for_transfer)\n\n\n\n\nImporting data to SQL Server\n\nThere’s lots of guidance online of how to import flat files from shared areas into Microsoft SQL server on the internet, including this guide.\nRemember that it is important to import them with consistent, thought-through naming conventions. You will thank yourself later.\n\n\n\nHow to grant access to your area\n\nMuch like setting up a SQL area, there are different ways to do this depending on the server your database is in. Visit our SQL learning page for details."
  },
  {
    "objectID": "creating-statistics/rap.html#processing-is-done-with-code",
    "href": "creating-statistics/rap.html#processing-is-done-with-code",
    "title": "RAP Guidance for Statistics Producers",
    "section": "Processing is done with code",
    "text": "Processing is done with code\n\n\n\n\nWhat does this mean?\nAll extraction, and processing of data should be done using code, avoiding any manual steps and moving away from a reliance on Excel, SPSS, and other manual processing. In order to carry out our jobs to the best of our ability it is imperative that we use the appropriate tools for the work that we do.\nEven steps such as copy and pasting data, or pointing and clicking, are fraught with danger, and these risks should be minimised by using code to document and execute these processes instead.\nWhy do it?\nUsing code brings numerous benefits, computers are far quicker, more accurate, and far more reliable than humans in many of the tasks that we do. Writing out these instructions saves us significant amounts of time, particularly when it can be reused in future years, or even next week when one specific number in the source file suddenly changes, and also provides us with editable documentation for our production processes, saving the need for writing down information in extra documents.\nReliability is a huge benefit of the automation that RAP brings - when one of the lines of data has to be amended a week before publication, it’s a life saver to know that you can re-run your process in minutes, and reassuring to know that it will give you the result you want. You can run the same code 100 times, and be confident that it will follow the same steps in the same order every single time.\nHow to get started\nSee our learning resources for a wealth of resources on SQL and R to learn the skills required to translate your process into code.\nThere are also two sections below with examples of tidying data in SQL and R to get you started.\nEnsure that any last-minute fixes to the process are written in the code and not done with manual changes.\n\n\nProducing tidy underlying data in SQL\n\nTo get started, here is a SQL query that you can run on your own machine and walks you through the basics of tidying a simple example dataset in SQL.\n\n\n\nTidying and processing data in R\n\n\nHere is a video of Hadley Wickham talking about how to tidy your data to these principles in R. This covers useful functions and how to complete common data tidying tasks in R. Also worth taking a look at applied data tidying in R, by RStudio.\nUsing the %>% pipe in R can be incredibly powerful, and make your code much easier to follow, as well as more efficient. If you aren’t yet familiar with this, have a look at this article that provides a useful beginners guide to piping and the kinds of functions you can use it for. The possibilities stretch about as far as your imagination, and if you have a function or task you want to do within a pipe, googling ‘how do I do X in dplyr r’ will usually start to point you in the right direction, alternatively you can contact us, and we’ll be happy to help you figure out how to do what you need.\nA quick example of how powerful this is is below, where my_data is processed to create new columns, have column names renamed, have the column names tidied using the janitor package, blank rows and columns removed, data filtered to only include specific geographic levels, and rows rearranged in order, all in a few lines of easy to follow code:\n\nprocessed_regional_data <- my_data %>% \n  mutate(newPercentageColumn = (numberColumn / totalPopulationColumn) * 100) %>% \n  rename(newPercentageColumn = percentageRate,\n         numberColumn = number,\n         totalPopulationColumn = population) %>% \n  clean_names() %>% \n  remove_empty() %>% \n  filter(geographic_level == \"Regional\") %>% \n  arrange(time_period, region_name)\n\nHelpful new functions in the tidyverse packages can help you to easily transform data from wide to long format (see tip 2 in the linked article for this, as it is often required for tidy data), as well as providing you with tools to allow you quickly and efficiently change the structure of your variables.\nFor further resources on learning R so that you’re able to apply it to your everyday work, have a look at the learning resources page."
  },
  {
    "objectID": "creating-statistics/rap.html#appropriate-tools",
    "href": "creating-statistics/rap.html#appropriate-tools",
    "title": "RAP Guidance for Statistics Producers",
    "section": "Appropriate tools",
    "text": "Appropriate tools\n\n\n\n\nWhat does this mean?\nUsing the recommended tools on our learning page (SQL, R and Git), or other suitable alternatives that allow you to meet the core principles. Ideally any tools used would be open source, Python is a good example of a tool that would also be well suited, though is less widely used in DfE and has a steeper learning curve than R.\nOpen-source refers to something people can modify and share because its design is publicly accessible. For more information, take a look at this explanation of open-source, as well as this guide to working in an open-source way. In practical terms, this means moving away from the likes of SPSS, SASS and Excel VBA, and utilising the likes of R or Python, version controlled with git, and hosted in a publicly accessible repository.\nWhy do it?\nThere are many reasons why we have recommended the tools that we have, the recommended tools are:\n\nalready in use at the department and easy for us to access\neasy and free to learn\ndesigned for the work that we do\nused widely across data science in both the public and private sector\nallow us to meet best practice when applying RAP to our processes\n\nHow to get started\nGo to our learning page to read more about the recommended tools for the jobs we do, as well as looking at the resources available there for how to build capability in them. Always feel free to contact us if you have any specific questions or would like help in understanding how to use those tools in your work.\nBy following our guidance in saving versions of code in an Azure DevOps, we will then be able to mirror those repositories in a publicly available GitHub area."
  },
  {
    "objectID": "creating-statistics/rap.html#using-run-scripts",
    "href": "creating-statistics/rap.html#using-run-scripts",
    "title": "RAP Guidance for Statistics Producers",
    "section": "Using ‘run’ scripts",
    "text": "Using ‘run’ scripts\n\nUtilising a single ‘run’ script to execute processes written in other scripts brings a number of benefits. It isn’t just about removing the need to manually trigger different code scripts to get the outputs, but it means the entire process, from start to finish, is fully documented in one place. This has a huge number of benefits, particularly for enabling new team members to pick up existing work quickly, without wasting time struggling to understand what has been done in the past.\n\n\nConnecting R to SQL\n\nIn order to create a single script to run all processes from, it is likely that you will need to use R to run SQL queries. If you are unsure of how to do this, take a look at the materials from Cathy Atkinson’s coffee and coding session on connecting R to SQL using DBI and odbc.\nChris Mason-Thom did another coffee and coding session on this, which you can watch below:\n\n\n\n\n\n\n\nDataset production scripts\n\n\n\n\nWhat does this mean?\nEach dataset can be created by running a single script, which may ‘source’ multiple scripts within it. This does not mean that all of the code to create a file must be written in a single script, but instead that there is a single ‘create file’ or ‘run’ script that sources every step in the correct order such that every step from beginning to end will be executed if you run that single ‘run’ script.\nThis ‘run’ script should take the source data right through to final output at the push of a button, including any manipulation, aggregation, suppression etc.\nWhy do it?\nHaving a script that documents the whole process for this saves time when needing to rerun processes, and provides a clear documentation of how a file is produced.\nHow to get started\nReview your current process - how many file scripts does it take to get from source data to final output, why are they separated, and what order should they be run in? Do you still have manual steps that could introduce human error (for example, manually moving column orders around in excel)?\nYou should automate any manual steps such as the example above. If it makes sense to, you could combine certain scripts to reduce the number. You can then write code in R to execute your scripts in order, so you are still only running one script to get the final output.\n\n\n\nWhole publication production scripts\n\n\n\n\nWhat does this mean?\nThe ultimate aim is to utilise a single script to document and run off everything for a publication, the data files, any QA, any summary reports. This script should allow you to run individual outputs by themselves as well, so make sure that each data file can be run in isolation by running single lines of this script. All quality assurance for a file is also included in the single script that can be used to create a file from source data (see the dataset production scripts section)\nWhy do it?\nThis carries all of the same benefits as having a single ‘run’ script for a file, but at a wider publication level, effectively documenting the entire publication process in one place. This makes it easier for new analysts to pick up the process, as well as making it quicker and easier to rerun as all reports relating to that file are immediately available if you ever make changes file.\nHow to get started\nThe Education, Health and Care Plans production cycle is a good example of a single publication ‘run’ script. They have kept their actual data processing in SQL, but all the running and manipulation of the data happens in R.\nThe cycle originally consisted of multiple SQL scripts, manual QA and generation of final files.\n\n\n\nThe team now have their end-to-end process fully documented, which can be run off of one single R script. The ‘run’ script points at the SQL scripts to run them all in one go, and also creates a QA report and corresponding metadata files that pass the data screener. Each data file can still be run in isolation from this script."
  },
  {
    "objectID": "creating-statistics/rap.html#recyclable-code-for-future-use",
    "href": "creating-statistics/rap.html#recyclable-code-for-future-use",
    "title": "RAP Guidance for Statistics Producers",
    "section": "Recyclable code for future use",
    "text": "Recyclable code for future use\n\n\n\n\nWhat does this mean?\nWe’d expect that any recyclable code would take less than 30 minutes of editing before being able to run again in a future iteration of the publication.\nWhy do it?\nOne huge benefit that comes with using code in our processes, is that we can pick them up in future years and reuse with minimum effort, saving us huge amounts of resource. To be able to do this, we need to be conscious of how we write our code, and write it in a way that makes it easy to use in future releases for the publication.\nHow to get started\nReview your code and consider the following:\n\nWhat steps might need re-editing or could become irrelevant?\nCan you move all variables that require manual input (e.g. table names, years) to be assigned at the top of the code, so it’s easy to edit in one place with each iteration?\nAre there any fixed variables that are prone to changing such as geographic boundaries, that you could start preparing for changes now by making it easy to adapt in future?\n\nFor example, if you refer to the year of publication in your code a lot, consider replacing every instance with a named variable, which you only need to change once at the start of your code. In the example below, the year is set at the top of the code, and is used to define “prev_year”, both of which are used further down the code to filter the data based on year.\n\nthis_year <- 2020\nprev_year <- this_year - 1\n\ndata_filtered <- data %>% \n  filter(year == this_year)\n\ndata_filtered_last_year <- data %>% \n  filter(year == prev_year)"
  },
  {
    "objectID": "creating-statistics/rap.html#standards-for-coding",
    "href": "creating-statistics/rap.html#standards-for-coding",
    "title": "RAP Guidance for Statistics Producers",
    "section": "Standards for coding",
    "text": "Standards for coding\n\nCode can often be written in many different ways, and in languages such as R, there are often many different functions and routes that you can take to get to the same end result. On top of that, there are even more possibilities for how you can format the code. This section will take you through some widely used standards for coding to help bring standardisation to this area and make it easier to both write and use our code.\n\n\nClean final code\n\n\n\n\nWhat does this mean?\n\nThis code should meet the best practice standards below (for SQL and R). If you are using a different language, such as Python, then contact us for advice on the best standards to use when writing code.\nThere should be no redundant or duplicated code, even if this has been commented out. It should be removed from the files to prevent confusion further down the line.\nThe only comments left in the code should be those describing the decisions you have made to help other analysts (and future you) to understand your code. More guidance on commenting in code can be found later on this page.\n\nWhy do it?\nClean code is efficient, easy to write, easy to review, and easy to amend for future use. Below are some recommended standards to follow when writing code in SQL and R.\nHow to get started\nWatch the coffee and coding session introducing good code practice below:\n\n\n\n\nThen you should also watch the follow up intermediate session:\n\n\n\n\nClean code should include comments. Comment why you’ve made decisions, don’t comment what you are doing unless it is particularly complex as the code itself describes what you are doing. If in doubt, more comments are better than too few though. Ideally any specific comments or documentation should be alongside the code itself, rather than in separate documents.\n\n\nSQL\n\nFor best practice on writing SQL code, here is a particularly useful word document produced by our Data Hub. This outlines a variety of best practices, ranging from naming conventions, to to formatting your SQL code so that it is easy to follow visually.\n\n\n\nR\n\nWhen using R, it is generally best practice to use R projects as directories for your work.\nThe recommended standard for styling your code in R, is the tidyverse styling, which is fast becoming the global standard. What is even better is that you can automate this using the styler package, which will literally style your code for you at the click of a button, and is well worth a look.\n\n\n\nThere is also plenty of guidance around the internet for best practice when writing efficient R code.\n\n\n\nHTML\n\nIf you ever find yourself writing html, or creating it through rmarkdown, you can check your html using w3’s validator."
  },
  {
    "objectID": "creating-statistics/rap.html#peer-reviewing-code",
    "href": "creating-statistics/rap.html#peer-reviewing-code",
    "title": "RAP Guidance for Statistics Producers",
    "section": "Peer reviewing code",
    "text": "Peer reviewing code\n\nPeer review is an important element of quality assuring our work. We often do it without realising by bouncing ideas off of one another and by getting others to ‘idiot check’ our work. When writing code, ensuring that we get our work formally peer reviewed is particularly important for ensuring it’s quality and value.\nPrior to receiving code for peer review, the author should ensure that all code files are clean, commented appropriately and for larger projects should be held in a repo with an appropriate README file.\nWhen peer reviewing code you should be consider the following questions -\n\nDoes the code do what the author intended?\nIf you’re able to run the code, does it run without errors? If warnings are displayed, are they explained?\nIf the project has unit/integration tests, do they pass?\nAre there any tests / checks that could be added into the code that would help to give greater confidence that it is doing what it is intended to?\nAre there comments explaining why any decisions have been made?\nIs the code written and structured sensibly?\nAre there any ways to make the code more efficient (either in number of lines or raw speed)?\nDoes the code follow best practice for styling and structure?\nAre there any other teams/bits of code you’re aware of that do similar things and would be useful to point the authors towards?\nAt the end of the review, was there any information you needed to ask about that should be made more apparent in the code or documentation?\n\nDepending on your access you may or may not be able to run the code yourself, but there should be enough information within the code and documentation to be able to respond to these questions.\n\n\nReview of code within team\n\n\n\n\nWhat does this mean?\n\nIs someone else in the team able to generate the same outputs?\nHas someone else in the team reviewed the code and given feedback?\nHave you taken on their feedback and improved the code?\n\nWhy do it?\nThere are many benefits to this, for example:\n\nEnsuring consistency across the team\nMinimizing mistakes and their impact\nEnsuring the requirements are met\nImproving code performance\nSharing of techniques and knowledge\n\nHow to get started\nIf you can’t answer yes, then:\n\nGet a member of the team to run the code using only your documentation\nUse their feedback to improve documentation/in-line comments in code\nOther tips for getting started with peer review can be found in the Duck Book\nThe Duck Book also contains some helpful code QA checklists to help get you thinking about what to check\n\n\n\nImproving code performance\n\nPeer reviewing code and not sure where to start? Improving code performance can be a great quick-win for many production teams. There will be cases where code you are reviewing does things in a slightly different way to how you would: profiling the R code with the microbenchmark package is a way to objectively figure out which method is more efficient.\nFor example below, we are testing out case_when, if_else and ifelse.\nmicrobenchmark::microbenchmark( \n   case_when(1:1000 < 3 ~ \"low\", TRUE ~ \"high\"), \n   if_else(1:1000 < 3, \"low\", \"high\"),\n   ifelse(1:1000 < 3, \"low\", \"high\") \n)\nRunning the code outputs a table in the R console, giving profile stats for each expression. Here, it is clear that on average, if_else() is the fastest function for the job.\nUnit: microseconds\n                                         expr     min       lq     mean   median       uq      max neval\n case_when(1:1000 < 3 ~ \"low\", TRUE ~ \"high\") 167.901 206.2510 372.7321 300.2515 420.1005 4187.001   100\n           if_else(1:1000 < 3, \"low\", \"high\")  55.301  74.0010 125.8741 103.7015 138.3010  538.201   100\n            ifelse(1:1000 < 3, \"low\", \"high\") 266.200 339.4505 466.7650 399.7010 637.6010  851.502   100\n\n\n\n\n\nReview of code from outside the team\n\n\n\n\nWhat does this mean?\n\nHas someone from outside of the team and publication area reviewed the code and given feedback?\nHave you taken on their feedback and improved the code?\n\nWhy do it?\nAll of the benefits you get from peer reviewing within your own team, multiple times over. Having someone external offers new perspectives, holds you to account by breaking down assumptions, and offers far greater opportunity for building capability through knowledge sharing.\nHow to get started\nWhile peer reviewing code within the team is often practical, having external analysts peer review your code can bring a fresh perspective. If you’re interested in this, please contact us, and we can help you to arrange someone external to your team to review your processes. For this to work smoothly, we recommend that your code is easily accessible for other analysts, such as hosted in an Azure DevOps repo and mirrored to github."
  },
  {
    "objectID": "creating-statistics/rap.html#automated-quality-assurance",
    "href": "creating-statistics/rap.html#automated-quality-assurance",
    "title": "RAP Guidance for Statistics Producers",
    "section": "Automated quality assurance",
    "text": "Automated quality assurance\n\nAny data files that have been created will need to be quality assured. These checks should be automated where possible, so the computer is doing the hard work - saving us time, and to ensure their reliability.\nSome teams are already making great progress with automated QA and realising the benefits of it. The Statistics Development Team are working with these to provide generalised code that teams can use as a starting point for automated QA. The intention is that teams can then run this as a minimum, before then looking to develop more area specific checks to the script and/or continue with current checking processes in tandem. If your team already use, or are working towards using, automated QA then get in touch as we’d be keen to see what you have.\nIt is assumed that when using R, automated scripts will output .html reports that the team can read through to understand their data and identify any issues, and save as a part of their process documentation.\nFor more information on general quality assurance best practice in DfE, see the How to QA guide.\n\n\nBasic automated QA\n\n\n\n\nWhat does this mean?\nThe list of basic automated QA checks, with code examples can be found below and in our GitHub repository:\n\nChecking for minimum, maximum, and average values across your data\nChecking for extreme values and outliers\nEnsuring there are no duplicate rows or duplicate columns\nChecking that where appropriate, geographical subtotals add up to totals (e.g. all the numeric values for LAs in Yorkshire and The Humber add up to the regional total)\nBasic trend analysis using scatter plots, to help you spot outliers and help tell the story of your data.\n\nThe Statistics Development Team have developed the QA app to include some of these basic QA outputs.\nWhy do it?\nQuality is one of the three pillars that our code of practice is built upon. These basic level checks allow us to have confidence that we are accurately processing the data.\nAutomating these checks ensures their accuracy and reliability, as well as being dramatically quicker than doing these manually.\nHow to get started\nTry using our template code snippets to get an idea of how you could automate QA of your own publication files. A recording of our introduction to automated QA is also available at the top of the page.\n\n\n\nPublication specific automated QA\n\n\n\n\nWhat does this mean?\nMany teams will have aspects of their data and processes that require Quality Assuring beyond the generalisable basic checks above. Therefore it is expected that teams develop their own automated QA checks to QA specificities of their publications not covered by the basic checks.\nWhy do it?\nQuality is one of the three pillars that our code of practice is built upon. By building upon the basic checks to develop bespoke QA for our publications, we can increase our confidence in the quality of the processes and outputs that they produce.\nHow to get started\nWe expect that the basic level of automated QA will cover most needs that publication teams have. However, we also expect that each publication will have it’s own quirks that require a more bespoke approach. An example of a publication with it’s own bespoke QA checks will appear in this space shortly. For the time being, try to consider what things you’d usually check as flags that something hasn’t gone right with your data. What are the unique aspects of your publication’s data, and how can you automate checks against them to give you confidence in it’s accuracy and reliability?\nFor those who are interested in starting writing their own QA scripts, it’s worth looking at packages in R such as testthat, including the coffee and coding talk on it by Peter Curtis, as well as this guide on testing by Hadley Wickham.\nThe janitor package in R also has some particularly useful functions, such as clean_names() to automatically clean up your variable names, remove_empty() to remove any completely empty rows and columns, and get_dupes() which retrieves any duplicate rows in your data - this last one is particularly powerful as you can feed it specific columns and see if there’s any duplicate instances of values across those columns."
  },
  {
    "objectID": "creating-statistics/rap.html#automating-summary-statistics",
    "href": "creating-statistics/rap.html#automating-summary-statistics",
    "title": "RAP Guidance for Statistics Producers",
    "section": "Automating summary statistics",
    "text": "Automating summary statistics\n\nAs a part of automating QA, we should also be looking to automate the production of summary statistics alongside the tidy underlying data files, this then provides us with instant insight into the stories underneath the numbers.\n\n\nAutomated summaries\n\n\n\n\nWhat does this mean?\nSummary outputs are automated and used to explore the stories of the data.\nThe Statistics Development Team have developed the QA app to include some of these automated summaries, including minimum, maximum and average summaries for each indicator.\nAt a basic level we want teams to make use of the QA app to explore their data:\n\nHave you used the outputs of the automated QA from the screener to understand the data?\nRun automated QA, ensure that all interesting outputs/trends are reflected in the accompanying text\n\nWhy do it?\nValue is one of the three pillars of our code of practice. Even more specifically it states that ‘Statistics and data should be presented clearly, explained meaningfully and provide authoritative insights that serve the public good.’.\nAs a result, we should be developing automated summaries to help us to better understand the story of the data and be authoritative and rigorous in our telling of it.\nHow to get started\nConsider:\n\nUse the additional tabs available after a data file passes the data screener as a starting point to explore trends across breakdowns and years.\nRunning your publication-specific automated QA, ensuring that all interesting outputs/trends are reflected in the accompanying text\n\n\n\n\nPublication specific automated summaries\n\n\n\n\nWhat does this mean?\n\nHave you gone beyond the outputs of the QA app to consider automating further insights for your publication specifically? E.g. year on year changes for specific measures, comparisons of different characteristics that are of interest to the general public\nAre you using these outputs to write your commentary?\n\nWhy do it?\nAll publications are different, and therefore it is important that for each publication, teams go beyond the basics and produce automated summaries specific to their area.\nHow to get started\nConsider:\n\nIntegrating extra publication-specific QA into the production process\nConsider outputs specific to your publication that would help you to write commentary/draw out interesting analysis"
  },
  {
    "objectID": "creating-statistics/rap.html#sensible-folder-and-file-structure",
    "href": "creating-statistics/rap.html#sensible-folder-and-file-structure",
    "title": "RAP Guidance for Statistics Producers",
    "section": "Sensible folder and file structure",
    "text": "Sensible folder and file structure\n\n\n\n\nWhat does this mean?\nAs a minimum you should have a folder that includes all of the final versions of documents produced and published, per release, within a folder for the wider publication. Ask yourself if it would be easy for someone who isn’t in the team to find specific files, and if not, is there a better way that you could name and structure your folders to make them more intuitive to navigate?\nWhy do it?\nHow you organize and name your files will have a big impact on your ability to find those files later and to understand what they contain. You should be consistent and descriptive in naming and organizing files so that it is obvious where to find specific data and what the files contain.\nHow to get started\nSome questions to help you consider whether your folder structure is sensible are:\n\nAre all documentation, code and outputs for the publication saved in one folder area?\nIs simple version control clearly applied (e.g. having all final files in a folder named “final”?\nAre there sub-folders like ‘code’, ‘documentation’‘, ’outputs’ and ‘final’ to save the relevant working files in?\nAre you keeping a version log up to date with any changes made to files in this final folder?\n\n\n\nNaming conventions\n\nHaving a clear and consistent naming convention for your files is critical. Remember that file names should:\nBe machine readable\n\nAvoid spaces.\nAvoid special characters such as: ~ ! @ # $ % ^ & * ( ) ` ; < > ? , [ ] { } ‘ “.\nBe as short as practicable; overly long names do not work well with all types of software.\n\nBe human readable\n\nBe easy to understand the contents from the name.\n\nPlay well with default ordering\n\nOften (though not always!) you should have numbers first, particularly if your file names include dates.\nFollow the ISO 8601 date standard (YYYYMMDD) to ensure that all of your files stay in chronological order.\nUse leading zeros to left pad numbers and ensure files sort properly, avoiding 1,10,2,3.\n\nIf in doubt, take a look at this presentation, or this naming convention guide by Stanford, for examples reinforcing the above."
  },
  {
    "objectID": "creating-statistics/rap.html#documentation",
    "href": "creating-statistics/rap.html#documentation",
    "title": "RAP Guidance for Statistics Producers",
    "section": "Documentation",
    "text": "Documentation\n\n\n\n\nWhat does this mean?\n\nYou should be annotating as you go, ensuring that every process and decision made is written down. Processes are ideally written with code, and decisions in comments.\nThere should be a README notes file, that clearly details the steps in the process, any dependencies (such as places where access needs to be requested to) and how to carry out the process.\nAny specialist terms should also be defined if required (e.g. The NFTYPE lookup can be found in xxxxx. “NFTYPE” means school type).\n\nWhy do it?\nWhen documenting your processes you should leave nothing to chance, we all have wasted time in the past trying to work out what it was that we had done before, and that time increases even more when we are picking up someone else’s work. Thorough documentation saves us time, and provides a clear audit trail of what we do. This is key for the ‘Reproducible’ part of RAP, our processes must be easily reproducible and clear documentation is fundamental to that.\nHow to get started\nTake a look at your processes and be critical - could another analyst pick them up without you there to help them? If the answer is no (don’t feel ashamed, it will be for many teams) then go through and note down areas that require improvement, so that you can revise them with your team.\nTake a look at the sections below for further guidance on improving your documentation.\n\n\nCommenting in code\n\nWhen writing code, whether that is SQL, R, or something else, make sure you’re commenting as you go. Start off every file by outlining the date, author, purpose, and if applicable, the structure of the file, like this:\n----------------------------------------------------------------------------------------------\n-- Script Name:     Section 251 Table A 2019 - s251_tA_2019.sql\n-- Description:     Extraction of data from IStore and production of underlying data file\n-- Author:          Cam Race\n-- Creation Date:   15/11/2019\n----------------------------------------------------------------------------------------------\n\n----------------------------------------------------------------------------------------------\n--//  Process\n-- 1. Extract the data for each available year\n-- 2. Match in extra geographical information\n-- 3. Create aggregations - both categorical and geographical totals\n-- 4. Tidy up and output results\n-- 5. Metadata creation\n----------------------------------------------------------------------------------------------\nCommented lines should begin with – (SQL) or # (R), followed by one space and your comment. Remember that comments should explain the why, not the what.\nIn SQL you can also use /** and **/ to bookend comments over multiple lines.\nIn rmarkdown documents you can bookend comments by using <!-- and -->.\nUse commented lines of - to break up your files into scannable chunks based upon the structure and subheadings, like the R example below:\n# Importing the data -----------------------------------------------------------------------------------\n\nDoing this can visually break up your code into sections that are easy to navigate around. It will also add that section to your outline, which can be used in RStudio using Ctrl-Shift-O. More details on the possibilities for this can be found in the RStudio guidance on folding and sectioning code.\nYou might be thinking that it would be nice if there was software that could help you with documentation, if so, read on, as Git is an incredibly powerful tool that can help us easily and thoroughly document versions of our files. If you’re at the stage where you are developing your own functions and packages in R, then take a look at roxygen2 as well.\n\n\n\nWriting a README file\n\nWhat does this mean?\nA README is a text file (.txt) that introduces and explains a project. It contains information that is required to understand what the project is about and how to use it.\nWhy do it?\nIt’s an easy way to answer questions that your audience will likely have regarding how to install and use your project and also how to collaborate with you.\nHow to get started\nAs a starting point, you should aim to have as many of the following sections as are applicable to your project:\n\nIntroduction\nRequirements (access, software, skills/knowledge)\nHow to use\nHow to contribute\nContact details\n\nThe Self-assessment tool and the QA app give two examples of readme files structured like this."
  },
  {
    "objectID": "creating-statistics/rap.html#version-control-with-git",
    "href": "creating-statistics/rap.html#version-control-with-git",
    "title": "RAP Guidance for Statistics Producers",
    "section": "Version control with git",
    "text": "Version control with git\n\nIf you do not already have git downloaded, you can download the latest version from their website.\nFor now, take a look at at the resources for learning Git on the learning resources page.\n\n\nVersion controlled final code scripts\n\n\n\n\nWhat does this mean?\nThis means having the final copies of code and documentation saved in a git-controlled Azure DevOps repo in the official-statistics-production area.\nWhy do it?\nHaving the final copy of the scripts version controlled gives assurance around how the data was created. It also allows teams to easily record any last minute changes to the code after the initial final version by using the version control to log this.\nHow to get started\nThe first step is to get your final versions of code and documentation together in a single folder.\nWe have a specific area set up for you to host your publication code in on the dfe-gov-uk instance of Azure DevOps, entitled official-statistics-production.\nTo gain access to this area, please raise a request on service desk by navigating through the pages detailed in the animation below.\n\n\n\nOnce you have navigated to this page, fill out the form with the following details and send your request off.\n\n\n\nAccess is usually granted within a few working days. Alert the Statistics Development Team when this is confirmed, and we will set up your repository and give your team access.\n\n\n\nUse open source repositories\n\n\n\n\nWhat does this mean?\nSaving or cloning your work into a repository that is visible to the public. We currently have brilliant examples of this in our DfE analytical services GitHub area, in which all of the code used to create public dashboards is publicly available.\nFor statistics publications we expect teams to be able to mirror their proccess code on GitHub after publication, which will help open up their code for other analysts to learn from.\nWe are currently working on ways to mirror private repos (i.e. AzureDevOps) to public repos on publication of your data. If you are interested in this please contact the Statistics Development Team.\nWhy do it?\nIt’s a key part of the technology code of practice as an agreed standard for digital services across government.\nHow to get started?\nContact us to get a repository set up in Azure DevOps, to set up a mirroring process to GitHub or to set up a repository on our dfe-analytical-services area on GitHub.\nYou should consider the following principles making an Official Statistics production repository public (some examples are R specific though can be applied to other languages):\n\nFollow the guidance on writing a readme file, and add context in about what Official/National statistics are\nEnsure no data (either input or output) is included in the repository\nHave a clear and organised folder structure (such as having R scripts in an ‘R’ folder)\nCheck your code is styled according the tidyverse styling\nUse renv for package management\nUse an R project\n\nWhen naming your publication’s repository you should use the publication name fully written out, in lower case, and with dashes for spaces – ‘graduate-labour-market-statistics’.\nA single repository should be used for all releases of your publication, there’s no need to have multiple as all the history is saved within previous commits. You can make use of tagging releases in git to help differentiate between each cycle.\n\n\nAvoid revealing sensitive information\n\nHere are some general best practice tips:\n\nUsing .gitignore to ignore files and folders to prevent committing anything sensitive\nNever committing outputs unless they’ve been checked over, even aggregates. We suggest only outputting to an output folder which is in the .gitignore file, to ensure this doesn’t happen by mistake\nKeeping datasets and secrets (e.g. API keys) outside the repository as much as possible, make use of secure variables\nChecking git histories: if someone is planning on open-sourcing code that has previously been in a private repository or only version-controlled locally, you want to be careful not to have anything sensitive in the commit history. You can do this by following the above rules. When in doubt, you can remove the git history and start the public repo without it\nYou can remove a file from the entire commit history if you did commit anything sensitive, although you still need to follow the usual procedures if this was a data breach\n\nYou can find out more in the duck book’s guidance on using git.\n\n\n\n\nCollaboratively develop code using git\n\n\n\n\nWhat does this mean?\n\nHas code development taken place in git, collaboratively across the team?\nAre you making use of pull requests for team members to review and comment on code updates?\nIs there a clear paper trail of changes to code (commits)?\n\nWhy do it?\nUsing git allows multiple people to simultaneously develop the same code using branches, all with a crystal clear audit trail showing what changes were made when using commits. It makes it easy for team members to review changes via pull requests.\nHow to get started\nTo get started you should:\n\n\nGet your code into a git controlled folder\n\nGet code into a git controlled folder in whatever version it is currently in. Use the following steps to do so:\n\nOpen the folder where your project is saved, right click anywhere in that window, and click “Git Bash Here”.\nThis will open a black box. Type in the following and hit enter\n\n\ngit init\n\n\nAfter hitting enter, type in the following and hit enter again after each line. You will need the URL of your Azure DevOps repository to complete this step. Contact the Statistics Development Team if you are not sure what this is or do not have one.\n\n\ngit add .\n\ngit commit -m \"first commit\"\n\ngit remote add origin YOUR_URL_HERE\n\ngit push -f origin --all\n\n\nYou may be prompted for either your windows or git credentials at this stage.\n\nIf prompted for your windows credentials, enter the username and password combination you use to log into your DfE device.\nIf prompted for your git credentials, visit your online repository, click on the blue “clone” box, and click “generate git credentials”. This will generate a username and password for you to enter.\n\n\n\nVisit your repository online, and check that all the files have uploaded. Other members of your team will now be able to work from your code.\n\n\n\n\nBuild capability within the team\n\n\nEnsure all team members have access to your project in the Azure DevOps official-statistics-production area. Contact the Statistics Development Team if there are any issues.\nGet team members to clone your repository in to their personal area, so everyone is able to work on code at the same time.\n\nTo clone code, they will need to do the following:\n\nRun through steps 1 - 2a of getting a file into a git controlled folder\nAfter running those lines, type in the following with your repository URL in the “YOUR_URL_HERE” space. This will clone the online repository to your local area.\n\n\ngit clone YOUR_URL_HERE\n\n\nMake use of git and version control in your team projects regularly. Like learning anything new, putting it into practice regularly is the best way to become confident in using it.\n\nPlease refer to the other links on the learning resources page to learn more about how to use git in practice."
  }
]